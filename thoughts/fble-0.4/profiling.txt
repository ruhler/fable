Fble Profiling
==============
Revisiting fble profiling, based on the following:
* Can we eliminate the overhead of profiling when it is disabled?
* We could implement 'call' counts as another form of profiling time, rather
  than treat it separately. Every function call counts as 1. To find call to a
  particular function, look at its self time.
* Challenges with over-abstraction currently: Lots of calls of a->b->c and
  d->b->e will make it look like a calls e a lot, when in reality it never
  does.
* Recently added -s option to fble-perf-profile.

For example, imagine I change the implementation of profiling to collect the
set of samples, e.g. {(a->b->c, 1000), (d->b->e), 200), ...}. We could do
everything in post processing.

The set will be large. We can save memory by representing it as a tree
perhaps, assuming most samples share common prefixes. But we still have the
challenges of recursion and tail calls that can make it get too large.

Is there some clever way I can encode things to bound the size of the profile
data based on the size of the code rather than the duration of execution?

Let's start by thinking about recursion.

  a -> b -> b -> b -> c

Potentially b could be an unbounded length. Say 1000 calls. And say we do a
sample for every call. That leaves 1000 different sequences to store. Sadness.
But is it useful? Can we use some sort of abstraction to save space without
losing anything interesting?

The current implementation uses the idea that... well, there are two parts.
One is time spent calling a function, and one is time spent calling into a
function from another function. As soon as we call function 'b', no need to
add more calls to b on the stack, because it won't make a difference to the
final numbers we care about. As soon as we add a call a->b, no need to add
more calls a->b to the stack, because it won't make a difference to the final
numbers we care about. But now I say we care about more things than we did
before. Is there a happy medium?

In the example above, I'm fine to merge b->b into b. It doesn't add any more
info. For example, assuming we are counting calls for simplicity:

 a: 1
 a->b: 1
 a->b->b: 1
 a->b->b->b: 1
 a->b->b->b->c: 1

May as well be saved as:
 a: 1
 a->b: 3
 a->b->c: 1

We see that a is called once, b is called 3 times, c is called once. I guess
what we are missing here is that b is called three times, twice by b and once
by a. So really we need:

 a: 1
 a->b: 1
 a->b->b: 2
 a->b->b->c: 1

Where, in this case, b->b stands for a recursive cycle?

How about any time we see a recursive cycle, create a new name for the cycle
and use that.

a->b->b: here we see a cycle: b->b. We want to keep track of entrance into the
cycle separately from cycling into it. Let's say B = b->b:

a->b->B->c ?

Not sure.

---

Proposal for new profiling format and viewer.

We describe a profile as a tree of nodes. Each node is labeled with the
profiling block it corresponds to and a sample count.

We can convert the tree of nodes to a set of samples sequences. There is one
sequence per node, and that sequence occurs the number of times of the sample
count of the node.

For example, you might have something like:

 -> a 1 -> b 1 -> b 2 -> c 1

This corresponds to the set of samples:

 -> a 1
 -> a -> b 1
 -> a -> b -> b 2
 -> a -> b -> b -> c 1

To bound the size of the tree, we impose a restriction that X -> Y for some
particular X and Y does not appear more than once on any given sample path.
For example, the following sequence is disallowed:

   -> a -> b -> a -> b -> c

Instead we abstract it as:

   -> a -> b -> a
            \-> c

This abstraction is a loss of information for the purposes of keeping the
profiling data more compact. In theory we could pick any length sequence
X -> Y -> Z -> ... to use as the restriction. I think a 2 element sequence is
most useful in practice.

For example,

 a 1 -> b 1 -> b 1 -> b 1 -> c 1

If we used a single element sequence for the restrction, this would be:

 a 1 -> b 3 -> c 1

That suggests a calls b 3 times, and b never calls b. With a two element
restriction, we have:

 a 1 -> b 1 -> b 2 -> c 1

Which makes it clear a calls b one time, and b calls itself twice.

A three element restriction doesn't appear to give us any more useful
information:

 a 1 -> b 1 -> b 1 -> b 1 -> c 1

Though I imagine there is some sequence you could come up with where you lose
useful information with a 2 element restriction instead of a 3 element
restriction.

We put the restriction on each path of the tree rather than the tree as a
whole to avoid confusing sequences from different paths. For example:

  -> a -> b -> c
  -> e -> b -> c -> d

We don't want this to be abstracted as:

  -> a -> b -> c -> d
  -> e -> b ->/

Because that suggests there is some path from a to d when there is not.

The bounds on tree size aren't great. It's something like O(N^N), but I bet in
practice it will be much better than that because the majority of callsites
have a constant number of callees.

Okay, so the profile format is clear. Here's how we track it at runtime:

The profiling thread has two data structure:
* The current real callstack. Each entry is a pair of profile id and pointer
  into the profile tree of the location corresponding to this stack entry.
* The current profile tree.

We keep a current pointer into the current profile tree. Call it P.

Push X:
  Push X onto the stack.
  If P -> X exists on the path from the root to P, go to that X. Otherwise add
  '-> X' at the current place in the tree and go to X.

Pop:
  Pop from the real stack. Update P to point to whatever is now on the top of
  the real stack.

Replace X:
  Pop from the real stack. Then push like you normally would.

Sample:
  Increment current sample value of P.

The only tricky part is detecting if P -> X exists on the path from the root
to P. But we already have something like that. We don't switch paths randomly,
we always pop everything off one path before going to the next, so we should
be fine there.

The last part is how to present the information. I vote for a web server so
you can use browser as a UI. The variety of information  we may want to
present is too big to have a single static text file.

Each page has the following options:
* List of 'selected' profile blocks. Removes from the profile tree any paths
  that do not contain all of the selected profile blocks.
* List of 'excluded' profile blocks. Removes from the profile tree any paths
  that contain any of the excluded profile blocks.
* List of 'folded' profile blocks. Replaces any sequences of the form
  a -> X -> y for folded block X with a -> y (details need ironing out).

Those options all act as modifiers on the profiling data.

To view profiling data, we have the following pages:
* Self times: For each profiling block, reports the self time of the block.
  That is, the sum of sample values of nodes with that block id.
* Dominated times: For each profiling block, the sum of sample values for
  every path that contains that profile block.
* Specific profile block X: 
   Going in: For each other block Y, counts number of samples with Y -> X.
   That's how much time you get back if you remove Y -> X.
   Going out: For each other block Y, counts number of samples with X -> Y.
   That's how much time you get back if you remove X -> Y.

For any profile block X mentioned on any page, make it easy to:
* Jump to the specific profile block X
* Add/remove X to/from 'selected', 'excluded' and 'folded' block options.

Make it easy to jump to self time pages and dominated time pages.

Have a list of currently selected, excluded, folded blocks to make it obvious
what they are looking at and be able to remove those blocks from those lists.

That's it!

Oh, and consider having different kinds of profiles: call count, time, allocs.
Whatever counter you want. Those will require different implementations at
runtime. It might be easiest if a profile tracked only one thing at a time.
Produce separate profiles for separate metrics? Not sure.

---

Development plan:
1. Settle on a file format for recording the profile.
2. Generate a properly formatted perf based profile.
3. Write a viewer. See if it's more useful or not. Iterate as needed.
4. Update the profiling implementation in fble to generate a profile.

For (1), ideally use an existing standard format. If not, I guess make my own.
Some key questions:
* Should it support multiple metrics or just one?
* How to store profiling block info: file, line number, etc.

Before I go down that path, I want to review some of the challenges I have
with the existing profiles and see if we have a path to solve them here.

1. Dispatch function overabstraction.

-> a -> Call -> b
-> c -> Call -> d

In the profile ends up with:

  a,c -> Call -> b,d

Makes it look like a calls d or c call b, when that's not true.

Example:

      59194   451688           /Fbld/Eval%.Eval!.sequence[084eX]   
         90   451988           /Fbld/Builtin/Define%.Define!!![090fX]   
       7166   451990           /Fbld/Builtin/Define%.Let!!![0921X]   
          1   453490           /Fbld/Main%.Main!!!.:.result[09d6X]   
**  5687121   453490    11226  /Fbld/Result%.Do![0497X] **

**  5687121   453490    16573  /Fbld/Result%.Do!.:.rb[049aX] **
          1   453490           /Fbld/Main%.Main!!!.:.result![09d7X]   
       7166   451990           /Fbld/Builtin/Define%.Let!![0920X]   
         45   451988           /Fbld/Builtin/Define%.Define!!![090fX]   
      59194   451688           /Fbld/Eval%.Eval!.sequence![084fX]   

I have two potential solutions here with my new format:
1. fold 'Do', and all the in between helpers.
2. If we start looking at Eval!.sequence!, then go to Do!., then add a filter
Do!. -> Eval!.sequence!, then you should see only the inputs Eval!.sequence
into Do! when you look at it.

This is slightly different from before, where we said we would limit all
traces to, say, ones containing Eval!.sequence!. Now I'm saying as I explore
up (or down?) from a node, add the path being followed as a filter.

2. Continuation/Dispatch functions showing up high in list.
For example:

**     7166   451990       28  /Fbld/Builtin/Define%.Let![091fX] **

So much time is spent in Let! because after we call Let!, the next thing it
does is evaluate its body, and everything is in the body. Let! has no
influence at all over what is executed in the body, so it's not useful to
associate the body time with the function Let!.

I almost want to set: only charge Let! for code under its control, not the
'Eval(env, Get(cmd.args, 1))' part. Just because so much of the rest of the program is
stuffed into body Eval part.

I'm not convinced we can figure out in general when we care about the
subroutine call and when not. For example, List.Length, the cost of the tail
entirely depends on the structure of the list argument. Clearly we want to
count that towards the cost of List.Length. But how is Let evaluation any
different? Depending on the structure of its argument, it has a different
tail.

Maybe the challenge here is the annoying structure of the fbld evaluation code
where Eval calls into everything and everything calls into Eval. It's a big
recursive knot that is difficult to untangle.

Any solutions for this? I wonder if we could group the recursive cycle into a
knot and then subdivide it into its child parts?

3. Recursive functions.

        226      148           /Fbld/Builtin/Define%.PreLookup!.command.:.:.impl.:[0902X]   
    3125991   101562           /Fbld/Env%.Lookup!.:.:[0469X]   
     981307   134898           /Fbld/Eval%.Eval!.command.impl.:[084bX]   
**  4107524   135046     4028  /Fbld/Env%.Lookup![0465X] **
    4107414   134081           /Fbld/Env%.Lookup!.:[0467X]   
        110        0           /Fbld/Env%.Lookup!.nil[0466X]   

Lookup calls into itself. Looking at entries like this don't feel terribly
useful. Self time is 4028. So where is all that 134081 going to? I guess in
this case we can follow it down and see it's the call to /Core/List/Eq%.Eq!,
which is outside of the recursive loop. Once again, it feels like we want to
separate 'recursive loop' from 'children of recursive loop'. Maybe that's okay
for now, it's just a bit tedious to traverse the graph and manually separate
out which parts are in the recursive loop and which parts are not.

4. Excessive traversal.

**        3   526454        0  <root>[0000X] **
          1   526384           /Core/Monad/State%.Monad![0976X]   
          1       70           <main>[0001X]   
          1        0           /Core/Stdio/IO%.Run![09a2X]   

**   282549   526384      615  /Core/Monad/State%.Monad![0976X] **
      65573   526384           /Core/Monad/State%.Monad![0976X]   
          1   505499           /Fbld/Main%.Main!!![09d2X]   
     216976    22757           /Core/Monad/State%.Monad!.ra[0977X]   

**        1   505499        0  /Fbld/Main%.Main!!![09d2X] **
          1   505499           /Fbld/Main%.Main!!!.:[09d5X]   

**        1   505499        0  /Fbld/Main%.Main!!!.:[09d5X] **
          1   503627           /Fbld/Main%.Main!!!.:.result[09d6X]   

**        1   503627        0  /Fbld/Main%.Main!!!.:.result[09d6X] **
          1   453490           /Fbld/Result%.Do![0497X]   
          1    50137           /Fbld/Parse%.Parse![080fX]   

As I traverse down, it's commonly the case that the majority of time is spent
in a particular child call. Maybe it would be nice to merge those all
together. For example, in this case, something like merging
/Fbld/Main%.Main!!! and /Fbld/Main%.Main!!!. into a single frame, so we don't
have to click through stuff we don't care about.

I think we could get pretty close if we pick something like 95% time, and
accumulate that as we go down. We could let the user pick the percentage to
join on.

Sounds like overall there's plenty to explore in the UI for viewing profiles.
Good news is I think the new profile format preserves all the information we
need for playing around with these things, unlike the current profiling
format.

---

On to profiling format. 

What I want:
* Describe a tree whose values are block id, sample count(s).
* Include for each block id, name, file, line number, column number.

Worst case, we could have a list of sample sequences instead of a tree. Just
seems like the tree is the more efficient way to store the data.

Survey of existing formats:
Linux Perf:
  tools/perf/Documentation/perf.data-file-format.txt
  It's very specific to the linux kernel. We could probably use it, but feels
  rather out of the way.

gperftools:
  https://gperftools.github.io/gperftools/cpuprofile-fileformat.html
  Basically a list of (sample count, list of PCs)
  Followed by a text map, which maps PCs to build number and filename. Looks
  like addrtoline can then be used separately to extract line number info.

Python Fil profiler:
 
Python cProfile:
  Has not compatibility or stability guarantees. So don't use this.

google/pprof:
  profile.proto format
  Uses proto3 syntax.
  Supports multiple custom metrics.
  Looks like it supports exactly the information we want:
  - multiple metrics per sample.
  - sample as a list of location ids.
  - separate section for giving info about location ids, including file and
    line and column number.
  Already has support for converting linux perf to pprof format.
  
I'm tempted to use google/pprof format, except that it's a bit complicated in
depending on things like proto3 and gzip. So it could be harder to write a
standalone tool for it.

Maybe I can use textproto format instead of binary? Or some other format pprof
supports?

Looks like proto3 has a way to convert between proto3 and json file format?

It looks like the proto3 wire format is fairly straight forward though. So
perhaps fine for me to write to it directly. There's just a lot of layers
involved: binary -> protoscope -> proto3 -> pprof.

I vote we eventually support pprof format, but to start, if we want, I can
define my own simpler format. We can provide a library in my format to
save/load as whatever syntax I want to start, and pprof eventually in the end.
In other words: for now write a library for my profiling format. Worry about
the file format later. But let's keep pprof format it mind for question's
about things like multiple metrics.

Cool. Next step is to draft the data structure / library for representing my
profiles in C. I can add code to load from linux perf directly to start rather
than have a separate file syntax to go through.

