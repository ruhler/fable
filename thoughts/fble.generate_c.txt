Fble Generate C
===============
It's been a while since we tried generating c code for fble compilation. Now
that we're considering cross platform support, seems like it's worth trying
again.

The problem we had with generating C before was that it took too much memory
(>1GB) to compile the generated C code. A lot of things have changed in fble
since then. Perhaps most importantly, we pass list and literals all the way
through the compiler instead of desugaring them first. Also, we are single
threaded now and have a standard way of supporting tail recursion at the C
level.

The benefits of generating C code are:
* Support all platforms we can build fble for without any extra dependencies.

The potential disadvantages of C code, compared to custom assembly:
* Compile time memory and performance costs.
* Runtime performance costs.

My vote is to give it a try, again. See if we can get past the compile time
memory costs and how close we can get to runtime performance. This will help a
lot for cross platform support.

How about I do it from scratch, ish. Based of generate_aarch64.

Initial thoughts looking over generate_aarch64:
* I think there's a lot of code we can reuse from aarch64. My vote is reuse by
  copy-paste, under the assumption we keep either one or the other in the end,
  but likely not both.
* Function args: heap, thread, locals, statics, profile
* Don't worry about debug info to start.

There will be some tricky parts, but for the most part, I think it should be
straight forward.

First step: wire up some stub code and make it so I can run it.

---

How can we do debug info? Like, what does bison do in its generated code?

We have pragmas like:

#line 3 "fble/lib/parse.y"

Let's start with that then.

---

I'm getting close. Some observations:
* The #line pragmas are making debug the code generation logic annoying. Can I
  get rid of them for now? I don't think they work the way I think either. I
  think we need a separate way to get dwarf.
* I'm getting real mixed up on what GenerateCMain and GenerateCExport should
  do.

GenerateCMain:
int main(int argc, const char** argv) {
  return <main>(argc, argv, <compiled module>);
}

Type of <compiled module> is FbleCompiledModuleFunction.

That looks fine.

Next, GenerateCExport: it should take a heap as input. What does it do? I
guess it should call the module function, passing the heap argument?

Maybe my comment in the documentation is wrong? The assembly code is literally
branching to the module function and returning the result. It must be passing
all the arguments directly.

Uh... I'm lost.

FbleCompiledModuleFunction is a function that, given a program, adds the
module to that program. That's what we define. What's what we call to ensure
dependencies are loaded, right? That's what we pass to a main function to be
able to instantiate a program. Export 'main' invokes main function on that,
and that's what we generate code for. That all makes sense.

What I don't understand is the CExport function. What type is that supposed to
have? I assume it's supposed to be a wrapper something or other?

According to docs, the exported function should return a zero argument fble
function that can be executed to compute the value of the given module. How
does it work? I don't understand what generate_aarch64 is doing. That can't be
correct, can it?

Step back. How would I generate the FbleValue in the first place?

I think the documentation is wrong. That must be out of date. It should just
give a nice name to the FbleCompiledModuleFunction with the internal name,
that is: void X(FbleExecutableProgram* program), right? Yeah. That makes
sense.

Next issue: Need to generate prototypes for all Run and Abort functions up
front.

Notes:
* Double check if spec tests are using the c target or aarch64. I think it may
  be different.
* Will want to clean up includes of execute.h, value.h at some point.
* Memory use for compiling the generated c code is looking not too bad so far?
* Runtime for compiling the generated code isn't great.

Actually, we're starting to hit issues with gcc memory use to compile the
generated code. Let's see if I can find out which one it is.

  out/pkgs/md5/Md5/Rounds.fble.c

It's 100K lines of C code. Ugh.

Well, something to dig into next:
* Why is Rounds.fble.c so big. Anything we can do to cut that down by an order
  of magnitude?
* Try running just the spec tests with -c target, see if everything passes.
* Try running some program manually that's compiled, just to convince myself
  it actually works.

One thing that stands out scanning through Rounds.fble.c is a whole lot of
struct accesses, each of which has an error case. And a function with a lot of
instructions, which leads to a pretty big case statement and per-instruction
overhead.

---

Seeing if I can add c code generation to spec tests at least. Looks like they
expose some more bugs. A couple of bugs fixed. All the spec tests pass with
the compiler. Let me figure out how to do both aarch64 and c tests in the spec
tests in a hopefully clean way.

Yeah. This works well. We can abstract away all the different targets and make
sure we test them all in spec tests. Or, at least, all of the available ones.

It might be fun to try compiling everything with generate_c on my windows
computer, which is x86_64 and has lots of memory. Just to see if it works and
maybe try running some benchmarks to compare interpreted, aarch64, and c.

---

The compiler appears to work fine on my windows computer. Max memory use I see
for compilation is around 500MB, which suggests perhaps we're close to being
able to do it on my Raspberry pi. Things that need to change to be able to
check this in:
* Distinguish better between hand written c code and generated c. In
  particular, we need different names for object files in both cases, e.g.
  Stdio/stdio.fble.o could be from Stdio/stdio.fble.c or Stdio/Stdio.fble.
  Don't assume case is sufficient to distinguish them.
* Use fbleobj instead of manual invocation to fble-compile where possible.
* Figure out how to decide which approach to build with: one, the other, or
  both.

It would be great to set up some benchmarks to understand how performance is
looking on c versus aarch64 target.

The path to getting rid of aarch64 target:
* Check in cleaned up changes to avoid name conflict in stdio.fble.o file and
  friends.
* Get it to compile on low memory.
* Setup benchmarks, check if they are within, say, 20% of aarch64.
* Figure out how to emit debugging info via C approach.

---

Goal: See how close we are to being able to compile everything with 1GB RAM,
and what we could do to get us closer.

Let's see how much memory it actually takes on what files.

Part of the challenge is, even the ones that don't take a ton of memory can
take multiple minutes to compile. Any way I can profile that? Maybe ninja -d
stats?

There are 4 culprits:

/Md5/Rounds%
/Sat/Aim%
/Invaders/Graphics%
/Graphics/Camera/SinCos%

Let me let them run for longer and see if any come close to finishing.

I clearly can't run all four at the same time. Let's try one at a time:

/Md5/Rounds%: Goes up to 60% memory and then completes okay.
/Sat/Aim%: Goes up to 72% memory and then completes okay.
/Invaders/Graphics%: Goes up to 45% memory then completes okay.
/Graphics/Camera/SinCos%: Goes up to 40% memory then completes okay.

So we're close. If I could get an order of magnitude better. Or even just
compile all of these one at a time, I maybe could swing it.

Let's see if number of lines of C code correlates here. It would be nice if we
could use that as a metric to try and improve.

Yes. That's shows it pretty clearly:

   108797 out/pkgs/md5/Md5/Rounds.fble.c
   105934 out/pkgs/sat/Sat/Aim.fble.c
    76723 out/pkgs/invaders/Invaders/Graphics.fble.c
    60029 out/pkgs/graphics/Graphics/Camera/SinCos.fble.c
    34514 out/pkgs/graphics/Graphics/Triangle/Tests.fble.c
    22824 out/pkgs/core/Core/Int/Tests.fble.c
    22319 out/pkgs/pinball/Pinball/Tests.fble.c

The top four. Looks like 40K lines maybe a good target to shoot for.

Where are all these lines coming from? Let's review the modules and see what
they do.

Rounds:
* Lots of hex literals.
* Lots of big structs.
* Lots of deep chains of struct accesses.
* C code shows lots of struct access instructions, including check for
  FbleStrictValue and corresponding error message.
* Some functions with 5K or more instructions.

Aim:
* Lots of int literals.
* Long nested list literals. There are no struct accesses at all.
* Some functions with 5K or more instructions.
* Lots of aborts and error messages.

Invaders Graphics:
* Lots of int literals and list literals.
* Some functions with 5K or more instructions.
* Lots of error messages.

Graphics SinCos:
* Lots of int literals.
* Long list literal.
* Some functions with 5K or more instructions.
* Lots of error messages.

Note: none of the fble files are particularly large. I expect all of these
should compile just fine.

Brainstorm of things to try:
* abort on error instead of have error handling.
* Remove 'abort' function implementations.
* Remove profiling code at every instruction.
* Use different options to gcc to optimize for memory somehow?
* Use initializer list instead of assignments for literal instructions.
 - Also for "statics".

What sticks out to me is:
* From fble side: lots of literals. See if I can improve code generation for
  that.
* They all have 5K+ instruction functions with lots of abort cases.

Let me start with something easy and noncontroversial: Generate as many arrays
using initializers as I can rather than separate assignment statements. It
won't reduce lines of code, but hopefully it helps with something inside. I'm
not sure if I expect much, but it's worth a try.

I don't see any memory improvement from this change. I like it anyway though,
so I'll keep it.

Next thing to try, just because it's easy to try: put all these array
initializers on a single line instead of spreading across lines. Clearly the
structure of the code is identical. But I'm wondering if the memory is
proportional to number of lines in terms of, perhaps, debug info. This
approach should drastically cut down on number of lines. I can see by how
much. And then we can see if it helps with memory.

If it helps with memory, I'll take it. If not... I'll look at some of the code
and see how hard it is to digest.

Looks like it actually doesn't make a difference in overall line counts, aside
from a few thousand lines saved. The code looks good. Longest line I'm seeing
is 255 lines or so, it doesn't look too bad. Most of these all fit easily in
80 characters. I'll keep this change.

   106841 out/pkgs/md5/Md5/Rounds.fble.c
    99785 out/pkgs/sat/Sat/Aim.fble.c
    72427 out/pkgs/invaders/Invaders/Graphics.fble.c
    55915 out/pkgs/graphics/Graphics/Camera/SinCos.fble.c
    32884 out/pkgs/graphics/Graphics/Triangle/Tests.fble.c
    21252 out/pkgs/core/Core/Int/Tests.fble.c

Next thing to try? I'm thinking either abort or profiling code. Both of which
are sort of not needed for typical use case and potentially take up a lot of
extra code.

A couple different experiments we can do for abort:
* Don't generate an abort function. Just use NULL.
* Don't output error messages on aborts.
* Don't generate tests for aborting.

I want to get a sense of what makes more or less difference. Let's try one at
a time and see if any are particularly noticeable.

1. Don't generate an abort function.

Interestingly enough, only about 25% of the generated C code is Abort
functions:

    79447 out/pkgs/md5/Md5/Rounds.fble.c
    73327 out/pkgs/sat/Sat/Aim.fble.c
    55834 out/pkgs/invaders/Invaders/Graphics.fble.c
    43343 out/pkgs/graphics/Graphics/Camera/SinCos.fble.c
    25419 out/pkgs/graphics/Graphics/Triangle/Tests.fble.c

More importantly, removing them doesn't have a significant effect on memory
use. Maybe it drops from 63% down to 57%. 72% down to 69%.

Next thing to try:
* Remove all checks for abort behavior. Add this on top of the no abort
  functions change. I'm looking for something to make a substantial
  difference.

They still take a long time to compile. Rounds is down from 57% to maybe 45%
with this change. Sat/Aim is down from 69% to 63% from this change.

We haven't reached an order of magnitude yet. And
interestingly enough, it's only shaved off maybe 15% of lines of code:

    65292 out/pkgs/sat/Sat/Aim.fble.c
    57523 out/pkgs/md5/Md5/Rounds.fble.c
    48176 out/pkgs/invaders/Invaders/Graphics.fble.c
    36794 out/pkgs/graphics/Graphics/Camera/SinCos.fble.c

Next thing to try, again on top of all this: remove profiling code.

That's it. Removing all the profiling code makes a big difference. Cut down
memory use by half. We can now compiling everything in parallel no problem.

    38828 out/pkgs/sat/Sat/Aim.fble.c
    31953 out/pkgs/md5/Md5/Rounds.fble.c
    31433 out/pkgs/invaders/Invaders/Graphics.fble.c
    24234 out/pkgs/graphics/Graphics/Camera/SinCos.fble.c
    15611 out/pkgs/core/Core/Char/Eq.fble.c

It also put us under the 40K line mark.

Interesting. Let's see if I can walk back some of the abort changes. Can
everything be explained by profiling, or is it some mix?

I'm starting to suspect the issue is total number of conditions in a single
function.

---

Focusing on Aim now. Let's add back abort checks while leaving out profiling.

Remember where we are:
* 72% baseline memory use.
* 69% -ABORT_FUNC
* 63% -ABORT_FUNC, -ABORT_CHECK
* 30% (?) -ABORT_FUNC, -ABORT_CHECK, -PROFILE

Add back abort check now:
* 40% -ABORT_FUNC, -PROFILE, but still it's fast to run (40s, not 2 minutes).

Add back abort function now:
* 44% -PROFILE, still fast, but not quite as fast.

Something to try: enable dumping of info from gcc. Things to try (from
https://gcc.gnu.org/onlinedocs/gcc/Developer-Options.html):
  -ftime-report
  -fmem-report
  -time
  -fdump-statistics (doesn't seem to do anything?)
  -fdump-statistics-option [-detail | -stats]

Looks like -ftime-report and -fmem-report are good starts.

Most of the time is spent in phase opt and generate. That's a little broad.
Can we get more detail?

I can't figure out a combination of options to give a summary of time spent in
each pass with more detail than -ftime-report.

Could we reproduce the issue, you think, by writing a function that's pure
profiling code? Just a bunch of:
  if (profile) {
    if (rand() % 1024 == 0) FbleProfileSample(profile, 1);
  }

Back to back to back?

---

I'm not sure what to do. Misc ideas:
* We could coalesce profile blocks into one. Do a single sample for a combined
  straight line of instructions. Not sure if the math is straight forward for
  the random of the sample, but that would cut down on calls to profiling.
* We could statically detect potential undefined values and avoid inserting
  abort checks if we know they can't trigger statically.
* We could wrap the condition around a function. For example, 
   ProfileSample(profile) = if (profile && rand() % 1024 == 0) FbleProfile(sample
  That way we get straight line code in the generated functions, and even
  though there is overhead to doing the function call, at least, hopefully,
  the compiler can handle compiling better.

I think, at this point, it would be good to get some benchmarks. Some sense of
how much performance we get interpreted versus aarch64 versus c generation
with various gcc compile options. For example, if C code is faster than
aarch64 even with putting conditions behind functions, then that would be
great, right? Or at least make the decision to add that indirection in the
generated code.

What benchmarks did we have before? What's the state of them today?

I see the following:
pkgs/graphics/Graphics/Bench.fble
pkgs/md5/Md5/Bench.fble
pkgs/pinball/Pinball/Bench.fble
pkgs/invaders/Invaders/Bench.fble
pkgs/sat/Sat/Bench.fble
pkgs/games/Games/GameOfLife/Bench.fble
pkgs/games/Games/Snake/Bench.fble
pkgs/games/Games/BenchmarkGame/Bench.fble

Here's what I think: each package should define a compiled program that is a
benchmark for the package. Assuming there is something interesting enough to
benchmark. I think initially Md5 and Sat would be great to start to get an
initial idea of performance.

Looks like the benchmarks are expressed as tests. So we could run them using
whatever we do to run tests.

Tests are wrapped in /Core/Stdio/IO%.Run(/Core/Test/Stdio%.Run(Tests)). Let's
try the same for md5.

md5-bench interpreted:  1m22s
md5-bench aarch64:        50s
md5-bench c:              57s (no special gcc options.)

---

Note: it doesn't look like there's any way to specify dwarf debugging info as
input to a c compiler. We would need to target the gcc or llvm IR level.
That's rather annoying. I don't see any options for llvm text based bytecode
dwarf either.

The tradeoffs for custom code generator versus targeting something generic
like C or llvm:
* Custom code generator is faster, less memory to compile.
* Custom code generator has full flexibility on dwarf debug info.
* Custom code generator has lots of flexibility on compiled code.
* Targeting c or llvm means lots more architectures supported.
* Targeting c or llvm probably gives better runtime performance with
  sufficient optimization options than I'll ever get in my own compiler.

Some possible compromises:
* Be able to generate c/llvm, but still do architecture specific dwarf info?
  Is that feasible? Or would we have to generate the assembly ourself to be
  able to do that?
* Specify a set of supported architectures.

Really, if we are going to support multiple architectures, I see no reason not
to generate C code as another option. That doesn't add any extra effort, but
gives much better tail coverage of weird platforms. Presumably without debug
support.

In terms of which architectures to support, I vote for: arm, aarch64, x86_64
to start. Or, in other words, just the ones that I have computers to test on.
Let other people worry about other architectures if they care.

Ok. I like this approach. Multiple specific target architectures, as I desire,
and a generic C architecture as a catch all. Debug capabilities are only
available on the specific target architectures.

What's my strategy around build and test?
* We can only test targets supported by the architecture: the specific one and
  C. Unless we want to do some qemu thing, which sounds complicated. We would
  need to cross compile the fble library, which means we would need a cross
  compiler.
* I think prefer to compile a specific architecture. But, for example, maybe
  we build benchmarks, and possible compiled tests in specific and generic
  targets, to improve test coverage.

That sounds reasonable. Everyone is responsible for testing the 'C' target.
Otherwise, only make changes to your own specific target and make sure that
keeps working. Worst case, if we break some other target, at least they can
use 'C' as a target until they have a chance to fix it.

Strawman:
* For each benchmark and test, provide foo-tests-c, foo-tests-aarch64,
  foo-bench-c, foo-bench-aarch64 variants. Run both tests.
* That means, for each file, we really want libfoo-c and libfoo-aarch64.
  That's a lot of compiling to be doing, which means we need to get past the
  high C compilation overhead issue before we can do this for real.

TODO:
* Set up sat-bench, get some initial numbers.
* Set up aarch64 and c versions of the profiles-test
  - Debug and fix failing c version.
* Factor conditions out of profile code, see if that helps compilation while
  continuing to enable profiling.
* Factor common strings out of abort code. Who knows, maybe that will help a
  little bit with memory requirements.
* See if I can add static analysis to compiler to track what values may be
  undefined or not. I think that could help performance and code generation
  for both aarch64 and C code.

---

sat-bench interpreted:  2m00s
sat-bench aarch64:      1m16s
sat-bench c:            1m25s (no special gcc options.)

That's within 15%. So I think I'm satisfied, at least in the current
implementation, that compiling via C code will result in code that runs fast
enough compared to compiling via aarch64 code.

It's more the issue of compile times, compile memory, and debug info to be
worried about.

---

What if we use -O0 when building fble objects from c? Does it make a noticeable
difference in compile memory use?

Aim goes down from 70% memory to... 71%. So no. No improvement with -O0.

How about by pulling conditions for profiling logic out into separate
functions?

Aim goes down from 70% memory to... 48% memory. That's pretty nice.

What about the benchmark performance?

sat-bench c:    1m25s ==> 1m30s.

Which is still much better than 2 minutes for interpreted. Cool. Let's stick
with that then. Is that good enough to fix all my compilation woes?

Yes! Compilation woes are fixed in terms of memory use requirements. Though
we are sort of on the upper edge of what's available memory wise, so ideally
try to improve things over time. Otherwise we could fall over the edge.

---

How to clean up the interface between compiled code and libfble? Currently we
need access to some internal header files. Can I make those public or
eliminate the need for them? This is important, because I don't want to
install internal header files, but they need to be available somewhere.

I guess worst case we could make a special header meant only for compiled
code, but let's see if I can't clean up things first.

What do we need access to and why?

execute.h:
 - FbleExecStatus, FbleThread, FbleStack, FbleExecutable

value.h:
 - FbleFuncValueStatics, FbleFuncValueProfileBaseId, FbleGenericTypeValue,
   FbleNewFuncValue, FbleStrictValue, FbleFuncValueExecutable

Where are this originating from?

Obviously we need a way to define a function value. What's a good public way
to do that?

FbleNewFuncValue:
 - heap, statics make perfect sense.
 - profile_base_id is a little bit sketch?

We need to specify number of args, number of statics, and number of local
variables, in order to call the function, right?

We need to specify a run function. That run function has to have access to the
thread and the stack, though perhaps as opaque things?

The question is, what code needs to be invoked to execute a function value and
to create one?

In order to run a function, you need:
* Access to static variables captured by the function. But this can be tied to
  the function implementation. It doesn't need to be general.
* Access to the arguments supplied to the function. This could be passed as a
  list of arguments, right?
* To know if the function is finished, aborted, or needs to be tail called 
  - A function ought to be able to clean up itself on abort. So that can be
    internal.
  - If a function needs to be tail called, it needs somewhere to keep track of
    arguments.

Maybe the big thing is, for GC to run, GC has to be able to find all statics
and arguments passed to the function. Well, we keep those on the stack? We
keep statics with the function, arguments and locals on the stack. What else
do you need?

That suggests the stack does need to be a known thing. I think that's fair
enough. And if the stack is known, we can use that for storing things on tail
calls.

So, the following should be public:
* FbleExecStatus
* FbleThread having stack and profile. allocator can be abstract?
* FbleStack having func, result, tail, locals.
  But not pc. Pc is an internal state thing specific to the interpreter I
  feel like. So instead of pc, we want user defined non-FbleValue state? No.
  we shouldn't need that internal state. When you run the code it should
  always start from pc = 0 and go through until the function is either
  completed, aborted, or replaced with a tail call.

Things to do:
* Remove 'pc' from FbleStack.
* Make FbleStack and FbleThread public.
* Make functions for manipulating the thread public. e.g. FbleThreadCall, tail
  call, return.

Actually, if we have functions for manipulating a thread, can we use those
instead for all access to the stack? Have functions for accessing local
variables from the top of the stack for a given thread?

To allocate a new function, we need to give the list of statics, the number of
required local variables. Probably don't need the number of args, but maybe
couldn't hurt? And you need a function capable of running given the thread
state for the function.

Back to initial TODOs:
* Remove pc from FbleStack.
* Remove abort function from FbleExecutable.
 - Abort directly from the run function instead.
* Encapsulate access to stack via functions.
* Make appropriate functions public.
 - We can put them in fble-execute.h. That seems a natural place to me.

I'm not sure what to do about profiling. Let's take it one step at a time.

Maybe start by removing the abort function. Just call that ourselves on abort
instead of return 'ABORTED' and then having someone else call it for us. Once
that's gone, the need to pass pc is gone too, so we should be able to pretty
easily get rid of that.
 
---

Let's contrast these changes with simple function API. The difference is the
SimpleFunc API doesn't have access to static values or tail calls. We will
want something in between.

Anyway, notes on uses of abort:
* When we abort, execution unwinds the entire call stack. Instead, function
  calls will need to abort themselves if their callee aborts.

Rolling this out could be a little bit tricky. First step, I think, is to
incrementally change code to use nothing on abort function with cleanup in the
run function. Start with the SimpleFunc API, though I'm not sure that's well
tested. Then go to interpreter, then generate_c, then generate_aarch64.

The trouble is, before that will work, we need to handle abort when a callee
aborts. And whose job is it to call PopStackFrame and FbleReleaseValue on the
result when a function aborts? The callee? Surely that's the responsibility of
the callee, just like it is when the exit normally. Maybe add an
FbleThreadAbort function that the callee can call to achieve that.

I think my proposal is good, it's just going to be a lot of detail work to
implement properly, and I'm not sure there is a reasonable incremental path.

Let's just go one at a time, moving abort logic from Abort function to Run
function, and remembering that any time we call a function, we need to check
it's result for abort and handle that there.

Yeah, the problem is if compiled code returns ABORTED and that finds its way
to interpreted code, the interpreter doesn't know how to abort that compiled
code. I think we need to do this all in one go.

This will be tricky, but I should be able to slog through it. Only 4 cases to
handle, right: simple func, interpreter, generate_aarch64, and generate_c.

* simple func is basically done.
* interpreter means calling abort function internally, then abort.
* generate_c means putting abort logic in same function with different pc
  labels and jumping right to the abort logic.
* generate_aarch64 means putting abort logic in the same function with
  different pc labels and jumping right to the abort logic.

Maybe an easy first step would be to pass FbleThread to the abort function,
and ask abort functions to do the equivalent of PopStackFrame.

---

Let's take the plunge. Just do it all at once. Wish me luck.

For the time being I'm skipping aarch64. Let's get everything else working
first and then deal with that.

I need to come up with a nicer way to print what code is running when I run a
spec test, so I can manually reproduce errors. Maybe make my own exec function
and use that to echo the command being run for any test related executions
(fble-test, fble-compile, etc.).

---

Trouble: I think we've spilled over the edge of memory allowance on Sat Aim
again. What can we do? I bet we need to keep the _Abort_* implementation
function as is. Call it directly in ReturnAbort.

I think that's better, but I'm still running into high memory use issues. In
this case when we have all three or four big modules compiling at the same
time. Maybe I was lucky before and they got interleaved, but not now?

Looks like we've regressed maybe 6% on memory use on Sat/Aim. Think about
what other things I could do. Only emit goto labels that we would actually
jump to?

---

Here's the plan:
1. Update aarch64 code to remove abort function.
2. Take some more time to try and optimize generate_c:
 - Don't emit unused pc labels
 - Wrap function call while loop in a separate function.
 - Use shorter labels for function names.
 - Avoid introducing variables in {} statements, use shared local variables
   for the full function.

First, how to update aarch64 code? Two ideas:
1. Just manually call the existing _abort_ function.
2. Include abort instructions in same function definition, jump there directly
from the error check.

I think jumping to the right place directly is better. Let me try that to
start.

---

Oh. I guess what happened is I don't even use generate_c for the big apps when
aarch64 is supported. That's why I didn't run into generate_c issues there
recently. Still worth trying to optimize? Why not?

---

Let's work on removing pc from FbleStack to start.

Done. That was easy.

Let's try some optimizations to generate_c for the fun of it. Back to
benchmarking via /Sat/Aim%.

/Sat/Aim%: 83782 lines of c code, 52.5% memory to compile at peak.

First thing to try: remove unused pcs in the run function.

/Sat/Aim%: 74966 lines of c code, 50.9% memory to compile at peak.

Cool. Not bad. The code feels slightly messy. Oh well.

Next thing: shorter labels for function names?

I'm not sure. That hurts debugging a little more than I like. Or could we just
output info about locations elsewhere?

Maybe more promising to start is a helper function to call functions.

/Sat/Aim%: 70174 lines of c code, 48.0% memory to compile at peak.

Using static size_t lit_[] = { ... }

/Sat/Aim%: 67776 lines of c code, 44.0% memory to compile at peak.

---

Next: 

Vararg version of FbleNewListValue. What to call it? That's the real question.

FbleNewStructValue - ...
FbleNewStructValue_ - FbleValue** args

I would like both to be easy to use. But also, want to avoid people
accidentally passing an FbleValue** to the vararg one. And ideally we be
consistent in terms of naming everywhere we support vararg.

Things like printf use vprintf for things that take va_list as an argument.
That's not really what my situation is.

Let's brainstorm some different options:
FbleNewStructValueVA
FbleNewStructValueX
FbleNewStructValueS
FbleNewStructValue_v
FbleNewStructValueA
FbleNewStructValue_a
FbleNewStructValue_l
FbleNewStructValueL

I don't know. How about just do what I'm doing now. Default is var args, '_'
suffix means a list? But which is the default to use? Maybe something more
verbose?

FbleNewListValueVarArgs
FbleNewListValue_va

I don't know. I think the last one looks best to me. And I kind of feel like
we should always use _va for the var args version, and the default should be
FbleValue**.

Or use FbleNewListValue_, FbleNewStructValue_ for the va approach. You have to
be explicit that way, it's different, not default, but also pretty easy to
use.

Okay. Let's start with that. The old switcheroo.

Using varargs FbleNewListValue_ function:

/Sat/Aim%: 66573 lines of c code, 43.8% memory to compile at peak.

Remaining similar cases:
* Data type instruction. Though that's not used currently.
* FUNC_VALUE_INSTR - FbleNewFuncValue
* FBLE_CALL_INSTR - FbleThreadTailCall, FbleThreadCall
  This could be a tricky one though.

And that's it.

Fixing up FbleNewFuncValue:

/Sat/Aim%: 66573 lines of c code, 43.8% memory to compile at peak.

Because /Sat/Aim% does not create any new functions. Fair enough.

---

Thinking about what should move to public API and what is okay to move to
public API, it's things from execute.h and value.h.

Reminder from before:

execute.h:
 - FbleExecStatus - can be made public.
 - FbleThread - can we make it abstract? Is 'stack' and 'profile' necessary?
 - FbleStack - can we make it abstract?
 - FbleExecutable - we would have to make it public. That should be fine.

So, real question here is whether we can abstract away access to stack and
profile fields of FbleThread. Because I would rather keep FbleStackAllocator
private.

Who accesses FbleThread fields for what reason?
* generated code, for access to 'profile' and 'stack.
* stack, for access to locals and function.
* function for access to statics and profile_base_id.

Here's what I think:
* Pass func, locals, and statics as argument to run function.
* Wrap access profile functions in versions that take FbleThread*
  Or: pass profile and profile_base_id in run function too.

value.h:
 - FbleFuncValueStatics, FbleFuncValueProfileBaseId, FbleGenericTypeValue,
   FbleNewFuncValue, FbleStrictValue, FbleFuncValueExecutable

---

After using varargs for call functions and removing {} scopes in generated c
code:

/Sat/Aim%: 60173 lines of c code, 42.9% memory to compile at peak.

---

Revisiting this now, because we still need to remove internal includes from
compiled c code. Looks like the first thought was to pass func, locals, and
statics as argument to the run function. The goal being to remove the need for
FbleFuncValueStatics to start.

First step is to move everything from execute.h to fble-execute.h. But I do
wonder if we can make FbleStack and FbleThread abstract types somehow?

---

Current uses of stack-> in generated c code:
* Call function on top of stack.
  - This code could be factored out into an FbleThreadCall function of some
    sort?
* Get locals
  - This could be avoided by passing locals to run function.
* Get func
  - This could be avoided by passing statics and profile_base_id to run
    function.

And that's it. How about let's change the run function to take those as
arguments then?

1. Factor out 'Call' function, so we never need to call run ourselves.
2. Change run function signature to take locals, statics, profile_base_id.
3. Make FbleStack an abstract type.
 - Or, even better, make it a completely internal type?

What should we call this 'Call' function? The idea is it should run the
function at the top of the stack.

Can we make it part of FbleThreadCall_?
* That would be useful for generate-aarch64.c too.
* That would be useful for interpret.c too.
* That would be useful for execute.c too.

This sounds like good cleanup to me.

Maybe we want to update FbleThreadTailCall_ to return FBLE_EXEC_CONTINUE or
something?

Note: having FbleThreadCall do the follow up call has an implication for stack
space: we are duplicating the arguments on the native stack and the managed
stack, where before we popped them off the native stack before doing the call.

Perhaps that's a future opportunity to make better use of the native stack for
arguments. I'm not going to worry about it right now.

---

What if we changed run function to take executable too? In other words, you
get everything you created the function with, plus local variables with the
arguments. Sounds good, right?

Should we pass 'result' too? No. We have FbleThreadReturn for that. And I
should start making use of that everywhere. That means passing around thread
instead of stack for interpreter abort functions. Maybe I can do that later.

---

Let's revisit from the top: what information do we need to define an fble
function?

To define an fble function:
* Access to locals/args.
* Access to static variables.
* Ability to return a value, abort, or continue.
* Access to user defined data (such as bytecode to interpret).
* Profile block base id, assuming that's not implicit from context.
  - For example, we could have PushBaseBlockId/PopBaseBlockId functions to
    maintain the stack of profile block ids in a way that users don't have to
    care.

To use a function:
* Number of args and locals.
* Know where the result should go.
* Check the result is finished/continued/aborted.
* Know the profile id of the function block.

To construct a function:
* Info for how to run and use a function.
* Static variables.
* Profile base id.

To free a function:
* How to clean up user data.

Special case:
* For module level functions, we want list of profile blocks to add to
  profile.

Note:
* We want to be able to represent information about an 'executable' using a
  static definition of a struct for generated code purposes.

There's a lot going on here. A lot of info we need, a lot of details to work
out. Rather than do it all at once, how about we take an incremental approach?

Hmm... But what's the goal here? Two goals:
1. Don't require including "value.h" for generated c code.
* Remove need for FbleFuncValueStatics by passing statics to run function.
* Remove need for FbleFuncValueProfileBaseId by passing it to run function.
  Or making it implicit based on context.
* Make FbleGenericTypeValue public.
* Make FbleNewFuncValue_ public.
* Make FbleStrictValue public.
2. Avoid exposing too many internal implementation details for how functions
are represented.
* Make FbleStack private. There should be no need to reference it.
* Make FbleThread abstract.
* Make FbleExecutable private.
3. Avoid need for separate FbleNewFuncValue and FbleNewSimpleFuncValue APIs.

Strawman proposal:
  FbleValue* FbleNewFuncValue(
    FbleValueHeap* heap,
    size_t num_args,
    size_t num_locals,
    size_t num_statics,
    FbleRunFunction* run_function,
    void* user,
    void (*on_free)(void*))

The problem is, we need a way to define an FbleExecutable for defining a
module before we have a value heap. That suggests FbleExecutable, or some
equivalent, needs to be a public structure. If we have that anyway, as a
template for constructing functions, we may as well reuse that for both
modules and functions. For a module, we need block ids. But we can have those
associated with FbleExecutableModule, rather than FbleExecutable, right?

Strawman Proposal 2:
* FbleExecutable: (subclassed for user data)
    size_t num_args
    size_t num_locals
    size_t num_statics
    FbleBlockId profile   (relative to module that the executable belongs to)
    FbleRunFunction* run_function
    void (*on_free)(void*)
* FbleExecutableModule:
    ...
    FbleExecutable* executable
      assert that num_args is deps.size
      assert that num_statics is 0
    FbleNameV profile_blocks;
* FbleValue* FbleNewFuncValue(
    FbleValueHeap* heap,
    FbleExecutable* executable,
    FbleBlockId module_profile_base_id,
    FbleValue** statics)
* FbleExecStatus FbleRunFunction(
    FbleValueHeap* heap,
    FbleThread* thread,
    FbleExecutable* executable,
    FbleValue** locals,
    FbleValue** statics,
    FbleProfileId module_profile_base_id)

This sounds good to me. Just want to think about if we can do anything better
for profile ids. Each module has some profile blocks associated with it.
Modules get relocated at runtime. We have to know where the module was
relocated to.

We don't know where a module is relocated to (profile block wise) until we
load the module and create the module function. The module function is like
any other function when we execute it. We don't treat it specially. But it
does get called from the top level, where profile base id is 0.

So, if there's one thing we could do to simplify, it would be this:
* We keep current profile base on the stack.
* FbleNewFuncValue takes profile_offset, which is relative to the current
  profile base at the time the function is allocated.
* We update current profile base before calling FbleRunFunction.
* Calls to enter/exit blocks are relative to current profile base.

The benefit being, this way we don't need to pass a profile base id to
FbleRunFunction. We still need to pass an offset to FbleNewFuncValue though,
and in practice I expect the offset passed to FbleNewFuncValue is zero for
anything except a module. If we wanted, we could define an FbleNewModuleValue
that takes module_profile_base_id without statics, and don't allow profile
base id to specified as part of FbleNewFuncValue.

What's awkward about this suggestion is:
1. We need wrapper functions for calling profile enter/exit, unless we want to
make profile base ids part of the profiling API.
2. It's not obvious to me when calling FbleNewFuncValue what the current
profile id is. We could fix that by passing a thread instead, but I kind of
prefer us not to have to have a thread ready when allocating a function value.

All of which suggests I stick with the above proposal. The only question being
whether we want to change the name of the argument.

Names are:
* profile => profile_block_id (relative to profile_block_offset)
* module_profile_base_id => profile_block_offset

Does profile_block_id make sense to be relative to profile_block_offset? How
do you know what offset it is relative to? Easy: whatever profile_block_offset
is passed to FbleNewFuncValue. And where we get that in practice, is either
from link, which is the module profile blocks, or FbleRunFunction, which is
whatever the current module's block offset is.

Revised proposal:
* FbleExecutable: (subclassed for user data) DONE
    size_t num_args
    size_t num_locals
    size_t num_statics
    FbleBlockId profile_block_id
      (relative to profile_block_offset passed to FbleNewFuncValue)
    FbleRunFunction* run_function
    void (*on_free)(void*)
* FbleExecutableModule: DONE
    ...
    FbleExecutable* executable
      assert that num_args is deps.size
      assert that num_statics is 0
    FbleNameV profile_blocks;
* FbleValue* FbleNewFuncValue(
    FbleValueHeap* heap,
    FbleExecutable* executable,
    FbleBlockId profile_block_offset,
    FbleValue** statics)
* FbleExecStatus FbleRunFunction(
    FbleValueHeap* heap,
    FbleThread* thread,
    FbleExecutable* executable,
    FbleValue** locals,
    FbleValue** statics,
    FbleProfileId profile_block_offset)

Note: it's not weird that the same FbleExecutable can be used with different
profile block offsets: because we want a static value for FbleExecutable that
can be reused with programs that have different sets of modules. This all
makes sense.

Good. We have a clear proposal. I like the proposal. Next steps are to
implement it. How so? What changes do we need to get there?

* Rename fields and update documentation.
* Move profile_blocks from FbleExecutable to FbleExecutableModule.
* Change signature for FbleRunFunction.
* Remove FbleSimpleFunc* API.
* Make FbleStack private.
* Make FbleThread abstract.

Nifty. Let's get to work.
            
---

I'm going to revert back to switch statement in the interpreter, because it
will be cleaner and easier to get rid of references to FbleStack. For the fun
of it, let's see how much it effects performance. It's tough for me to
predict.

Before change:
* /Md5/Bench%: 1m23.615s
* /Sat/Bench%: 2m1.172s

After change:
* /Md5/Bench%: 1m12.535s
* /Sat/Bench%: 1m48.365s

Yeah, so, there you have it. Cleaner, simpler, faster code.

Looking at git history, looks like even when I first made the change from a
switch statement to functions resulted in a performance regression of a few
seconds. Oh well. There you have it.

---

Next goal: make FbleThread abstract. But I think this one will be trickier.
Where we need to know it:
* For thread->profile, used in Profiling functions.

That's not too bad. Shall we just create some FbleThreadProfile* variants?
* FbleThreadProfileSample(FbleThread* thread)
  - FbleProfileSample(profile, 1) if profile and rand() % 1024.
* FbleThreadProfileEnterBlock(FbleThread* thread, FbleBlockId block);
* FbleThreadProfileReplaceBlock(FbleThread* thread, FbleBlockId block);
* FbleThreadProfileExitBlock(FbleThread* thread, FbleBlockId block);

That's actually perfect. Central logic for profile sampling, and don't have to
worry if profile is NULL or not. That's taken care of internally.


