Performance Refactor:
* Hypothesis: when using a let, we end up walking the entire graph of newly
  allocated objects for each binding. If there is recursion in the binding,
  we'll end up traversing the same graphs over and over and over and over
  again. It will be very bad.

  How to make this better:
  - optimize cycle detection (ref.c:349) so it isn't stupidly slow for large
    graphs.
  - add logic in the compiler to detect if this is a recursive let. If it is
    not a recursive let, don't update the dummy ref value, so we avoid having
    to traverse the newly allocated value.

  We should be able to confirm the problem with code such as:
  (Int@) { List@; } BigList = (Int@ n) {
    ?(n;
        0: EmptyList,
        S: {
          List@ tail = BigList(n.S);  # Requires traversing the whole list!
          Cons(n, tail);
      });
  };

  Note that the non-let variant should not suffer this problem:
  (Int@) { List@; } BigList = (Int@ n) {
    ?(n;
        0: EmptyList,
        S: Cons(n, BigList(n.S)));
  };

  Evidence:
  - Md5 benchmark improves by 8 seconds switching from let to anonymous struct
    import in fulladd.
  - A stack-smasher based test shows 28 seconds versus .2 seconds. Yup. This
    is definitely something big.

* Optimize Md5
  Program profile says:
    79% Bit2XN.add (24% Bit1.add, the rest recursion)
    11% Bit2XN.and (16% Bit1.and, the rest recursion)
     6% Bit2XN.or  (16% Bit1.or, the rest recursion)
     4% Bit2XN.not (24% Bit1.not, the rest recursion)
   Which I can totally believe. But the program code is fine for those, and the
   algorithm is fixed, so the rest belongs to the fble implementation.
  - ref.c:349 code coverage says this loop is executed a ton. Looks like a
    set contains kind of operation that could be made much more efficient?
    perf profiling also points to this line as a big contributor.
    This is checking to see if we have visited the node already or not, and
    recording the node's incoming reference for later.
  - it looks like we are creating quite a few function thunks. Is that
    expected? Any way to figure out which functions those are?
* Optimize TicTacToe
  - Wall clock time for RunAI.just looks funny. 14 seconds are spent in that
    block, when it looks like it should be a trivial block. What's up with
    that? Same with ChooseBestMove.nothing. It looks trivial, but a
    significant portion of the time in the block seems unaccounted for.
    Perhaps we loose stack frames in the profile when executing processes?
* Optimize Sudoku
  Program profile says all the time is spent in List%.Append for AppendXS.
  Program optimization brainstorm:
  - More efficient AppendXS implementation for constraints.
    This should be easy.
  - Reduce the number of constraints we generate total.

* Consider factoring out code in compile.c for computing modeled profile time.
* [perf] figure out how to use 'perf' for profiling
    perf record --call-graph dwarf [COMMAND]
    perf report -g folded,address
  - 'folded' seems to be the most useful. For each function, it gives the
    total time spent in that function broken down by call chains from the
    function. Use 'folded,callee' to break down functions by who called the
    function.
  - you can run perf record --call-graph dwarf -p <pid> too, to profile an
    already running process.
  - you can add '-d' to perf record to save addresses, then 
    perf report -g folded,address to list line numbers, which is pretty cool.
    Add "0.1,0" or even smaller to set the threshold and unlimited number of
    lines to get more information.
* Consider using put and get to synchronize EXEC processes rather than JOIN?
* Figure out why time profile says md5 is so much longer than tictactoe while
  wall profile says tictactoe is much longer than md5.
* Figure out why the Md5 cls optimization cut wall time by a factor of 1000,
  but profile time only by a factor of 3.
* Add an option to automatically determine performance model parameters based
  on wall clock time profiling of benchmarks.
* Ensure the implementation satisfies the performance spec. Add perf spec
  tests as necessary to catch bugs.
* Figure out why the tictactoe AI was 4 times faster when using a process
  computation instead of a pure computation, even though fble level profiling
  and common sense suggest it should be the other way around.
  - I wonder if it's because exec is non-recursive and let is recursive, thus
    introducing lots of reference cycles, which take much longer to retain and
    release?
  - A good way to figure this out would be look at code coverage line counts
    before and after.
* Figure out why it takes longer and much more memory to insert 5000 entries
  into the TicTacToe MemoTable directly rather than compute all the entries
  from scratch. Seems funny.
* [build] move 'perf' logic to build.fble.tcl
* [perf] Optimize FbleRefAdd
* [perf] Store scope size as part of InstrBlock and use an array for vars.
 - replace all AddToVector callbacks in ref.c if feasible.
* [perf] Eval in compile.c is called a ton. Shouldn't we only need to call
  eval after a let binding? Can't we use subst or other eval-by-construction
  for everything else?
* [clean] Tracking of time in the compiler is really messy
  Especially that we extract the pointer to the time field from NewBlock by
  assuming what NewBlock does. Figure out some way to clean this up.
* Document the runtime memory model,
  - Including that tail recursive functions should not smash the stack.

Miscellaneous:
* [clean] Can fble-stdio check that the function has the right type?
* Better error messages on types that have the same name but different values.
* Write man pages for fble and friends?
* Rethink arenas and documentation, because some cases appear to assume you
  have a bulk-free arena. Other cases its not well specified what is freed
  explicitly and what is expected to be freed implicitly.
* Better error message when the difference between a type is accidentally
  defining + vs. *, and it contains substituted polymorphic type variables.

  I claim a good model is: pass an arena to a function to say: the function
  allocates its result in this arena. The function creates and uses a separate
  arena for its intermediate allocations.
* Make child thread execution fair.
  Children should be time multiplexed, where priority is assigned based on how
  far down the family tree the child belongs. The amount of time a family gets
  to spend evaluating should be independent of the number of children in the
  family.

Future:
* Implement compiler to C. Idea is translate a function body into a sequence
  of commands like we have in the current interpreter. Split the command
  sequence into blocks any place there is a function call. Gather up all the
  blocks of all the command sequences in the program, give each a unique name
  starting from zero, then generate a loop containing one large switch
  statement with a case for each block. Global state is a list of thread
  contexts. Thread context is a frame, which has variables, ports, the id of
  the block that currently needs to be executed, and a pointer to the frame to
  execute after executing this block.

* Implement compiler to hardware. Same idea as compiler to C: break up into
  blocks. Now each block can be its own hardware block. Frames are queued up
  at their block, all blocks can execute in parallel as inputs are available,
  and we can pipeline or duplicate the blocks to allow for even more
  parallelism.

* Implement an fble debugger. Features:
 - Set a breakpoint at a line in a file.
 - Step through code line by line.
 - Evaluate expressions in the context of the current scope and print the
   results.
 - Auto breakpoint at undefined behavior?
 
 Use cases:
 - Debug why sudoku solver isn't working properly by stepping through a line
   at a time and printing intermediate values.

   Turns out it wasn't too hard to figure out the problem in this case without
   a debugger.

Snake:
* Make food appear randomly instead of at the tail.
* Speed up the snake every time it eats something.
* Test and fix bug when snake eats its tail.
* Ignore moves that aren't orthogonal to current snake direction.
* Keep track of and report score.

Md5:
* Remove Bits cls implementation, as it is no longer used and not very useful.
* Improve performance of Bit2XN.add, though it's not obvious how.

Sudoku:
* Improve performance enough to make tests useful.
 - More efficient constraint set concatenation?
   The profile says all the time is spent in List%.Append, but I think
   something funny may be up with the profile.

Game of Life:
* live if
  A. is alive and have 2 or 3 live neighbors
  B. is dead and have 3 live neighbors

Space Invaders:
* Render objects - how to test?
  manual test: Draw all objects to the screen as a gallery of them.
* Game loop driven by timer - how to test? 
  manual test: Have app with just ship that can be moved left and right (and
  fire bullets into space?)
* Pseudo-random bullet attack, UFO - how to test?
* Collision detection
