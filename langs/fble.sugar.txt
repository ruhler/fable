Fble Syntactic Sugar
--------------------
Things that are clunky to do in fble syntax today:

1. String and integer literals
------------------------------
For example, we have from Md5:
  Bit32@ t01 = H8(d, 7, 6, a, a, 4, 7, 8);

I haven't even started using strings, because I assume the same:
  String@ hello = S5(h, e, l, l, o);

Ideally we have something more like:
  Bit32@ t01 = 0xd76aa478;
  String@ hello = "hello";

Note:
* ideal syntax supports arbitrary length. Today we have to define a
  constructor for every different length, which is not reasonable.
* ideal syntax has no separator between characters in the raw literal.
* elements of the literal are raw characters, not fble expressions.

Actual Uses:
* Md5 for Bit32 literals.
* String names and output descriptions for tests.

More generally: any densely packed raw information of arbitrary length where
explicit separators between units of information would lead to a significant
amount of overhead.

Proposal:
* Allow any kind of name with '...' and '...'@
Where ... is any sequence of characters aside from single quote. But we can
escape single quote with single quote using ''

For example:  'don''t use single quote'
And that becomes an atomic name.
* Allow string literal "...", which is any character except double quote. But
  we can escape double quote using "".

For example: "The double quote, "", is good to avoid"

You specify a struct s for decoding the string literal. The mapping is as
follows. For each character c in the string, you use the value of the field
s.'c'. Then you have two special pre-named operations:
s.cons, s.nil.

Thus: s"do, not." is desugared to:
  s.cons(s.'d',
  s.cons(s.'o',
  s.cons(s.',',
  s.cons(s.' ', 
  s.cons(s.'n', 
  s.cons(s.'o', 
  s.cons(s.'t', 
  s.cons(s.'.', 
  s.nil))))))))

Sounds good to me. Only questions are: the precise syntax to use, and whether
'cons' and 'nil' are the right names to use for the combination.

Fundamentally we want a way to describe an atomic sequence of characters in
the input program that may contain funny characters. These sequences of
characters are used for names and for string literals. Some, possibly nicer
ways of doing this:

* Allow raw escapes in the program:
    Foo\.bar
* Allow quotes, like in bash:
    'Foo.bar'
    Foo'.'bar
    ''

Using quotes is nice, because it lets you describe the empty sequence, and to
give a dense specification of some kinds of funny characters. We probably want
some form of escape characters regardless, for things like newline and other
non-printable characters. Perhaps it makes sense to just allow a combination
of the two. Then we have the following categories:

* printable non-syntax characters: [a-z_A-Z0-9], etc.
* printable syntax characters: [@[],{}+-()], etc.
* non-printable characters: \n, \xXXX, etc.

Then we add escape sequences for printable syntax characters: precede them
with a \. Then an escaped printable syntax character is treated just like a
printable non-syntax character. An escaped non-printable character is treated
just like a printable non-syntax character. And, within single quotes, a
non-escaped printable syntax character is treated like a printable non-syntax
character. And maybe we want a way to have non-escaped non-printable
characters be treated like printable non-syntax characters (like you can in
tcl using {} instead of ""), but who knows.

Then we could introduce a special syntax for string literals. Perhaps:
Concrete Syntax:  '~' name

Then you could do something like:
    { StrLit; ~'hello there';}
    { IntLit; ~1149;}

Anything better than '~'?

    { StrLit; ^ 'hello there';}
    { IntLit; ^ 1149;}

    { StrLit; % 'hello there';}
    { IntLit; % 1149;}

    { StrLit; ~ 'hello there';}
    { IntLit; ~ 1149;}

    { StrLit; `'hello there';}
    { IntLit; `1149;}

    { StrLit; "'hello there';}
    { IntLit; "1149;}

    { StrLit; '"hello there";}
    { IntLit; '1149;}

I like the last combination the best. Single quote to introduce a literal,
double quotes for the word quote?

"Foo.Bar"@ "foo.bar" := ...

It's too bad we can't pass these as arguments to functions. Like, it would be
nice to be able to do something like:

   Int('1149), or Str('1149)

Unless, in general, we say { x; y;} and x(y) are always treated as equivalent?
So that x(y) for struct value x means evaluate y in the context of the
namespace of x?

No. That doesn't make sense. I propose instead:

String literal: expr '|' word

For example:
  x.'foo,bar'
  IntLit|1149
  StrLit|'hello, there'
  Int|1149
  Str|'hello, there'

Where expr is a struct that will be used as the prefix to the desugared
string. This way literals are more contained. There's no need to want them to
be in the current environment. We can always capture a literal in an object
and put that literal in the environment just as easily.

I wish I could use '~' as the character, because Int~1149 and
Str~'hello, there' look quite nice to me, but that would conflict with the
link syntax. Oh well. Vertical bar is probably fine too.

Note: integer literals will be hard if the only operator we have is a cons
operator. In practice we want to do a fold with some intermediate state, and
the direction of the fold should be flexible?

How to express integer literals using monadic bind:

 1049:

{ S(1); M(0); M(4); E(9));

E :: Digit -> Int -> Int
E d x = 10 * x + d

M :: Digit -> (Int -> Int) -> (Int -> Int)
M d f x = f (10 * x + d)

S :: Digit -> (Int -> Int) -> Int
S d f = f d

More generally, it all looks like M, except:

E d x = M d id x
S d f = M d f 0

It's a reader monad. You supply functions from Int to Int and they are chained
together using a combination operator. Organized another way:

F = Sum([I(1), I(0), I(4), I(9))
x = F 0

I :: Digit -> (Int -> Int)
I d x = 10 * x + d

Plus :: (Int -> Int) -> (Int -> Int) -> (Int -> Int)
Plus a b = \x -> b (a x)

Which is just function composition. Given a list of digits, this is just a map
and fold. But to get the final number you need to provide the initial value 0.
This means you need to specify two things for the literal: how to map from
name to digit, and how to combine the digits in the end.

For the purpose of the literal, we could say the digits are already the
functions:

  4 = \x -> 10 * x + 4

Another option would be to change the literal syntax to:

  | word

Where we would desugar "|abcd" into:
  ... that's where it breaks down. We need to provide a type for the elements,
even if we could otherwise hard code the list type for the sequence.

New Proposal:

A string literal is a list literal with additional data. A struct with the
following fields

 '?' - a struct with fields of type E@, each field a single char word.
 '(' - a function L@ -> T@ to convert the completed list to desired end value.
 ',' - a function E@ -> L@ -> L@ to cons an element to the list.
 ')' - a element L@ representing the empty list 

S|"abc" is desugared to list literal syntax:
  S(S.'?'.a, S.'?'.b, S.'?'.c)


2. Lists
--------
Today we have:
    S9(a, b, c, d, e, f, g, h, i);
or: A(a, A(b, A(c, A(d, ...))))

Ideally we have something more like:
  [a, b, c, d, e, f, g, h, i]

Note:
* ideal syntax supports arbitrary length.
* ideal syntax lets you add something in the middle of the list without having
  to change anything at the beginning or end of the list specification.
* elements of the list are expressions.

Actual Uses:
* When forming lists of test cases for a test.

Proposal:
* Ideally we get something for free when we work out the proposal for monadic
  syntactic sugar. But unfortunately, I fear something like:
  {T a; T b; T c; T d; T e; T f; T g;} is a bit too tedious still.

* Or, hard code a list literal for a specific type and let people convert from
  lists? I'd rather avoid hard coding anything for a specific type if
  possible, because presumably there are more general and flexible ways of
  doing such things.

  Perhaps something more fundamental is something based on induction. You
  provide an inductive case and some base cases, and it matches whatever it
  can for inductive and base cases. Maybe we want to allow the base case to
  require 4, or 3, or 2, or 1 args rather than assume the base case works with
  0 args. For example, for a non-empty list literal.

My vote is to keep things relatively simple and just desugar a list literal:
    [a, b, c, d, e]

To function calls with an expected name:
     \,(a, \,(b, \,(c, \,(d, \,(e, '[]')))))

In other words, pick a name for the cons function and a name for the nil
value, where the proposed names here were ',' and '[]'.

Question: does this work with type parameterized lists? You kind of wish you
could automatically infer the type of the list rather than have to explicitly
specify it. I guess you could always do:
  { @(',': ConsS<Foo@>, '[]': S0<Foo@>); [a, b, c, d, e]; }

or:
  { List<Foo@>; [a, b, c, d, e]; }

Which isn't too bad? Except it is a little sad to have everything done by name
lookup without concrete type checking?

We can do the exact same for string literals:
  ~'hello' desugars to:
  \,(h, \,(e, \,(l, \(l, \(o, '[]')))))

Maybe ',' and ']' would be good names to pick, corresponding to the sugar
a, b, ..., ]?

New Proposal, to go along with string literals and allow nice support for
variable length argument functions:

A list literal is defined using a struct with the following fields:

 '(' - a function L@ -> T@ to convert the completed list to desired end value.
 ',' - a function E@ -> L@ -> L@ to cons an element to the list.
 ')' - a element L@ representing the empty list 

Assuming l is a struct of such type, an expression l(x, y, z) is desugared to:
  l.'('(l.','(x, l.','(y, l.','(z, l.')')))))

There is still some question as to how strict to be when checking the type of
l in terms of checking for no extra fields and proper types ahead of
desugaring.

Amendment: 

Actually, it might be nice to allow different types of initial arguments. For
a more true var-arg function. That's not hard to do. Just allow any number of
arguments to the '(' function, where only the last arg is the variable length
part. For example, this way you could define a non-empty var-arg list
function: P(x, y, z);

The justification for the literal is that functions are really valuable
because they allow you to define your own syntax, and that syntax should
support variable length args in parens.

Note one consequence of the var-arg syntax is it is possible to define
no-argument functions. For example, the empty list: S(). I'm not sure if that
has any implications.

Proposal for type checking: I vote we want to limit the object's use to the
literal, so it's clear it is intended to be used as a literal. But allow the
same object to be used for list and string literals. Then we have type
checking:

'(' must exist, it defines types L@ and T@. And also has args A@, B@, ...
',' must exist, it defines type E@ and must match L@.
')' must exist, it must match L@.
'?' may optionally exist. If it does, all fields of it must have type E@.

Type check then requires args: A@, B@, ..., E@, E@, ...; producing a type T@.

For a string literal, the '?' requirement changes to "must exist". 

Because of the type requirements, this is more than syntactic sugar. It should
be given its own entry in the abstract syntax. The name of the construct?
struct_apply? For string literal... literal or struct_literal?

Or, func_apply_varargs, func_apply_literal?
Or, vararg_apply, literal? Yes. I like these.

Question: Can we do over-application of vararg functions?

For example, imagine mkLit(x, y) returns a literal. So we could do:

  mkLit(x, y)(a, b, e1, e2, e3);

Could we also write:
  mkLit(x, y, a, b, e1, e2, e3);

If so, perhaps we don't need to special case the separate kinds of initial
arguments? But then, how do you explain multi-arg using the single application
syntax? Because I should be able to do something like:

  mkLit(e)(e)(e)(e) ...

And then it's not clear when we should close the varargs. For example, what if
the literal returns a function that takes an element of type E? How would we
distinguish whether the element goes as a vararg or as an argument to the
computed function?

It almost seems like what I want is some kind of thing we can use as a value
or stuff an extra arg into, from the type perspective. Could we explicitly
distinguish the two using some kind of syntax? For example:

  List :: ListLiteral
  List(a) :: ListLiteral

  ListLiteral = (E -> ListLiteral)
 
But then, how to get the list from it?
  List(a)(b)(c)(d)$
  List(a, b, c, d)$
  List(a, b, c, d)$

Say we had some syntax, given a literal, that finishes that literal, such as 
  expr '$'

Though we'll probably want a different syntax. It would have to be something
at the end. It forces the application.

Well... we could use close paren to do that. Say that close paren terminates
the list literal, so you have to use the multi-arg syntax to give everything
in the list literal. How does this change things?

* No initial args needed. You can make those arguments to a function that
  returns a literal.

It's almost like we want to flip things around. List represents a partial
constructed list literal. Then you have three things:

1. The initial empty literal value. For example, the empty list. '('
2. A way to append a value to the literal. For example: append to the list.  ','
3. A way to extract the literal. ')'

I suppose it's the same. It doesn't matter if you go left to right or right to
left. Except I'm proposing to no longer make it a syntactic sugar?

But if you can set up an initial literal, with mkLit(a, b), then appending to
that literal to produce another literal is like adding multi-args to it. That
suggests I really want

1. An initial literal value (any partial list literal). For example, a list of
elements.
2. A way to treat the literal value as a function.
3. A way to treat the literal value as a value.

But you can already treat the literal value as a value, right? So maybe what
we want is:

A user defined value of type L.
A function F of type L -> E -> L.
A function T of type L -> T.

T(F(F(F([], a), b), c))

But in this case, T, F, and the intermediate value L define the literal.

l1 = []
l2 = l1.F(l1, a)
l3 = l2.F(l2, b)
l4 = l3.F(l3, c)
l4.T

Or, we just have two functions: the function to generate a new literal, and
the final value of the literal.

Literal = *(A -> Literal, Value)

Then desugared we sould have something like:

List([]).F(a).F(b).F(c).T

Or...

List([]).S(a).S(b).S(c).Z

Which clearly shows the inductive nature of the multi-arg function.

@ L@ = *((A@ -> L@) S, T@ Z)

It sucks to have to compute all the intermediate final values.

It's too complicated. From a syntax point of view, if you want to mix
functions and list literals, we have to make multi-arg application a first
class citizen, otherwise you can't distinguish between:

     mkLit(a, x1, x2, x3)(x4, x5, x6)
and  mkLit(a, x1, x2, x3, x4, x5)(x6)

Assuming mkLit returns a different list literal object.

New proposal:
Introduce a special syntax for list literals and use that instead of vararg
functions. For example: f(a, b, [x1, x2, x3, x4]) instead of
f(a, b, x1, x2, x3, x4). For list literal [a, b, c, d], all args must have the
same type T. Then the type of the list literal is:

   @ S@ = +(P cons, *() nil),
   @ P@ = *(T head, S tail),
   S@;

With possible different choice for the field names.

For string literal, you provide a struct value that has two fields. For
example, for an octal literal:

@ Digit@ = +(*() 0, *() 1, *() 2, *() 3, *() 4, *() 5, *() 6, *() 7);
(List<Digit>){ Number; } Literal = ...;
@ Lit@ = (Letter@: Digit@, Literal: Literal);

Where, again, the names of the fields 'Letter@' and 'Literal' are up for
debate.

String literal becomes syntactic sugar:
  <expr>|"abc" ==> 
  let s = <expr>
  in s.Literal([s.a, s.b, s.c])

The good parts:
* No confusion about multi-arg application.
* List and string literals become true syntactic sugars that can be handled at
  parse time instead of type check (though we may want to handle in type check
  any way for better error messages and more strict checking).

The bad parts:
* Introduces hard coded types into the language, including a recursive one
  that's perhaps not trivial to describe.
* How do we pick the names for these hard coded list and literal types?
* The need for a let expression to avoid repeated evaluation of the argument
  to a string literal when we desugar it. Unless we can evaluate the list
  literal in the back end?

Brainstorm of variations:

Could we make list literal and string literal first class citizens, so they
have their own kind of type? For example, a list literal can be described as a
pair of functions that take an input element type and return a resulting type.

  [T@]{L@} List = EmptyList, (T@ x, L@ l){ cons(x, l); };

This says: List is a list literal for elements of type T@ that produces a list
of type L@. The body of the list literal gives a pair of the empty list and
the cons function. We just need some syntax to distinguish list literal
literals from other kinds of expressions. Now you could use the list literal
as:

  List[a, b, c, d]

And for string literals:

 |01234567{Octal@} OctalLiteral = |(0: ..., 1: ..., ...), OctalDigitList, (OctalDigitList@){...}

In other words, the type of the string literal describes the set of legal
characters, and the value of the string literal literal defines the value of
each legal character, the list literal to combine those into a list, and the
function to turn that list into the literal value. Then you could use it as:
  
  OctalLiteral|"132"

It's a bit heavy weight syntactically, but now at least everything is very
explicitly and clearly typed. Rather than trying to encode things awkwardly
into struct values. And we don't have to make up or use hard coded types
anywhere.

I wonder if we could simplify by doing:
* Pass an arbitrary type to list literal, and it will construct by field
  position rather than name. For example: List[a, b, c] becomes:
  err... doesn't quite work given that a list type involves two mutually
  recursive types.

* Be able to define a union type using |01234567. Then a string literal need
  only specify the type |01234567, a list type, and the combining function.

Better Approach:

List: [<expr>, <expr>, ...]
  Given a list of expressions of the same type T@, returns a polymorphic
  function of type:
      <@ L@>(L@, (T@, L@){L@;}){L@;}
  In other words, a function that, when given an initial list and a way to
  prepend individual elements to the list, returns the given list with all the
  elements prepended.

  So the expression: [a, b, c, d] would turn into something like:
    <@ L@>(L@ nil, (T@, L@){L@;} cons) {
        cons(a, cons(b, cons(c, cons(d, nil))));
    }

  The advantage of this approach:
  * We don't have to build a list type into the compiler. Any list type you
    want that supports an initial value and prepending a value works.
  * The list syntax is standalone: you don't have to provide any additional
    information. This makes it easy to make abstractions for it that don't
    have to reveal internal details.
  * We don't try to embed some complex object into a struct value.
  * We don't have to worry about how to evaluate an object and share it. Aside
    from picking variable names for the function arguments, this could be a
    pure syntactic sugar if desired (though I don't recommend it).

Literal: <type>|<word>
  Given a type of letter and a word, returns a list of the letter in
  the word. The type must be a union type with single-character field names
  that take *() arguments. This type describes the type of a letter.

  For example,
    @ Octal@ = +(*() 0, *() 1, *() 2, *() 3, *() 4, *() 5, *() 6, *() 7);
    Octal@|132

  The literal is syntactically desugared to:
    [Octal(1: *()()), Octal(3: *()()), Octal(2: *()())]
  
  Because this is turned into a list, it will have a polymorphic function type
  that accepts a prepend function and tail list.

  It is a compilation error if the word contains a letter for which there is
  no corresponding field in the letter type.

  Advantages:
  * We don't try to embed some complex object into a struct value.
  * We don't have to worry about how to evaluate an object and share it. This
    could easily be made into a pure syntactic sugar.

  Disadvantages:
  * We end up hard coding the type *() in the compiler. But that's not so
    unreasonable a thing. Perhaps we ought to use it for put processes too.
  * You have to specify a type in the syntax, which means you can't fully
    abstract away conversion of the literal to a value. For example, you
    probably end up writing things like:
      HexInt(Hex@|00ffffff)
    instead of the simpler:
      HexInt|00ffffff
    But I think this is a fundamental requirement as long as we don't have a
    single built in letter type.

Awesome! Let's go with that then and see what problems we run into. I think
this will be a great improvement on what we have today.


3. Traversals
-------------
Today we have:

func ChooseBestMove(Board b, Player x; Position) {
  MaybePositionResult ul = MoveResult(b, x, Position:UL(Unit()));
  MaybePositionResult uc = MoveResult(b, x, Position:UC(Unit()));
  MaybePositionResult ur = MoveResult(b, x, Position:UR(Unit()));
  MaybePositionResult ml = MoveResult(b, x, Position:ML(Unit()));
  MaybePositionResult mc = MoveResult(b, x, Position:MC(Unit()));
  MaybePositionResult mr = MoveResult(b, x, Position:MR(Unit()));
  MaybePositionResult ll = MoveResult(b, x, Position:LL(Unit()));
  MaybePositionResult lc = MoveResult(b, x, Position:LC(Unit()));
  MaybePositionResult lr = MoveResult(b, x, Position:LR(Unit()));
  MaybePositionResult best = 
    ChooseBestMaybePosition(
      ChooseBestMaybePosition(
        ChooseBestMaybePosition(
          ChooseBestMaybePosition(ul, uc),
          ChooseBestMaybePosition(ur, ml)),
        ChooseBestMaybePosition(
          ChooseBestMaybePosition(mc, mr),
          ChooseBestMaybePosition(ll, lc))),
      lr);
  best.Just.position;
};
 
Nicer would have been:
  Best $ do
    Pos@ p <- positions();
    MaybePositionResult pr <- MoveResult(b, x, p);
    ...

Or for sudoku we have:
    InitialRowConstraints(s1(), input.s1,
    InitialRowConstraints(s2(), input.s2,
    InitialRowConstraints(s3(), input.s3,
    InitialRowConstraints(s4(), input.s4,
    InitialRowConstraints(s5(), input.s5,
    InitialRowConstraints(s6(), input.s6,
    InitialRowConstraints(s7(), input.s7,
    InitialRowConstraints(s8(), input.s8,
    InitialRowConstraints(s9(), input.s9,
      S0<Constraint>())))))))));
  };

We want:
    row <- AllSymbols();
    col <- AllSymbols();
    cell <- input[row][col];  # guards on Maybe type
    EqConstraint(CellId(row, col), cell);

Or:
    for (row : AllSymbols) {
      for (col : AllSymbols) {
        for (cell : input[row][col]) {
          ...

Proposed syntax today is bind:
  Foo@ x <- f;
  body;

Which is sugar for f((Foo@ x) { body; })

Note some alternatives:
* Monads in haskell: you don't specify the combining function on each line,
  but have a single combining function for a sequence of statements. This way
  you could easily describe a list: List { a; b; c; d; e;}

  But we know there are issues with monad composition. So maybe that's not the
  best approach.

Another example came up. Given a list of tests, we want something like:

  List<TestName@> fails;
  for (T : Tests) {
    Print(T.name);
    Result r := T.test;
    if (r.fail) {
      Print("failed");
      fails.append(T.name);
    }
  }

There are three parts:
1. traversal - iterating over all elements in Tests.
2. body - the function to actually apply.
3. combination - to collect the failing tests into 'fails' as output.

The current proposal for bind gives traversal and body, but doesn't help with
combination. If we used a monad, the assumption is that traversal and
combination are the same data type. It's easier to specify, but less general.
Is there an easy way to describe the combination here too? You could add it to
the traversal I suppose:

List<TestName@> fails = {
 Test@ T <- forEachM(tests, catMaybes);
   Print(T.name);
   Result r := T.test;
   if (r.fail) {
     Print("fail");
     Just(T.name);
   } else {
     Nothing;
   }
}

Where the type of forEachM is:
 [a] -> ([b] -> c) -> (a -> b) -> c 

That makes sense, right? Or maybe:
 [a] -> (b -> b -> b) -> (a -> b) -> b

So you are given a list of elements a, a way to turn each element a into a b,
and a way to collapse all the b together into a single element.
  
Or make it another argument to the function? Provide the accumulation so far
to the body? Or a function to finish the accumulation?

 [a] -> (a -> b -> b) -> b

List<TestName@> fails = {
 Test@ T, List<TestName@> fails <- forEachM(tests);
   Print(T.name);
   Result r := T.test;
   if (r.fail) {
     Print("fail");
     ConsS<TestName@>(T.name, fails);
   } else {
     fails;
   }
}

Maybe I just need to be creative using the existing syntax options to start.
  
Practical Uses:
* tictactoe, sudoku, etc.

