Modular Compilation
===================
Goals:
* Avoid having to read implementation details just to get the type of a
  module.
* Allow shipping a module in binary form without full source code available.
* Allow implementing a module in C directly, see os_io.txt.

Proposal:

1.
Add special let syntax for defining a variable with no value. Just don't
provide a value. 

For example:

Int@ x;

It uses the <type> form of let, not the <kind> form. Semantics are to give a
runtime error saying x is uninitialized. Intention is to be able to describe
types without the implementation. Now we can provide .fble files for reading
the type from, as long as you don't try to interpret or compile that .fble
file itself.

2.
Add option to compiler to pass a separate implementation file. In this case,
the compiler compiles your implementation file. It still reads the .fble file
from the expected path, and uses that to verify the type of your
implementation file.

The idea is: you compile your private implementation file, and you distribute
the public header file.

No need for .fble vs. .fble.@. Everything is .fble.

3.
Need a way to find and load a compiled .fble file on the fly. For example,
someone ships a .so with their compiled code, and you want to run it with your
fble-stdio app.

---

See foreign_function_interface.txt for many related thoughts.

My latest thinking is:
* '?' '<' <type> '>' as concrete syntax for an undefined expression.
  Use this to be able to write .fble header files.
* When reading a .fble for types only, have the compiler be smarter about only
  loading dependencies needed to get the types.
* You distribute a package with optional libfble-<pkg>.so file and .fble
  source. Types are read from the .fble files. We always load the
  libfble-<pkg>.so file if we can. If it defines a module implementation,
  prefer that. Otherwise fall back to the .fble source code and interpreter.

Some scenarios:
* Pure interpreted - you ship the full .fble source. Your package is
  interpreted.
* Binary only - you ship a libfble-<pkg>.so with compiled code, and .fble
  source with ?<...> for all the implementations to provide the type info and
  documentation.

If you wanted to, I suppose you could implement your own fble compiled module
directly in native, rather than have any .fble source code. Note this is a
different approach from FFI. You would present an FbleGeneratedModule, rather
than an FbleFFIFunction.

Now that I think about it, let's use the FbleGeneratedModule approach for FFI
rather than add FFI to the language. In that case, what do we need to support
the FbleGeneratedModule approach in practice?

We should add the ?<...> construct to the language. That's so fble-compile can
compile code against precompiled modules.

Once we have that, in theory I can have two variations on .fble files for a
module: the actual source passed to the compiler, and the 'header' version.

How do I keep these separate in practice? What's a normal developer flow going
to look like? Honestly I like having them next to each other, named the same,
but with different extension. What would we call them? Would we rename them at
install time?

I think it's nice to make it obvious whether the code is a header file or full
source from the extension. So people know what to expect. We already have a
nice proposal for that: .fble for full source, .fble.@ for the type. Because
.fble.@ is a special funny kind of thing.

And now it's simple, right?

* When you load a module for its type, you look for the .fble.@ file first,
  then the .fble file.
* When you load a module for its value, you look for the .fble file.
* When you compile an fble module, you compile the .fble file, but also check
  the type against the .fble.@ file if it exists.

Bad things happen if the type of the .fble file doesn't match the type of the
.fble.@ file. Maybe that's one reason to prefer one over the other? If you are
shipping a .fble file, there is no reason to ship a .fble.@ file too. If you
aren't shipping a .fble file, you need to ship a .fble.@ file. Things can't
get out of sync if you don't ship them both.

We'll always have the possibility of the generated code not matching the
.fble.@ type, but that seems harder to mess up in practice.

Hmm...

Imagine we are shipping pure interpreted. Then locally all you have are .fble
files. Easy.

Imagine we are shipping binary instead. Locally you'll need both. At install,
you'll want just the header files.

If the compiler is looking for the header files, seems like you should name
the header files .fble. Name the implementation files something special. For
example, .fble.%? But that's weird to me. The main implementation of fble
should be called .fble, then header should be called something different.

Okay then, how about this:

.fble always used for full source.
.fble.@ always used for header.

If you ship just .fble, that's used for type and interpreter.
If you ship just .fble.@, that's used for type, no interpreter supported.
If you ship both, 
  For interpreter: use .fble for code, use .fble.@ for type, and verify the
  types match at runtime.

  For type, just use .fble.@.

In other words, .fble.@ is the source of truth for the type. If there is a
discrepancy, it's considered a bug in the .fble file, and we validate that
before loading and using the .fble file.

Summary of proposal:
* ?<...> syntax for undefined value, for use in .fble.@ files.
* .fble.@ file source of truth for type, if it is present. It will always be
  read if present.
* No change to fble-compile command line invocation.
* Developers organize their code as .../Foo/Foo.fble.@, .../Foo/Foo.fble.
  They can chose to install just the Foo.fble.@, the Foo.fble, or both.

After I make this change, I'll should be able to compile a libfble-<pkg>
library, then compile other code against it using a -I path that just contains
the .@ files, and have it work.

Is this all I need for the FFI case? For compiled code, I think yes. I can
manually write my own generated module code. Maybe we need some assumptions
about naming in the generated code. More on that in a second.

For the interpreted case, I want interpreted code to be able to load compiled
modules. We need some way to tell the Load function about pre-compiled
modules.

Today we have a way to tell FbleLink that the module we want to link is
compiled. Really what I want is to tell FbleLink the list of modules that are
compiled. For this case, we assume compiled code never tries to reference
interpreted code? Yes, because we generate the code to manually link via
direct reference to FbleGeneratedModule. Maybe we want to relax that
eventually, but I think it's fine to do that as an orthogonal project?

Good. So change the interface to FbleLink to pass a list of
FbleGeneratedModule files. Any time we try to load, first we check that list.
Fall back to the interpreter if it's not in there.

So, for example, FbleStdioMain will add to the list of precompiled modules
whatever you give plus any FFI compiled modules. FbleLink should double check
the type from the .fble.@ file. That happens implicitly in the interpreted
load of the .fble file that references the precompiled module.

Now, back to the question of exposing internal names. If I'm manually writing
my FbleGeneratedModule instead of relying on the compiler to generate it. The
challenge is, if A depends on B, and you compile A, we assume we know what the
name of the FbleGeneratedModule for B is. Can, or should, we not do that?

Here's my proposal:
* FbleGeneratedModule stores 'deps' as a module path instead of as
  FbleGeneratedModule.

It's that simple. Now, we load interpreted or compiled on a module-by-module
basis. The compiled code for A doesn't have to care if B is compiled or
interpreted, or what the name of the compiled code is for B if B is compiled.

What this does mean is we need to tell FbleLink about the complete list of
compiled modules. That's a pain. And we would need to know generated compiled
code names in that case regardless.

In a future world, it would be nice if FbleLink could dlopen to figure that
out. It's going to have to look for a libfble-foo.so file to load for the
compiled code anyway. If it can do that, it can look to see what's statically
linked as well, but, well, it shouldn't have to. In other words, it discovers
the list of compiled modules from the package search path. No need to tell it
things explicitly. I like that.

Summary of end vision:
* Ship libfble-foo.so with your package. FbleLink will look for it and load it
  to try and find compiled code first.
* Ship Foo.fble for FbleLink to interpret from if not compiled.
* Ship Foo.fble.@ to give source of truth type for the module.
* Compiled code for a module has FbleGeneratedModule type using a standard
  symbol name based on the module path. Each FbleGeneratedModule refers to the
  module path of any dependencies. It's FbleLink's job to locate and load
  those dependant modules.

Question on mapping module path to symbol:
* We could use a standard name mangling.
* Or, each .so file defines some standard init name that gives back the list
  of FbleGeneratedModule's that it provides.

Standard name mangling sounds fine to me. It's straight forward. It just means
we make the name part of the standard. Note this is a platform-specific part
of the standard, not tied to the fble language spec (though we could if we
want for practical reasons).

A separate list of generated modules seems ... well. dlsym can already do the
lookup. The dynamic symbol table is basically that. I don't know what
algorithm dlsym uses, but why not reuse that?

Name mangling seems straight forward. We would have to do it anyway, even if
we wanted some standard init name. Makes sense to me to do it at the module
level, not the package level.

But, if we are assuming some standard for module names, then no need, for now,
to change FbleGeneratedModule to list deps instead of generated modules.
Also, when would we be able to double check the type of the
FbleGeneratedModule is what's expected by the compiled code?

Fine. Now, can we try to put everything together into a coherent development
plan?

Phase 1: Link against a precompiled library without source.
* Add ?<type> expression.
* Add support for .fble.@ files.
  - When loading for a type, load that file if it exists instead of .fble.
  - When loading for a value, load that file if it exists in addition to the
    .fble, and very the .fble type matches it.
* Now, in theory, I could distribute just the .fble.@ files and the
  libfble-foo.a file and generated compiled code from it that works.

Phase 2: Use precompiled library from interpreted code, short term.
* Change FbleLink to take a list of FbleGeneratedModules to look in.
 - note: .fble.@ or .fble is required for type info.
* Now, in theory, I can manually write StdioIO and other FFI code and pass
  that in as part of FbleStdioMain.

Phase 3: StdioIO and AppIO rewrite
* Change return type from Bool to Int
* Pull StdioIO% out into a hand written module implementation.
  The native implementation should need no module dependencies.
* Rewrite the AppIO% API in whatever similar way makes sense.

Phase 4: Dynamic loading of package libraries.
* Remove FbleGeneratedModules list option to FbleLink.
* Have FbleLink look for and dynamically load .so/.dll files.

And beyond:
* Write my sockets module and http server.
* etc...

I do have the option to jump straight to Phase 4 instead of going via Phase 2.
We could even start with that, right?

For example, what if I have FbleLink try to load the generated module with
dlsym, and compare that with what is provided. If we can get that to work on
linux and windows, then we should be in good shape, right?

From some tests, it shouldn't be hard to make work on linux. We just need
something like:

  #include <dlfcn.h>
  void* dlFoo = dlsym(NULL, "Foo");

  -ldl

dlfcn isn't c99 though, meaning I would have to go back to platform specific
coding again.

If we aren't automatically loading the required library, then we need
something like the following first:

  dlopen("libfoo.so", RTLD_LAZY | RTLD_GLOBAL); 

Assume there is some windows magic to make the same thing work. How should I
proceed on windows?
* libfble-<pkg>.dll needs to be shared library.
* libfble.a could stay a static library, no problem.
* We need to track down libfble-<pkg>.dll files at runtime. I want to control
  the search path myself. If I had code in place for that, then this would be
  not so bad. I don't have to worry about annoyances of rpath.

What I would want is to update the FbleLink code to explicitly try to load any
and all libfble-<pkg>.so files during load?

The downside there is that we can no longer bundle all the code with a
compiled fble binary. We would have to install the libfble-<pkg>.so files
somewhere and track down where they are at runtime. But that's the whole
problem with using .dlls for those things on windows in the first place, so
that's probably expected.

On Linux, I can statically link a function into the executable, then make it
dlsym accessible with -rdynamic (and presumably related options). That's kind
of cool. It means we aren't forced to find symbols in separate .so files. We
can find them in the currently running executable too if we want.

One challenge is we don't know which package a module belongs to. We have a
search path. When do we load the .so file for a package?

Does it make sense to have one-to-one mapping from package name to .so file?
Maybe you want to spread an implementation of a package across multiple .so
files, or you want to bundle multiple packages into a single .so file?

Part of the challenge is getting the type info for a module. We don't care
today about the type of the main module or compiled modules we reference
directly. But if we are loading a module from a package, we'll want to double
check against the .fble.@ file? I suppose only if referencing it from
interpreted code. If referencing from compiled code, we'll already have done a
check and hope for the best.

Let's try and summarize how we can find code:
A. Embedded in the currently running executable.
B. In a shared library in the current working directory.
C. In a shared library in the same directory as the executable.
D. In a shared library on the runpath.
E. In a shared library on the package path.

Linux supports (D) for auto loading, windows apparently doesn't.

Well, I suppose we be flexible and do the best we can.

1. See if the module symbol is already available.
Allows for any preferred mix of (A), (B), (C), and (D).

2. For each package path in turn:
...

We need to be careful about the case when the compiled code shows up in
multiple places at once. And it would be nice to avoid dlopening the same
packages over and over. I worry about namespace collisions.

If we don't have to worry about collisions, I would say:

At the start of FbleLink, load all the .so files from the package path. Then,
when looking for a module, see if we loaded it yet or not.

Do we need to worry about security? Like, it's dangerous to load an arbitrary
.so file? Not sure what we can do about that. If you are providing the package
path with that directory, we need to be okay to open it.

I forget a little bit how the package path and module search path works.
Anyway, seems reasonable to start by loading every .so you find on the package
path, then search for modules in whatever you loaded.

Is that too expensive? We end up loading a bunch of code we don't need? How
else can we know what we need to load though?

You almost wish the module path told you the package it belongs to.

---

I remember how it works today. The main thing for finding modules is the
module search path, which is the list of root directories to search in. The
package search path gives you a way to easily add a package to the module
search path.

Stepping back, what are the problems I'm trying to solve here?
* Prevent different packages from defining the same modules.
* Define what .so files to load to find a particular module.

Today nothing prevents different packages from defining the same modules. This
could lead to collision. It gives a way to work around abstract type access
restrictions. That's not great.

How might we structure things differently?

Require all packages be installed to the same module root?
* But then we have no way to mix system and locally provided modules.

Commit to the first module root that has a prefix of the package path? For
example, assume package A provides /Foo/Bar% and package B provides
/Foo/Bar/Sludge%. If package A is on the path before package B, then when
looking for /Foo/Bar%, you find it in A and stop. When looking for
/Foo/Bar/Sludge%, you find /Foo/Bar% in A, then commit to looking there for
Sludge, you don't find it. If B is before A, then looking for /Foo/Bar%, you
see the path in B and commit there?

Does that help with the build dependency tracking issue we have with
fble-deps? Not entirely. You could still add a new module to an earlier
package in the search path that conflicts with something later.

Based on the system vs local idea, we need some way to provide multiple
arbitrary paths to module roots. We need to search those paths. I seem to be
suggesting that we want to enforce somehow that trees in these different paths
don't overlap in some way, or at least make it well enough defined that if you
have some path in A, you can't have some subpath of that path in B?

It would be nice if we can organize code where different subpackages are in
different directories. Let's look at some examples:

A provides /Foo/Bar%, B provides /Foo/Bar/Sludge%
* Ought to be disallowed.

A provides /Foo/Bar/Sludge%, B provides /Foo/Bar%
* Ought to be disallowed.

A provides /Foo/Bar%, B provides /Foo/Sludge%
* Ought to be allowed?

A provides /Foo%, B provides /Foo/Sludge%
* ??? Ought to be disallowed per above?

That suggest we look at .fble file availability. When searching for
/Foo/Sludge%, for each module root:
* Does this have /Foo%? If yes, commit to this package. If no, allow it to be
  in another package.

Another aspect to consider is how to link with libraries directly instead of
via the search path.

For example, I'm thinking of naming the .so files after the modules, not the
packages. Instead of libfble-core.so, have libfble-Core.so? Allow there to be
libfble-Core-Foo.so and libfble-Core-Bar.so?

Seems like we want the entire module path in the library name. We need a way
to convert the '/' in the module name.

Or, associate each package with a module path prefix. For the package
/Foo/Bar%, distribute it as .../Foo/libfble-Bar.so. To link against the
package, you list package directories in order: -L .../Foo -lfble-Bar.

We distinguish between empty directories - for organization, and directories
with a Foo.fble or Foo.fble.@ or libfble-Foo.so. As soon as we find one of
those in the package search path, we commit to that location for all
submodules.

Now, what if the same module is defined in multiple places?
* We have a well defined search path to tell us which to use.
* We load .so files using RTLD_LOCAL, keep track of the handles by name, load
  them as soon as we encounter a submodule, and look directly for the
  submodule in the loaded .so file.

In other words, submodule gives us a search path, we traverse from the root
and get a .fble or .so from a parent path. Look for the submodule there. If
not found, error out.

How about, use raw .so or .dll extension for a precompiled module? Like,
either we have Foo.fble, Foo.fble.@, and/or Foo.so. There is an option to the
linker to avoid the lib<...>.so name mangling. For example: -l:Foo.so 

The implications of this change are we now need to search the entire module
path, not just jump right to the end module. But that's true as soon as we
start bundling multiple modules into the same file, so that makes sense to me.

Good. We have a solid proposal now:
* Keep package search path as is for now, and the code organization we have.
* Keep module search path as is for now.
* When looking for modules, look for parents first, as soon as you find any
  parent, commit to the current module root for that module.
* Put .so files for a module tree in Foo.so where you would have had Foo.fble.

Now then, going back to how to organize the search code for a module:

1. Search in the current executable.
2. Search in already loaded .so files explicitly, we'll keep track of the
module tree for each loaded .so, so we know which one is the right one if any.
3. Search on disk, loading a .so and using it if appropriate.

Imagine we build some fble-foo executable. We can link it against module
libraries statically, and everything is fine (on Linux at least, assuming we
used export dynamic). We can link it against module libraries dynamically on
Linux, using rpath to find the .so files. What about Windows?

I expect the executable is installed to .../bin/ and called from an arbitrary
place. How can it find the .dll files it needs? Can I make it relative to
where the binary is installed?

Things to look into:
* SxS manifest redirection
* PATH - as a brute force, we could use this maybe.

Looks like SxS could work for us. We can compile it into the executable or
install it with the executable. It should be able to list for us where all the
.dll files are that it wants to load.

Note that the dlopen/dlsym equivalent on windows appears to be
LoadLibrary/GetProcAddress?

---

I have a clear vision now I think. How do I want to get there?

Brainstorm of tasks:
* Figure out how to use SxS on windows.
* Avoid hard coding .so vs. .dll in build system.
* Pass FbleGeneratedModuleV instead of FbleGeneratedModule* to FbleLink.
* Get fble building again on windows.
* Update search algorithm to commit as soon as parent module found.
* Add support for ?<...> construct.
* Add support for reading types from .fble.@ files.
* Add support for dlsym loading modules from the current executable.
* Add support for dlsym loading modules from Foo.so files.
* Change Stdio to return Int@ instead of Bool@.
* Move StdioIO to a custom implemented module.
* Move AppIO to a custom implemented module.
* Start an fble user guide doc to document these things in detail?

First priority should be to get the windows build working again. I just need
to decide how to do that. Some options:
* Learn about SxS, figure out how to use that to make .dlls work.
* Switch back entirely to static libraries.
* Switch just windows back to static libraries.
* Go straight to LoadLibrary/GetProcAddress support.

What I ought to do is figure out how to abstract away in the build system
whether a library being used is shared or static. Switch to that. Save the
code somewhere for switching to shared, but then go back to static. Or add a
switch, but I don't have a good way to test the switch, so doesn't seem like
the best approach.

Let's do this.

Step 1: Double check if we can use .so for  -l fble.cov, and if not,
understand better why not.

If we can, then no need to separate 'lib' from 'shared_lib' in the build
system?

/usr/bin/ld: ./test/fble-mem-test.cov: hidden symbol `__gcov_merge_add' in
/usr/lib/gcc/aarch64-linux-gnu/10/libgcov.a(_gcov_merge_add.o) is referenced
by DSO
/usr/bin/ld: final link failed: bad value

I don't know. I can't seem to figure it out.

gcc -std=c99  --pedantic -Wall -Wextra -Wshadow -Werror -gdwarf-3 -ggdb
--coverage -o ./bin/fble-disassemble.cov ./bin/fble-disassemble.cov.o
-Wl,-rpath,\$ORIGIN/../lib  -L ./lib -lfble.cov
/usr/bin/ld: ./bin/fble-disassemble.cov: hidden symbol `__gcov_merge_add' in
/usr/lib/gcc/aarch64-linux-gnu/10/libgcov.a(_gcov_merge_add.o) is referenced
by DSO
/usr/bin/ld: final link failed: bad value
collect2: error: ld returned 1 exit status
n

Which DSO is referencing this symbol? the only DSO it could be is
libfble.cov.so.

      8: 0000000000000000     0 NOTYPE  GLOBAL DEFAULT  UND __gcov_merge_add

That makes sense that it is trying to link to that symbol. For whatever
reason, libgcov.a says you aren't allowed to have a dynamic shared object file
do that. Okay, so why doesn't libgcov.a like that, and what should we do
instead?

It's because libgcov.a is a static library, not a shared library. Maybe I
would need libgcov.a to be a shared library installed on my platform?

The other option is to try and pull that into libfble.cov.so using magic
linker flags. Add the -static linker option. Doesn't work. Different error
about some other missing library.

Okay, figured it out. I need -lgcov or --coverage when building the shared
library. Let's try that route and see how goes.

---

How to make users of libraries agnostic as to whether they are dynamic or
shared?

We already have that for system libraries. -L ... -l... No need to care. The
difference for local libraries is we need to take dependencies on them, which
means we need to know their names.

The solution ought to be simple. Have lib return the name of the generated
library. Pass that around instead of the explicit name.

The only annoying bit would be spec-test.run.tcl. Can I remove those bit of
references? I ought to be able to.

---

Can we have all libraries built the same? Avoid the distinction between lib
and shared_lib?

Let me see what all the uses of those are today.

Everyone is using shared_lib today except libfbletest.a. Let's switch
libfbletest.a over to shared_lib. Then everyone will be the same. Then we can
rename it all back to just lib.

---

Next step is to abstract away the suffix of the library.

I see two ways we could go about this:
1. Pass directory, lib name, objs to lib. Return the path to the library.
2. Have a variable we pass everywhere with the name of the extension.

For whatever reason (1) feels cleaner to me. Let's try that route.

Libraries I'm building that I should properly reference now:
* 

hmm ...  libfble-$name.so is tricky to reference?

Also, installing the file becomes trickier: how do I know where to install it
to? There needs to be an easy way to get the name of a library. Easiest way
would seem to be, just have some $::lext?

---

Next question: do we really need an undefined expression as part of the fble
language?

The proposal was:

   ?<Foo@>

To create an undefined expression of type Foo@. The behavior is to report an
error when the expression is evaluated at runtime, and to have compile time
type Foo@.

But I can already accomplish that in the language, using, for example:

  /Core/Undef%.Undef<Foo@>.undefined

If I wanted to, I could write a helper function:

  Undefined<Foo@>

How to think about this question?

Things to think about:
* There is no way in general to prevent access of the wrong union field. There
  will always be a way to have errors in the language, without adding an extra
  syntax for it.
* ?<...> is not very descriptive from a code point of view. Alternatives could
  provide a string explanation. The Undef approach can communicate some
  information. A function that takes an error string more, but that would
  depend on the definition of a string type.
* Syntax is slightly clunky (see above) if we want to report the error message
  exactly where the error occurs. Because wrapping it in a helper function
  moves the origin of the error to the function body. This isn't a problem if
  we report the full stack of an error though.
* Use of undefined expressions ought to be rare, so a little extra syntax
  isn't an issue. We also shouldn't expect to execute in practice.
* You could imagine having an 'error' primitive in the stdio library.

All of which is to say, it's hard to find a compelling reason to add new
syntax to the language for something you can already do.

Here's what I suggestion: re-conceptualize .fble.@ files. Instead of thinking
of them as header files where values of things are marked ?<...>, think of
them as: this has the same type as the .fble module. Which is exactly what
they are. They needn't have the same structure.

Thus, I conclude: no need to add a new ?<...> syntax to the language. Good.
We just need to give some hints as to how to write .fble.@ files manually.

---

Next step in our journey is to support .fble.@ files for reading types from.
We need this before we can have interpreted code call into compiled code,
because we need some way to communicate the type of the compiled code to the
interpreted code.

We need to unify the FbleGeneratedModule and FbleLoadedModule types. Because I
want to be able to load an FbleGeneratedModule.

FbleLoadedModule:
  - module path,
  - list of (module path) deps
  - FbleExpr* type and value.

FbleGeneratedModule:
  - module path,
  - list of (generated module) deps
  - executable, profile_blocks.

The way we link these together:
* Loaded modules get compiled, which replaces type, expr with code and
  profile_blocks. We add the blocks to the profile and allocate a new
  interpreted function value from the code. To create the interpreted
  function, we create an FbleExecutable wrapping the FbleCode.
* Generated blocks get added to the profile, we create a new function value
  out of the executable.
  
---

How would I design loading and linking if I did it from scratch?

Consider sources and use cases.

Use cases:
1. Load something to get its type only.
 - fble-compile case, when compiling some other module.
2. Load something to get its bytecode.
 - fble-compile case, for the module being compiled.
 - fble-disassemble.
3. Load something for the purpose of executing it.
 - interpreter case for running code
 - running generated code

Source:
A. .fble.@ - for type information.
B. .fble - for source and/or type information.
C. .so/compiled in - for generated code.

Considering the combinations:
* 1A - want to load FbleType*.
* 1B - want to load FbleType*.
* 1C - not supported.
* 2A - not applicable.
* 2B - want to load FbleExpr*.
* 2C - not applicable.
* 3A - not applicable.
* 3B - want to load FbleExpr*.
* 3C - want to load FbleExecutable*.

Case (1C) looks wrong. It means we couldn't bundle a standalone interpreter
that is prelinked with compiled code, because we wouldn't have access to the
types of precompiled modules.

I've wanted in the past some way to validate types of modules passed to
fble-stdio and fble-app, for example. Maybe there is an appropriate solution
here to solve these two issues?

Let's assume I magically have a way to describe the type of a generated
module, so that 1C is now supported. How should things look?

Note that when I load something, I often (but not always) want or need to load
its dependencies too:
* To get the type of a module, I need the type of its dependencies.
* To execute a module, I need to be able to execute its dependencies.
* You could imagine a case at some point where I want a way to load bytecode
  for all modules, but that's not the case today. We only want to load
  bytecode for a particular module, and the types of all its dependencies.

This brings us back to a question I've had before: if we store the type as
part of the generated module, what's the point of having a .fble.@ file at
all? Here are some reasons:
* .fble.@ files serve as user documentation for the API to a module.
* It's easier to describe the type of a native module using .fble code.
* Error messages related to types will be easier to understand if there is a
  .fble.@ file to reference.

It's the conflict between those things saying a separate .fble.@ file is very
good to have, and the 'standalone' desire saying we want to avoid a separate
.fble.@ file.

I don't want compiled code to be able to depend on interpreted code, because
if you change the interpreted code's type, it's going to crash.

---

This is tricky because there are so many different corner cases.

The .fble.@ files could, in theory, have a different, conflicting, dependency
order from the .fble files. I don't know why you would do that. It sounds like
something to avoid. But nothing in the spec I have in mind prevents it.

This suggests to me we want to keep type and expr and generated code in
separate data structures when loading.

If I didn't care about duplicated work, I could structure like this:

1. Load the types of all the modules.
For each module, load an FbleExpr* for the type. Convert to FbleType* in the
compiler using a 'CompileForType'. You could imagine an optimization that
skips loading dependencies that are not necessary to compute the resulting
type. Mainly avoid going into the def of a let variable with an explicit type.

2a. If trying to compile a specific module, load the bytecode for that module.
Um... we may get a new set of dependencies we need to load for typing though.
That sounds problematic.

To compile a module or to evaluate its type, we need to evaluate the type of
everything it depends on.

To execute a module, we need to load all the modules it depends on in
dependency order.

Let's just list all the possibilities, and think about it in terms of the API
to load a single module versus to load a module and all its dependencies.

1. Load for compilation.
The main module:
 - Load .fble and, if it exists, .fble.@
 - Recursively load dependencies for both the .fble and .fble.@ for types.
 - Get the type from the .fble.@ (if it exists).
 - Compile the .fble to bytecode and get its type.

This gives us the following variations on recursive loading:
* Load all for types. Given a list of modules, loads them all and everything
  they depend on, but only for the purpose of evaluating the types of the
  modules. Prefers .fble.@ files. Falls back to .fble files if no .fble.@
  files present.
* Load for compilation. Loads the main module specially. Then calls 'Load all
  for types' on dependencies.

And individual module loading:
* Load for type. Loads just for the type. Prefer .fble.@ file. Fall back to
  .fble if .fble.@ doesn't exist.
* Load for compile. Load .fble file. Load .fble.@ file too if it exists.

2. Load for execution
- Load the main module, either generated or from .fble. If it has a .fble.@,
  we'll want to check the type of that too.
- If it's from .fble, for anything it depends on, load for type??
- For anything it depends on, recursively load for execution.
- Each loaded module is either a GeneratedModule or bytecode.

So we are adding the following variation on recursive loading:
* Load all for execution.

And the following variation on individual module loading:
* Load for execution. If there is a GeneratedModule, use that. I suppose
  simplest is always to load the .fble.@ type?

Anyway, we could start with individual module loading.
* Given module path to load, and the module search path.
* Input whether you are loading for Type, loading for Compile, or loading for
  execution.
* Returns path, deps, FbleExpr* type, FbleExpr* value, and
  FbleGeneratedModule* generated. The type, value, and generated are filled in
  depending on what was requested. Loading for type files in only the type.
  Loading for compile files in type and value. Loading for execution fills in
  type and either value or generated depending on what was found.

It's a little sad to add that false dependency of the compiler on code
generation. We could layer it in two parts. Load for type and load for compile
is the first part. We have a separate load for execution, which first tries
FbleGeneratedModule, then falls back to load for compiled if need be.

LoadForType - returns path, deps, FbleExpr* type.
LoadForCompile - returns path, deps, FbleExpr* type, FbleExpr* value.
LoadForExecution - returns path, deps, FbleExpr* type, FbleExpr* value,
  FbleGeneratedModule* generated. Or, returns FbleGeneratedModule* only,
  doesn't try to load the type. It's the caller's job to fall back to
  LoadForCompile if it can't find the generated module already. We do it that
  way just to simplify the return type instead of making it a union of
  FbleGeneratedModule* or  LoadedForCompiledModule*. If you load the
  GeneratedModule and still need the type, you can LoadForType from there
  instead of LoadForCompiled.

---

The first thing I want to accomplish is writing a StdioIO% module by hand.
I'll want to write a .fble.@ file and pass the hand coded 'generated' module
to FbleLink to link with. The assumption is we have interpreted code that
references the generated code. How can we get there?

FbleLink should gather together a list of compiled and generated modules that
it then links together. What type does it use for the list?

We want an FbleLoadedProgram*, that has the mix. The type checker can
typecheck that?

Review of the various kinds of programs we have today:
* Loaded: path, deps, FbleExpr* type, FbleExpr* value
* Typechecked: FbleTc*, currently a side data structure.
* Compiled: path, deps, FbleCode* code, FbleNameV profile_blocks,
* Generated: path, FbleGeneratedModuleV deps, FbleExecutable*, FbleName

When we compile a module, all we use are path, deps, and the FbleTc*. After it
is typechecked, we don't worry about FbleExpr* anymore.

So in practice, today we go:

path, deps,
    FbleExpr*                           Loaded
==> FbleTc*                             Typechecked
==> (FbleCode*, FbleNameV)              Compiled
==> (FbleExecutable*, FbleNameV)        Generated

Note there are two ways to go from FbleCode* to FbleExecutable*. One is via
generated code. The other is via FbleNewInterpretedFuncValue, which wraps the
FbleCode* in an FbleExecutable, and at the same time passes the FreeCode
destructor to the FbleValue* function value we allocate.

For generated modules, we don't manage their memory, we just assume they stay
alive as long as they need. For FbleCode*, we make sure it stays alive as long
as it needs, taking a refcount on the code.

Okay? I have a decent understanding of where things are now. How do I want
them to look?

---

Proposal:

FbleProgram* has, for each module:
  FbleModulePath* path;
  FbleModulePathV deps;
  FbleExpr* type;
  FbleExpr* value;
  FbleCode* code;
  FbleExecutable* native;
  FbleNameV profile_blocks;
  
When we load a program or a module, we tell the loader what we need from it.

After loading, a module can have one of the following states:
* type is non-NULL, all else NULL. This module is loaded solely for its type.
* type and value are non-NUll, all else NULL. This module is loaded for
  compilation. If type == value, the compiler can optimize and avoid
  recompiling that multiple times.
* type and native are non-NULL, all else NULL: This is a generated module
  whose type is also required.
* native is non-NULL, all else NULL: This is a generated module whose type is
  not required.

After loading a program, we pass it through the compiler. The compiler does
typechecking of everything needed, and converts the 'value' to 'FbleCode*' for
those modules with non-NULL value. We can continue to keep FbleTc internal to
the compiler.

It may be there are no modules which need compilation, in which case the
compiler pass will be effectively a no-op.

After a program is compiled, if you want to do something with the compiled
main code, go ahead. If you want to run the program, you link together
everything into a single FbleValue*.

We can still have FbleGeneratedModule and have it store dependencies to other
FbleGeneratedModules directly. We treat that as information needed to
initialize an FbleProgram*, copying over the deps, profile names, and
native FbleExecutable as part of the load step before linking the program.

Am I okay mixing all the phases of the program into a single type, or do I
want to split them? If I split them, how would I do that?

Three separate types, like we have now. We can treat Compiled and Generated as
the same, with just a type cast difference for FbleCode* versus
FbleExecutable*. The tricky part is when you load a module, you don't know if
you're going to get value or native. I suppose we load into two parts. The
type gets loaded separately from the native. But if the loader knows about
these things from the start, may as well combine the data structure from the
start. As long as interpreted code can depend on generated code, and the
loader is responsible for loading interpreted and generated code, it makes
sense for it all to be together in a single data structure.

Sounds like a plan. How to we get there?

1. Replace FbleLoadedModule and FbleCompiledModule with FbleModule.
2. Link generated via FbleModule.
3. Clean up and generalize loading of modules to allow for mixing of
interpreted and generated instead of having separate load paths for each.
4. Add support for .fble.@, etc.

While I'm at it, I might want to rename FbleGeneratedModule, because we'll
start writing them by hand. We could say, FbleNativeModule. I think that's
more descriptive.

---

FbleProgram could be kept internal if I have the right APIs. Let's review.

* FbleLink - already hides it in case of loading for execution.
* FbleCompile - could be added to load and compile right away.
* fble-deps is the only tricky part?

fble-deps is the case where we want to load without compiling. Hmm...

I don't know. Maybe that's too much change for right now. Start smaller?

---

I want to change FbleLink API. Instead of being either interpreted or
compiled, pass a module_path and a native_search_path so we can mix.

But a lot of code is assuming either/or right now. How should I update that?
For example:
* compiled header line is printed for compiled programs.
* We change arg parsing in case of compiled programs.

Consider something like fble-stdio:

In some cases we compile the module path in. In other places we want to get
that on the command line. Seems like I'm currently conflating two, now
different, things:
1. Is the program running with compiled code or not.
2. Is the module to run compiled into the program or not.

(1) isn't going to make sense for much longer. We'll have a mix of interpreted
and "compiled" code, because the builtin stdio API is implemented as native
code.

(2) still makes sense. And you could imagine mixing it with interpreted code.
For example, I create an fble-sat program that reads from the .fble file.
That's reasonable. It provides default arguments for the module. Not sure how
it's going to provide the module search path though... Use the default?

---

I'm not convinced it makes sense to change the standard main function API:
passing argv and a single optional FbleNativeModule. If we want to add builtin
modules, that should be part of the main function itself. Think of this main
function as an interface for the compiler to use to pass a single compiled
module.

So it makes sense to keep that API as is. No need to worry about header line.
I can jump straight to the internal API update.

The internal API update will be to FbleLink to start. It takes a vector of
native modules as the native_search_path. All else the same. Callers should
pass their single native module in the vector, in addition to any other
builtin native modules they want to make available.

---

The next step is to add support for .fble.@ files.

FbleLoad needs to know what it's being called for:
* From FbleLink: FbleLoadForExecution
* From fble-deps: FbleLoadForExecution for now. Needs more discussion.
* From fble-disassemble: FbleLoadForModuleCompilation
* From fble-compile: FbleLoadForModuleCompilation

Internally we'll want FbleLoadForType as well, but no need to expose that.

Eventually we'll want these load functions to take a native search path
argument. Don't worry about that right now.

---

Is typecheck all set up to support .fble.@ files? In theory I want it to use
the 'type' field for type checking, not the 'expr' field. Let's see what it
does today.

FbleTypeCheckProgram:
  We type check each module in tern. If it has a type, we type check the type.
  If it has a value, we type check the value. Then we double check their types
  match.

FbleTypeCheckModule:
  Type checks the program.
  
Issues with the current approach:
* We don't optimize for the case where type and value are both provided and
  are the same. I suppose load can indicate that by setting type to NULL? But
  that's not really what we want.
* We assume the same module arguments are required for the 'type' and 'value'
  expressions. This is a problem if the type has dependencies not in value,
  and we are compiling for execution.

What to do about those cases?

---

Easy:
* If something is loaded into the .type field, it is intended only to be used
  for type purposes. If something is loaded into the .expr field, it is
  intended to be used for execution. If both are available, we get the type
  from the .type field and double check against. expr. If only one is
  available, whichever one that is, we get the type from that field.
* For module dependencies, take the union of the .fble and .fble.@
  dependencies. There's no harm having unused dependencies, and it will make
  things simpler.

I claim the typechecking code already implements exactly the behavior we want.
Except, minor point: if both type and expr exist, we should return the type
from 'type', not from expr. That's an easy fix.

Next step will be to add support for loading .fble.@ files in FbleLoad. But
let me review first changes to the search logic I wanted to do, in case we can
simplify things. Recall from before:

* When looking for modules, look for parents first, as soon as you find any
  parent, commit to the current module root for that module.

When loading for type, we try .fble.@ first, then fall back to .fble. When
loading for execution, we try .fble.@, then we open .fble.

As soon as we find either .fble.@ or .fble file in the module search path, we
commit to that root. I can make that change first. I should document it
somewhere. And ideally test it?

---

Trouble: Say the first package in the search path has /foo/bar/sludge%, and
the next package in the search path has /foo/bar%. What should the behavior
be? I want this to be disallowed, but how can we reasonably discover it?

I think, don't worry about package search restrictions yet. We can do that
separately.

Then the next step is looking for .fble.@ files. The behavior we want in load
is:
* If loading for type: try .fble.@, if not tryp .fble for 'type'.
* If loading for exec: try .fble.@. Require .fble for 'expr'.

Two questions:
1. Can we update the spec tests to make it easy to test .fble.@ files?
2. How do we keep track of whether we are loading for type or for exec in
FbleLoad?

To properly test .fble.@, I would want:
* .fble and .fble.@ for execution, with types matching.
* .fble and .fble.@ for execution, types not matching.
* .fble.@ only for execution of that module: fails.
* .fble.@ only for compile of that module: fails.
* .fble.@ only for compile of other module: succeeds.

So, a couple features we want:
1. Be able to specify both .fble and .fble.@ for the same module path.
2. Be able to test 'compile only' of a module in spec tests.
Add: no-compile-error option: all it does is try to compile.
Or: Just runtime-error to say expect runtime error because module not found.
And distinguish between that and compile-error. I kind of like that. Good.

And for (1): great! We already read directly from .fble and .fble.@ files. No
more generating things from tcl. So we are good. We already support everything
we need.

But I need to update the language spec for .fble.@ files, right?

My desired changes to the spec:
* Ditch this notion of no Foo.fble meaning value is Unit@().
* Add a paragraph or so on .fble.@ files.

Cool. Let's get to it.

---

Next step is loading of .fble.@ in addition to .fble. Assume loading for
execution for now.

The way the loader currently works is:
* It calls Find to get the filename of the .fble file.
* It calls FbleParse to get the value and record dependencies.
* The main module uses a different block of code than dependant modules.

For first round, let's assume the .fble.@ file is located in the same
directory as the .fble file? No. In general I might expect them to be located
in different directories? Unclear. I don't have a good story at the moment.

---

Next step is to avoid loading .fble files for compilation if there are .fble.@
files. The code should be easy. The slightly more tedious part is adding
support for it in the test suite. I want a kind of run that is compile only
without error.

Currently I have 'no-error' to mean compile and run without error. How do I
say: compile only, expect no error? Let's summarize options:

  no-error: compile, evaluate, no error expected
  compile-error: compile, expect error
  compile-warning: compile, expect warning
  runtime-error: compile, evaluate, expect error

Running implies compiling. Ignore the warning part for now. Options are:

{compile, execute} * {error, no-error}. I'm only missing the compile-no-error
options. Can we come up with better names? Maybe:

  @@fble-test@@ compile-error
  @@fble-test@@ runtime-error
  @@fble-test@@ no-error

Hmm...

runtime-error is nice, because it says you get the error at runtime, not at
compile time. Rather than have to duplicate the test. I really just need a
better name for: compile only. Maybe:

  @@fble-test@@ compile

implies you only compile, and you don't expect an error? Sounds good to me.
Should be easy to implement. Or, @@fble-test@@ compile-module, to be explicit
that we are only compiling the main module. I like that.

---

Okay! Now in theory we support modular compilation with .fble.@ files. Nifty.
What's next?

Back to the goal of writing a StdioIO% module by hand. Now I can write the
header file for it and compile modules against that header file. I could hand
write my own FbleNativeModule for it. In theory compiled code should now work
fine. What's missing is being able to load native code for execution. That's
the next step.

Add native_search_path argument to FbleLoad functions. Have it search that
list when trying to load a module for execution.

