Performance Refactor:
* Inline the body of link into the link process 
  - There's no need to allocate another process and execute it right away.
* Inline the body of exec into the exec process
* Special case single-binding exec during compilation.
  - It should compile to a non-exec process that does the binding then the
    body without spawning any threads.
* Separate blocked threads from running threads
  - Keep a list of the running threads and iterate over that list in
    RunThreads instead of all threads. This should avoid the 2,288,383 of
    2,474,801a calls to RunThread on blocked threads reported by code
    coverage.
  - If we want to keep the same quota behavior, have each thread store its
    allowed quota when it is created? Or maybe don't bother with fairness.
* Figure out why time profile says md5 is so much longer than tictactoe while
  wall profile says tictactoe is much longer than md5.
* Figure out why tictactoe profile seems so useless.
* Clearly specify performance of evaluation in spec.
 - We should be able to list all possible performance model parameters based
   on the spec description.
* Add an option to automatically determine performance model parameters based
  on wall clock time profiling of benchmarks.
* Ensure the implementation satisfies the performance spec. Add perf spec
  tests as necessary to catch bugs.
* It's very unintuitive that $(f(...)) calls f(...) before executing the
  process $(...). Clarify the spec on that and make sure we implement it
  correctly. And think about the other kinds of procs too, like put and get.
* Consider replacing $(...) with ${...} where the body of the eval is not
  evaluated until you execute the eval.
* Figure out why the tictactoe AI was 4 times faster when using a process
  computation instead of a pure computation, even though fble level profiling
  and common sense suggest it should be the other way around.
  - I wonder if it's because exec is non-recursive and let is recursive, thus
    introducing lots of reference cycles, which take much longer to retain and
    release?
  - A good way to figure this out would be look at code coverage line counts
    before and after.
* Figure out why it takes longer and much more memory to insert 5000 entries
  into the TicTacToe MemoTable directly rather than compute all the entries
  from scratch. Seems funny.
* [perf] Collect benchmarks somewhere?
  - md5 run on 6k file. ~7 minutes
  - tictactoe find best move for empty board. ~3 minutes
  - sudoku on sample board. ~13 minutes
  - sudoku on empty board. ~215 minutes
  - stack-smasher 14 bits: ~34s.
* [perf] figure out how to use 'perf' for profiling?
  perf record --call-graph dwarf [COMMAND]
  perf report -g --stdio
* [build] move 'perf' logic to build.fble.tcl
* [perf] Optimize FbleRefAdd
* [perf] Store scope size as part of InstrBlock and use an array for vars.
 - replace all AddToVector callbacks in ref.c if feasible.
* Test what gets evaluated at eval vs. exec time for each kind of process.
* [perf] Eval in compile.c is called a ton. Shouldn't we only need to call
  eval after a let binding? Can't we use subst or other eval-by-construction
  for everything else?
* [clean] Tracking of time in the compiler is really messy
  Especially that we extract the pointer to the time field from NewBlock by
  assuming what NewBlock does. Figure out some way to clean this up.
* Document performance model.
  Specifically that we use strict evaluation to model performance because it
  is a simple model, which is essential for writing high performance code.
  Lazy evaluation is not 'performance modular' in the sense that the runtime
  of a function depends on how its arguments were computed and how its result
  is going to be used, rather than just the value of arguments. Lazy
  evaluation has some benefits I'll miss, but not nearly enough to justify
  loss of a simple, modular performance model. Implementations should focus on
  improving constant factors, not improving complexity over the performance
  model.
* Document the performance model which says tail recursive functions
  should not smash the stack.

Miscellaneous:
* [clean] Can fble-stdio check that the function has the right type?
* Better error messages on types that have the same name but different values.
* Write man pages for fble and friends?
* Rethink arenas and documentation, because some cases appear to assume you
  have a bulk-free arena. Other cases its not well specified what is freed
  explicitly and what is expected to be freed implicitly.
* Better error message when the difference between a type is accidentally
  defining + vs. *, and it contains substituted polymorphic type variables.

  I claim a good model is: pass an arena to a function to say: the function
  allocates its result in this arena. The function creates and uses a separate
  arena for its intermediate allocations.

Future:
* Implement compiler to C. Idea is translate a function body into a sequence
  of commands like we have in the current interpreter. Split the command
  sequence into blocks any place there is a function call. Gather up all the
  blocks of all the command sequences in the program, give each a unique name
  starting from zero, then generate a loop containing one large switch
  statement with a case for each block. Global state is a list of thread
  contexts. Thread context is a frame, which has variables, ports, the id of
  the block that currently needs to be executed, and a pointer to the frame to
  execute after executing this block.

* Implement compiler to hardware. Same idea as compiler to C: break up into
  blocks. Now each block can be its own hardware block. Frames are queued up
  at their block, all blocks can execute in parallel as inputs are available,
  and we can pipeline or duplicate the blocks to allow for even more
  parallelism.

* Implement an fble debugger. Features:
 - Set a breakpoint at a line in a file.
 - Step through code line by line.
 - Evaluate expressions in the context of the current scope and print the
   results.
 - Auto breakpoint at undefined behavior?
 
 Use cases:
 - Debug why sudoku solver isn't working properly by stepping through a line
   at a time and printing intermediate values.

   Turns out it wasn't too hard to figure out the problem in this case without
   a debugger.

Snake:
* Make food appear randomly instead of at the tail.
* Speed up the snake every time it eats something.
* Test and fix bug when snake eats its tail.
* Ignore moves that aren't orthogonal to current snake direction.
* Keep track of and report score.

Md5:
* [prgm] Optimize Md5.cls function
  - change << and >> to take number of bits to shift instead of a single bit.
  - change cls to use or(x << n, x >> (K - n))
  - consider changing Bits implementation to an array of bits, so that cls is
    a simple index transformation?
* Improve performance of Bit2XN.add, though it's not obvious how.

Sudoku:
* Improve performance enough to make tests useful.
 - More efficient constraint set concatenation?
   The profile says all the time is spent in List%.Append, but I think
   something funny may be up with the profile.

Game of Life:
* live if
  A. is alive and have 2 or 3 live neighbors
  B. is dead and have 3 live neighbors

Space Invaders:
* Render objects - how to test?
  manual test: Draw all objects to the screen as a gallery of them.
* Game loop driven by timer - how to test? 
  manual test: Have app with just ship that can be moved left and right (and
  fire bullets into space?)
* Pseudo-random bullet attack, UFO - how to test?
* Collision detection
