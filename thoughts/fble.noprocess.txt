Fble No Process
===============
Exploratory thought: can / should we remove processes from fble?

Contrast processes with abstract monadic type parameterized interfaces.
Processes feel magic and built in and special. Abstract monadic type
parameterized interfaces feel natural (if maybe a bit cumbersome) and general.

This thought keeps coming up, over and over and over. Do we need processes?
Why can't we do everything with, let me call them, monads instead?

Processes give us:
* A convenient syntax for sequencing.
* Concurrency support.
* A way to create references to values of any type (via links).
* The option for custom compilation support and optimizations.

Monads are less convenient syntax wise (but more precise from a type point of
view). It's not obvious if they provide the same concurrency or performance,
and they don't give a way to create references to values of any type.

We could implement a concurrency monad, but there's no way to implement links
unless we add a type erasure feature. Proposed new feature: you can convert
any type to some magic type T, and you can convert magic type T to Maybe of
any type, depending on whether the T value was originally created from that
type. It's type safe, but lets you put objects of different types all in the
same data structure. That allows you to create references (via keys into some
data structure) to values of mixed types.

Then I'm thinking the following:
* Get rid of the built-in process type.
* Have Stdio@, App@ interfaces be based on an abstract monadic type that the
  stdio.fble.c, app.fble.c implementations can provide their own
  implementation of.
* Implement a concurrency monadic interface based on cooperative
  multithreading for those cases we want concurrency. One implementation of
  this could be a native implementation. But you could also run things pure.

Benefits:
* Encourages use of more precise monad types.
* We can focus optimizations on monads, which are more generally applicable
  than the process monad was.
* Programmers don't have to pick between process (easier, more limited) and
  monad (harder, more general).
* Simpler implementation, because we don't need to implement processes in the
  type system or compiler.
* Better control over scheduling policies, because that can be part of the
  concurrency monad library rather than being built into the language.

Downsides:
* Might be harder to get basic programs to run fast, but honestly, better to
  focus optimization on more general things than a specific, limited use case.
* Syntax for monads might be less nice. But again, better to focus making more
  general things easy to use rather than have niceness in a limited use case.
* Harder to justify magic type T than concurrency for fundamental motivation
  of inclusion in language?

Concurrency is pretty easy to justify as a fundamental requirement:
* Your program runs as the main thread of control in the context of an
  external environment where other things are running.
* To support composition, we should be able to run your program in the context
  of a larger fble program.
* Hence, we should have a way to combine fble programs together in an
  environment where multiple things are running in their own threads, all
  within a single fble program. That is concurrency.

On the other hand, the concurrency we care about is the interface, not the
implementation. One implementation could be native OS threads, another
implementation could be built in to fble runtime, another implementation could
be using monads as an fble library. Using monads best fits with the idea of
concurrency as an interface as opposed to concurrency as an implementation.

Another point that's come up a few times: IO ports versus abstract functions.
For processes, I think of all side effects in terms of puts/gets to the
outside world. But when programming, it's nicer to think in terms of abstract
functions that have side effects. The monadic description is pretty well
suited to the idea of abstract functions that have side effects. I'm not sure
there's a fundamental difference one way or the other, but consider how we
implement side effects now.

Today, all external side effects are done using IO ports, that mean bringing
data out up to the top level. If we instead used abstract functions, we could
get rid of the notion of a link entirely in the implementation and instead
provide a native function that does side effects in place. That feels like it
would be more efficient than pushing things back and forth over IO ports.

All of this sounds pretty good in terms of arguing for removal of processes.

How do we justify references instead of processes as a fundamental language
feature? They are needed for concurrency, because you want two different
threads of control to be able to communicate. The only way that can happen is
if they have some reference to a shared value. That shared value can be
modified by one thread at any time, with the other thread seeing the side
effects. That is a reference.

We could have built in pointers, as many languages do, but that implies a
built in global synchronization scheme. I like the idea better of being able
to type erase values. Then users can define their own references and data
structures to store the data. And it's the maintenance of those data
structures that naturally leads to synchronization.

For example, the scheduler keeps a map from int to type erased value. Only the
scheduler thread can modify the map, so synchronization is clear and
guaranteed, and independent of other pointer values. Everything is very
explicit.

One way to think of type erased values is like an infinite field union, where
the fields are done by type. Instead of something like Value@(int: 4), you
would say, conceptually: T@(Int@: 4). Then that makes sense as a useful kind
of data type: a type indexed union. It needs special support for tagging and
checking types.

One concern is, how could you implement that in hardware, for example? If you
can't possibly know the size of the value ahead of time? Well, that's no
different than recursive types, so I'm not sure why I would be bothered by
that.

The implementation in software is pretty straight forward: use an FbleValue*
for the type. We need special compiler support for tagging and checking types,
which is some motivation for why this needs to be a built in thing.

Don't we already have some language feature that's like an abstract type? Or
was that a previous feature since removed?

There is something called an abstract type. Hey, look! We already have
something called an abstract type. But it's not quite the same, because it
doesn't allow mixing of abstract types with different internal types. They are
annoyingly similar concepts, but not the same. In particular, the existing
abstract type does compile time checking of the erased type, whereas what we
want for references is runtime checking of the erased type.

It's not hard to define a new feature for type erasure. It would be something
like:

  ERASE(x), converts something of type X@ to type ERASED@
  RESTORE(X@, x), converts something of type ERASED@ to type Maybe@<X@>. 

We just need a new type ERASED@ and two new primitive operations: erase and
restore. It's slightly awkward to have a built in Maybe@ type. Oh well. The
alternative would be to have a runtime error instead if you try to convert
something of the wrong type. Just like we have a runtime error if you try to
access a union of the wrong type. But then, should we have a way the user can
check the type? Maybe a case statement syntax support?
  x.?(
    Int@: ...
    Bool@: ...
    : ...);

I'm not sure that makes as much sense as case statement for unions. It's not
like we'll have a tag in the value to switch to the type. It's more like we'll
have a type that we can check if it matches or not.

Anyway, theoretically I think getting rid of process is a good idea. To start,
even before making language changes, we can convert Stdio@ and App@ to the new
approach. Those don't require concurrency I don't think, so should be straight
forward. No new language features needed to try that out.

Next step then:
* Redefine Stdio@ as an abstract polymorphic monad, and see how far we can
  push that.

That should give us a sense of the tediousness aspect of programming in the
absence of processes.

---

Seems to work okay. For a first stab, not entirely clean, what was:

   Unit@ _ := io.stdout(Str|'PASSED');
   !(True);

Turns into:

   Unit@ _ <- m.do(stdio.out(Str|'PASSED'));
   m.return(True);

That's nice to me. There's just the issue of having to pass 'm' and 'stdio'
everywhere we want to pass it to. Or deciding if we want to pass it as a
single StdioM@ type, and then how to nicely extract the 'm' and 'stdio' parts
from it.

What's next then? This is an interesting question. Like, do we want to change
Test@ to be StdioM@, or to be MonadM@? If it's parameterized, that's much more
general, right? But, maybe, also more tedious?

Because some tests maybe we want to do io. Some tests, maybe, we want to do
concurrency. Some tests, maybe, we want to do App@ operations.

Maybe that's one of the benefits of this parametric approach. We could
describe a test that does IO, but then run it in a pure environment.

I think I want to learn more from experience about how to structure the
library with this new approach. How about changing the tictactoe game to use
the new proposed API? And maybe step back and think about what I want the new
proposed API to be first.

Actually, tictactoe uses concurrency for the AI. Maybe start with one of the
benchmark games, where the IO only happens at the top level?

One approach we could use, I suppose, to avoid having to pass Stdio@ and IO@
to every function would be to define the module as a function that takes
Stdio@ and IO@ interfaces?

This is going to need trial and error I think.

---

Plan:
1. Move Stdio.fble and Process.fble to IO subdirectory.
2. Clean up new Monad and Stdio APIs
  Monad@ is interface with do, return
  Stdio@ is interface with in, out, err
  StdioMain@ is the type of the main function for stdio apps.
  IO/Stdio%.IOStdio converts StdioMain@ to IO/Stdio%.Stdio@.
3. Migrate things over to new Stdio@ interface. See how tedious it is.
  Keep Test as !TestResult until we've converted all of the test cases to be
  pure within that. Note that this will require implementing a concurrency
  monad or removing concurrency where we currently use it.
4. Remove IO and other uses of built in processes.
5. Remove processes from the spec and implementation.

It's a long road. A lot of stuff in the implementation is going to go away and
otherwise be simplified, but they will be big changes refactor and clean up
right.

Let's see how goes.

---

Step (1) was easy and done.

Step (2)...

fble-compile: fble/lib/type.c|782| TypesEqual: Assertion `false && "poly apply type is not Normal"' failed.

Uh oh. Bug in the type system. That's scary.

We have two PolyApplyTypes we are comparing. The claim is that these are in
normal form. Is it possible to have a PolyApplyType in normal form? Why not?
If it's an abstract poly like M@, right?

Yeah. See. It is possible. So I should add a test case for this and fix it.

Question: what two types are being compared here? So I know what to base my
test case off of.

It's this line:

(/Core/Stdio%.Main@) { Stdio@; }
IOStdio = (/Core/Stdio%.Main@ main)(IO@ io, List@<String@> args) {

Where Main@ is polymorphic. What do you think, it's because we have M@<Bool@>
in the return type of the function, so we end up comparing M@<Bool@> with
M@<Bool@>, where M@ is abstract. That's it, right?

But it may be more complicated to end up substituting like this.

Let's repro, then minimize, then fix.

Repro is done. It's pretty simple and makes sense. Next step is to figure out
how to do type equality on (normalized) poly application. If it's normal, that
means you can compare poly and compare args, right?

I feel like we better test not equal too though.

Cool. Easy. Done. Fixed.

That's step (2) out of the way.

List of things to migrate off of Stdio@:
* Cat program. Should be easy. Done.
* PiDigits. Should be easy. Done.
* BinaryTrees. Should be easy. Done
* BenchmarkGame Bench. Good test of pure implementation of Stdio@. Done.
* BenchmarkGame Test. Good test of pure implementation of Stdio@. Done.
* Sat solver. Should be doable. Interesting case of abstraction over
  abstraction. Done.
* TicTacToe. Depends on concurrency?
* Test@ - Wait until very end.

---

Experience:
* Forgetting m.do leads to a somewhat difficult to decipher, though
  technically quite correct, error message.

---

Next step: migrate BenchmarkGame Test to a pure implementation of Stdio.
* Works well enough. No complaints from me.
* One thing that's slightly awkward is we get back a list of strings, and
  realistically we only care about the concatenated list, not how it's
  partitioned into different outputs. So there's some notion of causality that
  we are no longer easily able to test this way. Maybe we could come up with
  some fancier way to test Stdio applications that's like an expect script.
  You say: give this input, expect this output, then give this input, etc. I'm
  confident we could implement such a thing using pure monads. It's just more
  effort than I want to put right now.

---

Next step: Sat solver. How will this look?

The first thing we do in sat solving is to read all the lines of input from
IO. That should be easy to reimplement using abstract Stdio. So I think this
will be pretty straight forward.

Yeah. No issue at all.

---

Next step: TicTacToe. 

I suspect we'll want to do this in two parts. First part is to remove the
concurrency. Second part is to migrate Stdio.

What we want is to provide a function that takes AI@ state and a Turn@ and
returns a Position@.

It's actually pretty convoluted the way TicTacToe is currently written. I
think it will be an improvement to get rid of the concurrency aspects of it.
Just need to think about how I want it to be organized.

AI: Has a memo table that we want to compute lazily. That makes it slightly
more complicated. Maybe we should model it as a monad then, with a 'Move'
function? Or straight up AI@ -> Board@ -> Player@ -> (AI@, Position@).

As a Monad, it would be: Board@ -> Player@ -> AI@<Position@> + Monad@<AI@>. I
think Monad is overkill in this case. Let's just store AI@ and Position@.

So, AI interface is: @(AI@, Move).

Board% is fine as is.

Game%: Is okay, except TicTacToe should now be...

I think we want Game@. Then you have a function
 Game@ -> Input@ -> (Game@, Output@)

But Output@ is just the Board@ and GameStatus@. We can store GameStatus@ as
part of the game. So maybe just:

Input@ -> Game@ -> Game@.

Then Game% is: Game@, Status@, Input@, Initial, Play

Now Testing is really easy. Just be able to compare game states and verify
various combinations of Input@ and Game@ updating Game@ state.

And Stdio% becomes:
  Get input, convert to Input@, play round of game, convert and put output. Go
  until game is over.

TicTacToe becomes a Main@ function.

If we want now it's really easy to test at the Stdio level of granularity?

Let's start by cleaning up the AI interface and updating the tests and
rest of the game over to that. Then update the Game interface. Then we should
be all set.

---

TicTacToe AI interface cleaned up easily and nicely. Tests updated. Next step
is to update the Game interface.

Updating the game interface wasn't bad. It's cleaner this way too.

And now the rest of TicTacToe is updated to use pure stdio interface instead
of processes. Nice.

---

Next step... can we get tests off of use of processes? That's the last place
we use the IO/Stdio interface.

Um. I'm worried that's blocked on many of the other uses of processes. App@ in
particular.

The idea is to change TestCase@ to have a function from Unit to TestResult@
for the test instead of TestResult@!. But that's going to need a lot of work,
right?

What if we introduce a new kind of Test@: iocase, which is the 'case' of
today. And then 'case' because the new pure thing. Then slowly transition as
many tests as I can over to the pure 'case', and then it's clear what remains
to be transitioned. I don't think we can get rid of IO/Stdio until all of the
test cases are transitioned off of processes, which probably means almost all
of everything transitioned off of processes.

Yeah, this sounds like a good approach to me. Add iotest case. Port everything
over to pure test that we can. Get the list of IO tests. Put that list here,
and we can see what's left to fix.

---

Using (Unit@) { TestResult@; } is a little clunky for describing tests. Not so
much worse than !(...), but still leaves a little to be desired. Oh well.

We could do more monadic style:
 {
   Unit@ _ <- Test(Str|TestName);
   ...
 }

Or maybe add support for zero argument functions?
 Test(Str|TestName, () { ... });

---

IO todo for tests:
* MD5 test requires processes.

And that's it! Just MD5. Because Md5 API uses processes.

What's the plan for Md5 then? We want to support reading files a byte at a
time or so. We kind of want a File@ interface. Like:

<<@>@ M@>(Monad@<M@>, File@<M@>) { M@<Md5Hash@>; }

Where File@ has a single method. So no need to name it? No need to make
something general about it at this point.

  M@<Maybe@<Bit8@>>

The other thing that needs to change is our use of concurrency. We have Pad,
which transforms stream of Bit8 into a different format: data + 'last' bit
with padding added.

The question is, do I still want to leverage concurrency in describing the Pad
function? How much worse is the code if instead of doing it as concurrency, we
did it as a stateful GetStreamdByte function?

Concurrency approach:
* Pass msglen, length as arguments.
* Separate Pad and PadZ functions to track state.

Non-Concurrency approach:
* Caller has to hold on to state (make it monadic?).
* Pass msglen, length, is_padding arguments via state.

Mostly the annoying part will be passing the padding state around the rest of
the Md5 functions, instead of being able to store it with a complete separate
process.

In practice this means defining a state monad on top of the file monad.

So, I don't think we need a concurrency approach. Which makes sense for
controlling scheduling. But we do need a monad for the padder. We can put that
in a different module, which will be nice. I'm just not sure how to layer the
different abstract monads here. The padder will be something like, given
abstract M@, Monad@<M@>, File@<M@>, give us abstract P@, Monad@<P@>,
Stream@<P@>.

Or, maybe, if you provide something that works for any P@, Monad@<P@> and
Stream@<P@>, Padder can run that for you and give you something that works for
any M@, Monad@<M@>, File@<M@>.

Anyway, I think the next step is to try and write a separate padder module,
using whatever interface makes sense for it.

---

Concurrency is starting to look more attractive for padder. At one point we
output the 8 bytes worth of the message length. It's nice to be able to do
that via a sequence of 8 puts. How else would you do it? Have a buffer of the
next bytes to output and append to those?

Is there a way I could describe it with a Put interface, but interact with it
with a Get interface? Maybe stash the next element somewhere, and populate
that with a continuation?

How I want to describe the things:

  Unit@ _ <- Put(1);
  Unit@ _ <- Put(2);
  Unit@ _ <- Put(3);
  return(Unit)

That defines some object, say M@<Unit@>.

How I want to read the things:
  E@ e <- Get;
  E@ e2 <- Get;
  ...

I feel like the state is a Maybe@<E@> plus a function from Unit to itself.
Really, no need to return in this case, right? As long as we know when it is
done.

@ M@ = Maybe@<*(E@ e, (Unit@) { M@; } m)>

(E@)((Unit@) { M@; }) { M@; } Put = Just(e, m);
M@ Return = Nothing;

Except modified slightly because we have the underlying source monad buried in
there. Let me rename things a bit then:

@ S@ = M@<Maybe@<E@, (Unit@) { S@; })>

We kind of want S@ as part of a state monad. Ugh. This is a bit complicated.

---

Reminder: monad is preferred over explicitly passing around a state because
that way you don't have to explicitly pass around a state.

It's more complicated than I would like, but here are the components I think
we'll want:
* File@ interface. M@<Maybe@<Byte@>>. This is what you have to implement to
  get Md5 done. This is consumed by the padder.
* Stream@ interface. M@<Byte, Last>. Because that's what Md5 uses. Otherwise
  we could reuse the File@ interface here. Maybe that's worth doing as initial
  cleanup. This is what the padder implements and the md5 round module uses.
* Padder implementation. Will use something like P@ = M@<Maybe@<Streamed,
  P@>>. It collects together a sequence of function calls that incrementally
  output the padded words. We can use bind notation to make this feel like we
  are implementing it in terms of a sequence of puts.
* Padder adaptor. Takes P@ that we produced in the padder implementation and
  provides a Stream@ interface implementation for it.
* Rounds implementation. Straight forward given abstract Stream@ interface.
* Top level. Given File@, instantiate a padder, padder adaptor, and rounds
  implementation and connect them all together.

What's tedious about this is most of these blocks are glue logic. It's only
the padder implementation and rounds implementation that describes the core
md5 logic.

I vote we start by seeing if we can get rid of Streamed@ and use
M@<Maybe@<...>> instead. That will cut down on one interface at least.

---

Minor cleanup done to md5 to get rid of Streamed@ in favor of Maybe@. How do
things look now? Can we make the glue code a little more generic and reusable?

Basically you have producers and consumers.

Producer: produces a sequence of elements, one at a time, and then finishes.
Consumer: consumes a sequence of elements, one at a time, until they are all
consumed. You can switch up the type of element being produced.

* We have an interface you can use to describe a producer. It does puts.
* We have an interface you can use to describe a consumer. It does gets.
* We have a way to feed a producer to a consumer. Converts the result of a
  producer into whatever is needed to run a consumer on.

Maybe we use a type S@ to describe a stream, P@ to be the producer monad, and
G@ to be the consumer monad. And we provide functions P@ -> S@ to describe a
stream using a producer and G@, S@ -> M@ to consume a stream.

---

Here is the plan:

* Get% defines Get@ = M@<Maybe@<T@>>
  An interface to monadic computation to get values of a given type.
* Stream% defines Stream@ = M@<Maybe@<T@, Stream@>>, Put functions, Get@<Steam@, T@>
  A type representing a stream, a convenient syntax for constructing a stream
  using Put and do notation, and an implementation of the Get interface for
  streams.
* Round% implements the rounds part of md5, given an abstract Get of pre-padded
  bytes.
* Pad% implements the padder, which takes a Get interface and produces a
  Stream.
* Md5% combines everything together, calling Pad, then passing the result via
  Get interface wrapper to Round.

---

Experience: this is really hard to figure out, detail wise.

Okay, so where I'm at right now is to define Stream@ and define a helper Put
function that works within the original M@ get monad. Rather than define a
monad specifically for the stream. This way I can implement the Padder pretty
nicely and end up with an M@<Stream@>.

The next annoying step is to create a new monad which is ...

(M@<Stream@>) { M@<A@>; }

So, a ReaderT like thing that can read the stream. No. Neads to be a StateT to
keep track of how much of the stream has been read so far.

Okay, so the StateT isn't too bad to implement.

---

I have a draft of the md5 structure in place now. Just needs some cleanup to
get it to compile. Let's see how goes.

It works. Wow. That's pretty cool. I end up providing different monads for
benchmarks (Int@ state monad) and tests (List@<Bit8@> state monad). I still
have to reimplement the fble-md5 C wrapper code. I kind of want to check
things in first to start though.

