Fble Type Inference
===================
As part of exploration of bind syntax (see fble.bind.txt), we added limited
support for type inference. This makes it pretty nice to write code involving
polymorphic functions.

It doesn't take long to realize there are some other places type inference
would be nice too. The goal here is to identify all the places it makes sense
to have type inference and come up with some reasonable way to describe all
those places in the specification and implement it in the implementation.

I also want to take some time to convince myself again that this form of type
inference isn't going to be a bad thing for the language. One concern I have
now is that type inference hides the type application from the syntax. But
type application is not free in reality in general, so shouldn't it appear in
the syntax?

Other places where it could be nice to add type inference:
* struct_value_explicit_type - poly value of a struct type, would be nice to
  infer the type arguments from the struct value arguments.
* union_value - poly value of a union type, would be nice to infer the type
  arguments from the union value arg. Only applicable in the special case when
  all the type arguments can be inferred from the particular constructor you
  are using. For example, Maybe@(just: ...) works, but not Maybe@(nothing: ...).

Actually, I think that's all.

Maybe the way to do this in the spec is to expand poly_infer? Or, provide
poly_func_apply, poly_struct_value_explicit_type, and poly_union_value? Or
provide some sort of meta abstract to the grammar that does poly<func_apply>,
which could be useful for bind too?

How about the implementation? In general the implementation approach is the
same. I want a type of a particular tag. I'll give you a function that, given
the type with the given tag, gives you a collection of equality constraints
desired. We can abstract common logic for extracting the underlying type from
a poly, inferring and auto-applying the types.

---

Using type inference more, some requests:
* List[Str|a, Str|b] should work, right?
* Foo@(...), where Foo@ is polymorphic would certainly be nice.
  Yeah. It really would be nice.
* It's not obvious to me when I should expect type inference to work and when
  not.

---

Type inference is the biggest weakness in the language spec right now, the way
it treats things inconsistently.

There are two aspects. First is where we want to allow type inference or not.
The second is how to describe the spec in a nice way with respect to type
inference.

The first should be easy. We want type inference generally whenever we are
applying arguments to a polymorphic entity. Because we can use the arguments
to infer the type of the polymorphic entity. This includes:
* struct_value_explicit_type
* union_value
* func_apply
* list
* literal
* bind

Today we only support it for func_apply and bind, where bind is specified as
desugaring to func_apply for that. The mechanism we use in the spec for this
is to define a poly_infer which is the type inference variant of func_apply.

Brainstorm of approaches for doing this in the spec:
* Add poly variants for all these constructs: 
  poly_struct_value_explicit_type, poly_union_value, poly_func_apply,
  poly_list, poly_literal, poly_bind.
* Add a clause to each of these constructs saying the expr may also be a poly,
  in which case type inference is used.

I think that's the gist of it. The two approaches are: understand the features
without polymorphism, then add poly. Or understand the features knowing
polymorphism. It's mostly about what feature you know about when.

It's hard to explain polymorphism without first explaining structs, unions,
functions.

Note, for the three syntactic sugars, it's not clear from the language spec if
they are really syntactic sugars or not. For example, could we use list,
literal, and bind with a struct type? We should say explicitly, and mention
about polymorphic inference at that point too.

I guess it all comes down to how these three concepts interact:
* core types: struct, union, function
* polymorphism - which spans across syntax elements
* syntactic sugar - which (maybe?) spans across syntax elements

If I were to describe syntactic sugar, I would say it as: desugar at abstract
syntax level. That's what you get. Doing the same for polymorphism would be
talking about polymorphism all at once.

I think it's good to keep polymorphism as a separate concept from core types
and syntactic sugar. We just need to note somewhere how they all interact.

Do I want to introduce new abstract syntax for poly? Or reuse the original?

Strawman:
* Define core syntax like we do now.
* Have a section on type inference that lists struct_value_explicit_type,
  union_value, and func_apply as where it gets applied. That's clear enough
  without having to introduce a poly_infer or other abstract syntax.
* Add a note to syntactic sugar that it happens before desugaring, so things
  like struct values can be used and poly can be used.

I definitely want poly support for list, literal and bind. Do I need struct
value support? Why not? I suppose why not would be because it's more effort
and, honestly, who wants to create a struct value list or literal or bind?

Recap:
* Define polymorphism and syntactic sugar after core types, by listing
  abstract syntax nodes where it applies rather than introducing new abstract
  syntax nodes.
* Support polymorphism for struct, union, and func apply.
* Support polymorphism for all the syntactic sugars.
* Only open question: support struct for the syntactic sugars?

Is there any user downside to supporting struct for the syntactic sugars?
Maybe just the potential for an error, but that's pretty low because you need
a pretty specific struct type before you could accidentally do a syntactic
sugar you don't mean to.

And poly has made it clear we would like it to apply to struct types. So let
me go out on a limb and say the user will want struct types for syntactic
sugars.

Okay? Then I have a proposal for how to move forward here. I vote we give it a
try, do a revision of the spec with this in mind, add tests for the various
combinations, and do the implementation for various combinations.

Uh, we can also ask whether we want to support abstract_value as a poly
inference or syntactic sugar. That's stretching in a bit, don't you think?

---

Currently bind is implemented as entirely concrete syntactic sugar. List and
literal get their own abstract syntax entry, because we want to pass info
about them all the way down to generated instructions level for efficiency
purposes. Bind desugaring has basically no overhead, whereas list and literal
have real overheads because they are O(N) in size.

Based on that, in terms of what we support, I propose:
* poly: struct, union, func, list, literal, bind
* list, literal: functions and poly functions only.
* bind: any matching concrete syntax, including function, struct, and abstract
  value. And any poly that you can get from the desugared.

The proposed specification:
* struct, union, func as is.
* poly - no abstract syntax. Say we do inference on struct, union, func
  applies.
* list, literal - say function only, including poly functions.
* bind - say pure concrete syntactic sugar.

We can note the rationale for bind being treated differently from list and
literal.

Alternatively, we could restrict bind to function only for consistency with
list and literal. It just means I have to go out of my way to implement it.
Admittedly, not that far out of the way. So the tension is between consistency
of specification and ease of implementation. So let's be consistent, right? Do
the tiny little bit of extra work on the implementation side to disallow
non-function bind.

Because, honestly, who is going to create a struct type with a single function
argument and then use bind syntax for that?

I think I prefer consistency in this case over the weird use case of struct
bind. And I don't want to allow struct list or literal because we really do
want list and literal to go down into the depths of the implementation.

Here's a question. If list, literal, and bind are specific to functions,
should we put them in with the section on functions?

Okay, so they aren't. Because list and literal talk about structs and unions
too.

If we go this route, then keep list, literal, and bind as abstract syntax. But
remove poly_infer. Just note that type inference is done in these cases.

---

I updated the spec. All that's left is to add support for type
inference for struct, union, list, and literal. Ideally in a nice general way.

What we have today:
* TypeInfer - you call it for each argument, it checks the argument has the
  correct type and fills in any type parameters it infers.
* Note that TypeEquals is a special case of TypeInfer where there are no type
  arguments to be inferred.

MISC_APPLY uses different paths for non-poly and poly function. A nice place
to start would be to generalize that out I think. So, uh.

1. Reorganize misc apply to depoly at the top.
 - Eliminate duplicate calls to FuncApply.
 - Change struct args to use TypeInfer instead of TypeEquals.
 - Exclude abstract value case if there are any poly args.
2. Union should be separate and straight forward.
 - Reuse code from (1) where possible.
3. List and literal are separate and straight forward.

Okay. So it's doable. If I factor out the right code, it's not too bad I don't
think. Let's take it one step at a time.

Ugh. It's so hard to make changes to this part of type inference, just given
how many different error conditions there are and objects to keep track of
memory management for.

---

Overall flow:
* type check function (allocates misc)
* type check args     (allocates args)
* extract poly        (allocates vars, poly, body)
* switch on tag
  func:
    * check application okay
    * apply inferred type params (allocates poly_tc)
    * check poly_tc
    * allocate result tc
  type:
    * get normal type (allocates vtype, vnorm)
    * switch on tag
      struct:
        * check arg count
        * check args
        * allocate result
      package:
        * check arg count
        * check module access
        * allocate result
      default fall through
  default:
    * report error

It's messy trying to clean up things as early as possible and on multiple
branches. So how about let's try cleaning up things once at the end.

That means no returning out of branches early.

But what about cases where we need results of previous parts? Like, we need
the args to be okay? Put those cases as nested if statements guarded by the
args being okay.

How to do the default fall through? We need to distinguish between a case
being triggered and a case succeeding. For fallthrough, we want to say if no
other cases were triggered. Slightly annoying, but lets add a bool to keep
track of that? Call it 'misc_type_acceptable' or some such.

What do you think? Shall we try this? For now, continue to disallow
polymorphic structs, just to limit the amount of new code we need to add. The
goal is just to reorganize the existing code.

Uh, it's really annoying to add a layer of nesting in case there was a
previous error.

Maybe let's be a little more creative. What I would love is to be able to
return at any time we run into a problem, but also only have cleanup code in
one place. So maybe we define a helper function that exports a thing to keep
track of everything that may need to be cleaned up. And call a wrapper
function. Crazy? How about we give it a try and see?

We can make it even a little nicer by having a generic cleanup object that
accepts lists of types, type assignments, and tcs. Then anything we want
cleaned up, we just add it to the list.

---

Trying the generic cleaner approach, before changing any of the type inference
logic. It's tricky because Tc is passed by value. We don't currently have a
way to make a copy. That means we need to transfer ownership away from the
cleaner somehow to avoid freeing parts that we want to hold on to. Like an
std::move kind of thing.

Maybe we store the Tc value on the cleaner, everyone else has to reference it
by pointer, and so they can take ownership and free up by setting the field
values to NULL via the pointer.

Now there is trickiness with poly, which we sort of do an update in place for.
That's very awkward, because how can we update it in place and use it to return
failure to apply poly?

Can I create an std::pointer like type? Would that help with anything?

Note: my draft use of a vector for storing Tc to clean up is going to have
issues once the vectors start getting resized, because the pointers will point
to the wrong place.

I feel like we need to preallocate space for everything we want to track on
the cleaner. It's okay with types where we pass around points and can make
copies. It's harder with things like Tc, where we have no notion of a copy and
pass it around by value.

Taking a step back, the goal here is:
* Be able to return immediately on failure so that subsequent code in the
  function can assume there hasn't been a failure.
* Avoid duplicating logic for cleanup.

That means tracking ownership of things as it changes in the function, and
doing cleanup of ownership in a wrapper function.

Maybe it's worth writing down all the things we may want to clean up at some
point:
  Tc misc
  Tc[] args (Length depends on argc)
  FbleType* normal (The normalized type of misc)
  FbleType* vtype  (The value of misc if misc is a type)
  FbleType* struct_type aka vnorm (The normalized value of misc if misc is a type)
  FbleType* pkg_type aka vnorm (The normalized value of misc if misc is a type)
  FbleType* body - for each poly body (The normalized type of a body of misc)
  FbleTypeAssignmentV vars - vars.xs and FbleType vars.xs[i].value

The only thing I can think of to make this workable is to define a struct for
the local variables in a wrapper function and clean up there. Make it specific
to MiscApply. What do you think? Shall we give it a try and see if that works
better?

It's a bit tedious that we can't just put the wrapper and function body
together in one place. I'm not tempted enough to use goto. Let's see how the
body of the MiscApply function looks when we don't have to worry about any
cleanup.

It's still pretty tedious. I still have to keep track of what we keep or not.
It feels like there's a whole lot of stuff I have to juggle in my head at
once, like I can't just focus on one piece of code at a time.

I wonder, do you think we could do it better with a lot of little functions?
Each function is only responsible for cleaning up what it allocates itself,
and because you do a lot of function calls, there's less lines of code between
where you allocate something and where you clean it up?

---

I think lots of little functions will still be difficult, because in some
cases it takes ownership of an argument, and in others it doesn't, depending
on whether there is an error or not. As long as we have something like Tc
that doesn't support reference counting, it's hard to make this modular.

This whole discussion explains why garbage collection really is important.

What if we added reference counts to FbleTc? Then you could "make a copy" or
an FbleTc. Then we have separate ownership of an FbleTc for the local variable
and for the result. That means we always clean up the local variable,
regardless of the result.

To avoid duplication and worrying about everything that's in scope every time
we return, we aren't allowed to return in the middle of a block where some
object is allocated. To allow you to return in the middle of a block where
some object is allocated, you need to use a separate function.

Things would look like this:

  Foo foo = Alloc(...);
  Result result = DoThing(foo, x, y, z, w, ...);
  Free(foo);
  return result;

It's still pretty tedious to pass a whole bunch of local variables and to have
the body of the function some place else rather than inlined.

Why am I still tempted to use goto?

The goto case would be: put local variables all at the start of the code
block. Whenever you return, instead of returning directly, do a goto.

  Foo foo = NULL;
  Foo bar = NULL;
  ...
  {
    Nice code goes here.
    Result result = ...;
    goto done;
  }

  done:
    Free(foo);
    Free(bar);
    return result;

The benefit being we don't need a wrapper type and function to do the cleanup.
Or we could, if we refer that to goto. Honestly I don't think that matters
nearly as much as the question of whether ownership of a value belongs with
the local variable or the result. If we reference count Tc, then ownership can
always belong with both the local variable and the result.

If we make Tc reference counted, we can use a generic cleaner object. We could
add to a list of things to clean when we first allocate an object. It stays on
that list even if we want to return it as a result, because we increment the
reference count.

The only question then is, when do we invoke the cleaner? We could do it any
time we exit the function. For example, something like:

 Cleaner cleaner;
 Foo = Clean(cleaner, Alloc(...));
 ...
     return CleanReturn(cleaner, result);
 
 return CleanReturn(cleaner, NULL);

Any issue with a while loop, for example with poly, where we want to allocate
and clean within that loop? I think we could do local memory management
outside of the cleaner for that, and just use the cleaner for the out object.

What about things like vectors, where .xs needs to be freed in a non-reference
counted way? Does everything have to support reference counting for this to
work?

Let me test this out on FbleType*. I feel like I already tried this, but maybe
if I focus on FbleType* and be prepared to support reference counts for Tc*
we'll make more progress.

Define a Cleaner object, a NewCleaner function, a Clean method to add
something to be cleaned, and a Cleanup function to do all the cleanup?

It's showing potential. To take full advantage of it we need support for Tc.
Notes:
* It's nice that every time we return we do Cleanup call instead of specific
  things. Real easy to check we've done cleanup every time.
* It would be nice to have a CleanupAnd... function so you could do the
  Cleanup as part of the return statement.
* I don't think there will be any easy way to incrementally add cleaner
  support. There's lots of details that have to be gone through.
* It will be better once we have cleaners because we explicitly see when we
  are planning to return some tc value, because we need an explicit retain for
  it.
* We can use cleaners for vector .xs. Just have a vector of void* to that will
  be passed to FbleFree for cleanup.

What do you think? Add reference count to Tc? Switch typecheck to use
cleaners. Work through all the tedious details. See how things look after
that?

Maybe I can add incremental support for cleaners by instantiating local
cleaners one case branch at a time. Once all branches have the local cleaner,
I can make it into a single function level cleaner. That sounds reasonable.
Just be willing to accept that the intermediate state is not going to be as
nice as the final state.

I say let's take a leap. Try it. Worst case we can always roll back. This is a
good learning experience. But do it incrementally, bit by bit. Otherwise I'll
be overwhelmed like the last 5 things I've tried.

Steps:

1. Make FbleTc ref counted.
2. Add cleaner incrementally, one case branch at a time, until all are done.
3. Review final code, see how I feel about it, and report back here.

---

* Any better name I can come up with than TypeWithCleanup and TcWithCleanup?
  Ideally something much shorter?
* How about a FAILED variant of the cleanup function?
* Maybe I could use a wrapper function so we can factor out the allocation and
  cleanup of the cleaner? That should make it cleaner, right? Yeah, I kind of
  like that idea. No need for 'TypeWithCleanup' and 'TcWithCleanup' that way.
  We can just use 'Cleanup'.

Yeah. That's good now with the wrapper function. I'll just have to remember to
convert all the branches to use the cleaner.

Branches remaining:
* let expr
* union select expr
* func expr

Thoughts:
* Would be nice to clean FbleTypeAssignmentV too? In misc apply.
* Should we pass cleaner to PolyApply?


