Fbld Improvements
=================

I'm happy with the syntax for fbld. The implementation needs work.

One idea is to try implementing fbld in fble. Partly as an excuse to write
more real world fble programs, partly because it almost feels nicer to use
fble than tcl given things like tracking error locations.

I see two big challenges with using fble for fbld:
1. How to make it easily extensible. Can users write their own front ends and
back ends? Would they have to write fble? Is that too much to ask? How can we
compose with other existing programs like groff?

2. How to deal with bootstrapping dependency of fble on fbld and fbld on fble?
It's a bit annoying, because it's just the help text for fble-stdio. Maybe
have an option to compile fble with and without that usage text and do a mini
bootstrap that way in the build system.

Big things I want to improve for fbld (regardless of what language we use to
implement it):
* Location tracking, so we can point to the exact place in a file where an
  error occurs.

* Composition: so we can easily implement commands directly in terms of other
  commands if we want to, instead of having to convert back into strings and
  re-parsing.

Both those things come down to this challenging aspect of fbld:

The commands have to parse args using fbld, the fbld parser has to execute
commands using the commands. That creates this cycle going back and forth
between the parser and commands where we have to keep track of and pass
location information back and forth. We can't just parse the whole thing all
at once and then execute commands all at once.

---

This should be pretty straight forward I think.

Assume some monad for computation/side effects.

We have generic commands that don't care about the monad. They can be
parametrized by it. The monad lets you call a sequence of commands.

Define fble functions that take typed (post-parsed) arguments.
Define a generic command map that takes non-typed List@<String@> arguments,
parses the arguments appropriately, and forwards that to the typed fble
functions.

The implementation of a command can call either the raw fble function it
wants, or invoke a command via the generic command map.

Typed fble functions for backends can work with specific monads. For example,
maybe we have an HtmlM@ for generating html documents.

We have a block parser and an inline parser that both work solely with generic
monad via the generic command map.

For composition, you create a command map that works for a particular
specialized HtmlM@ monad. You invoke the block parser, which causes all the
commands to be executed recursively in the monad. You can do what you want
with the results of that. Easy.

Note: instead of List@<String@>, we'll want List@<StringL@>, or some variation
that tracks locations for strings. And the block and inline parsers should
operate on StringL@ to maintain file location information.

I think this will be nice, straight forward, very composable. The two issues
I see are:

1. How to get the filename for what we are parsing.
Ideally we can open named files rather than just stdin. Then that's solved. We
want that for fble-md5 too.

2. How to let people write their own extensions to fbld without using fble.
They need some programming language to be flexible enough. For ease of use, it
would be nice to have a programming language with an interpreter. Some options
are: tcl, python, fble, some custom new fbld language. I think, let's not
worry about this now.

---

First step: add support for opening named files. Even before we start on fbld
implementation. We can do this on md5.

Goal is to change the command line interface to md5 by adding an option to
pass one or more file names on the command line (or '-').

Output format is:

<sum>  <filename>

Or, in case of a directory

fble-md5: <name>: Is a directory

Let me see if I can dig up my old thoughts on how to support file names:
* Skip ReadDir to start.
* (String@) { M@<Maybe@<IStream@>>; } Read;

Maybe it's that simple. Just need to implement it.

The return value should be True if all files are found. False if any are not
found.

---

Getting started on fbld, the tricky part is the knot in the middle.
* The parser needs to know how to invoke commands.
* The invoked commands want to call back into the parser.
* Neither parser nor individual command knows what the other commands are.
* You could get an error message at any point while invoking a command or
  running the parser.
* All of parsing and command invocation takes place in some monad M@, which is
  abstract for the parser and some commands, but may be concrete for other
  commands.

Access to the invoke function, possibility of error, and monad M@ are common
between invocation and parser. The string to parse and the state of that is
specific to the parser. I want some monad transformer Fbld@ that stores the
command invocation function and error handling.

Interface from within Fbld@:
  (Loc@, String@) { Fbld@<M@><Unit@>; } error - reports an error.
  (StringL@, List@<StringL@>) { Fbld@<M@><Unit@>; } invoke - invokes a command.
  <@ A@>(M@<A@>) { Fbld@<M@><A@>; } lift - execute an M@.

Is there anything simpler we could do? Like, commands take invoke as their
first argument and return an M@<Maybe@<String@>>? And parser takes invoke as
their first argument? No need for an Fbld@ transformer monad?

Result@ = +(Unit@ ok, String@ err);
Invoke@ = <<@>@ M@>(Invoke@<M@>, StringL@, List@<StringL@>){ M@<Result@>; };

<<@>@ M@>(Invoke@<M@>, StringL@) { M@<Result@>; } Block;
<<@>@ M@>(Invoke@<M@>, StringL@) { M@<Result@>; } Inline;

Cool. Easy.

---

Ugh. Parsing with locations is tedious. Can I make a little Parser@ monad to
help? I want to do things like:

* Get the next character from the input stream, have location advance
  automatically based on the character in question.
* Run a Parser@ computation to get some value at the beginning of the input,
  returning the rest of the input.

(Parser@<A@>, String@) { *(A@ x, String@ tail); } Run

And maybe it can do errors too. And this can be fully separate from M@, right?

Might be nice if we can have a running state though. So:

(Parser@<A@>, S@) { *(A@ x, S@ s); }

Where S@ stores info about the string, the location, errors, etc.

Things to write:
 * Parse a character.
 * Parse plain text before next @... command.
 * Parse to end of matching ']' character.
   - Could result in an error if unmatched.
 * Parse command name.
  
---

I bet I can entirely split the parser off from M@. Write code to parse inline
text into a sequence of commands and block text into a sequence of commands.
No need for M@ at all there.

---

I need to update the parse to pass around the current indent level and allow
parsing of indented strings. Otherwise we'll mess up column numbers when
parsing nested block structured text.

This brings up an interesting question. What should be the location for next
line arg in terms of column number? What if it's an empty line?

Loc@ needs an indent field, which defines what the column at the start of the
next line is. That's a separate issue.

Next line argument should be, for example, column 2. If it's a blank next
line, it should be... doesn't matter I don't think.

I need to come up with a test case to capture locations properly. Maybe, parse
a command. Extract the next line argument. Parse that, verify the locations
are set properly. Yeah.

---

Inline and Block parsing is done. What's next?

Let's review all the current use cases of fbld. I'll want to migrate them over
one by one to fble based fbld, I would think.

* build.lib.tcl - @config, @BuildStamp
* @doc --> html
* @tutorial --> html
* @usage --> man (1)
* @usage --> c header
* doc comment --> man  (3)
  - Extract doc comments from file.
  - Convert doc comments to man.
* Core tags syntax check.
* Core tags html back end.
* Core tags man back end.
* Core tags roff back end.
* @tutorial front end.
* @usage --> help front end.
* @usage --> man front end.
* @usage library

Let's start with Core. Core is an interface. In other words, a struct type
parameterized by abstract monadic type M@.

And we have an instance of Core@ for html, man, text, and optionally 'check'.

We don't currently use 'check' anywhere. So why bother with it?

* Define /Fbld/Core% with Core@, some way to convert typed functions to
  generic fble command invocation.
* Define /Fbld/Core/Html% instance of Core@ on an abstract monad with
  OStream@.
* Try and use fble fbld to generate fbld.html.
 - Will need a solution for @FbleVersion, @BuildStamp

Cool. That sounds like a good next target.

What type do we use for the raw types of functions? Before we said
'post-parsed' arguments.

Anywhere we expect ESCAPED, we should accept /Core/String%.String@;

Anywhere we expect INLINE...
  List@<Command@>?
  M@<Unit@>?

Because we can go:
  String@ --> List@<Command@> --> M@<Unit@>

From fble code, M@<Unit@> is most generic.

String@ --> List@<Command@> is either Inline or Block parse.
List@<Command@> --> Core@.* is either Inline or Block invoke.
Core@.* --> M@ comes from the back end.

Where do we put the logic to know if we should inline or block parse/invoke?

We'll want two different Invoke@ functions: one for inline, one for block. So
we can distinguish between tags depending on whether it's an inline or block
context.

We'll have a function from Core@ to *(Invoke@, Invoke@) that defines how to
sub-parse and sub-invoke each argument.

---

Type inference isn't working:

  <@ A@>(M@<Result@<A@>>)<@ B@>((A@) { M@<Result@<B@>>; }) { M@<Result@<B@>>; }
  DoR = <@ A@>(M@<Result@<A@>> ma)<@ B@>((A@) { M@<Result@<B@>>; } f) {
    Result@<A@> ra <- m.do(ma);
    ra.?(err: m.return(Err<B@>(ra.err)));
    f(ra.ok);
  };

      (Command@ cmd, M@<Result@<Unit@>> mx) {
        Unit@ _ <- DoR(mx);
        inline(inline, block, cmd);
      });

In the application of 'DoR':

../pkgs/fbld/Fbld/Invoke.fble|30 col 24| error: expected type M@<Result@<A@>>, but found M@<Result@<Unit@>>
|| Inferred types:
||   A@: ???

Even if I explicitly give the type of A@ as Unit@. Is this expected?

M@ is fully abstract. There's no way to expand that. Do we know that M@<X@>
equals M@<Y@> if X@ = Y@? Or do we not take advantage of that fact?

Yes. we say poly equal and arg equal.

I should be able to step through this in gdb and trace what's going wrong.
It's just a little tedious to get to the right call in gdb.

Because we should say Result@<A@> equals Result@<Unit@>
Which then should give us A@ equals Unit@
Which should infer things just swell, right? Or, I suppose Result isn't
abstract, so we will say:

+(Unit@ ok, String@ err) versus +(A@ ok, String@ err).

And that should work just fine.

---

Found the issue. I have two different abstract types M@ defined at different
locations. Type error is working as intended aside from not making it clear
the difference between two different types with the same name.

---

How should I implement @FbleVersion and @BuildStamp tags?

The way it's implemented in tcl:
* The build script creates a version.fbld.tcl file to define
  inline_FbleVersion, pulling $::version as the value.
* build.lib.tcl defines inline-BuildStamp which executes the buildstamp
  program whever it is invoked, ensuring we have the latest build stamp
  whenever we run the program.

Let's start with @FbleVersion, which seems slightly simpler.

Options:
A. Define /Fbld/FbleVersion% that hard codes the value of @FbleVersion.
 - Remember to update it any time the version is updated.
B. Define /Fbld/FbleVersion% that reads the raw value from
  /Fbld/FbleVersion/Value%, or some such. Have the build script auto-generate
  that /Fbld/FbleVersion/Value% file as, /Core/String%.Str|'...';
C. Hard code the version, but add a test that it matches what's defined
  elsewhere.

(B) sounds easy enough to me. I can't think of any other sane options. The
only trick with (B) will be figuring out how to add the generated code to the
include path.

Let's think about @Buildstamp next, which is trickier. The goal is to get the
latest value of buildstamp every time you run, e.g. fbld-html-doc.

Maybe that suggests we should read the buildstamp value from a file when
fbld-html-doc starts? Or... should we add an 'exec' option to Stdio@ for
executing other programs?

How do we want generic 'fbld-html-doc' and fble build specific @FbleVersion
and @Buildstamp to work? It's like, how do we add custom tags after the fact?
Should I worry about that for now, or don't care and worry about it another
day?

---

Another challenge: implementing the @code tag. Can we reuse source-highlight
from within fble? How?

I think we need exec support to be able to compose with other programs. That
will let us reuse source-highlight (assuming we can find the path to it in some reasonable way?) and buildstamp (again, assuming we can find the path to it).

I'm thinking, for exec, also have a 'fifo' function to return IStream/OStream
pairs, then pass stdin and stdout streams as an argument to exec along with
command line arguments. It forks off the process to execute in the background.
Maybe we return an M@<Int@> to be able to block on and fetch the exit status of
the process.

Another approach would be to re-implement source-highlight equivalent in fble.
Sounds like an interesting program to try and write. The trouble is, there are
a lot of languages to have to support.

---

I've finished fleshing out the core tags. Going to have to decide what's next
to work on. A few options:

* Add a markdown backend so we can generate README.md.
* Implement mapping from foo.fbld to foo.html for @fbld html backend.
* Figure out how to specify libraries like spec/fble.fbld.tcl
  Where to put the .fble file?
  Do we want a separate binary for this other than fbld-html-doc?
* Figure out how to implement @FbleVersion
* Figure out how to implement @BuildStamp
* Figure out how to do source highlighting for @code

---

We want users to be able to supply their own front ends and own back ends, and
have different front ends and back ends be combined together.

I claim this cannot be done today in fble with a compiled binary.

To pass a new front end or back end to an existing compiled binary, you need
some way to convert the .fble code into its corresponding fble value at
runtime, dynamically. Options:
* Put the .fble code into the compiled binary, pass a name as a reference to
  the code. But this doesn't allow new code, it only allows code in the
  binary.
* Come up with a different syntax for implementing tags that can be parsed
  and loaded from fble. But then we are not using fble to implement tags.
* Implement a parser for fble that can turn it into a value at runtime. But...
  we would need an interpreter in fble?

The point is, unless we have some magic way to take a String describing a
module path or .fble filename and dynamically load it, we can't pass new fble
modules on the command line as arguments.

The other route is for the user to provide the main function. Then they can
pass whatever code they want. They can run the interpreter or compile it if
they so choose.

---

What is a front end? It would be nice to have a specific type for frontends so
you can easily combine them.

Front ends are built on top of Core@, and possibly other front ends. There are
two ways we may want to use a front end:
1. Directly.
2. As markup.

To use a front end directly requires knowing the specific type of the front
end. To use it as markup just needs generic Markup@ for Inline and Block.

Core@ is special because it is an interface, not an implementation. Other
markups can pass around their implementation directly as functions to be
called.

So, I expect a front end is an fble module that takes Core@ as an argument and
defines a function for each tag supported by the front end, and Inline and
Block Markup@.

Having modules be functions is starting to be problematic. Consider a front
end B that depends on front end A, and both depend on core.

B wants to access A directly. We'll end up invoking the A module function
twice: once when defining B, and once at the top level. That does not scale
well.

An alternative is to provide A as an argument to B. But that is like exposing
internal implementation details. Whoever is using B shouldn't have to care
about whether B uses A internally. They do need to care that B uses Core
internally, because the user has to provide the backend implementation of
Core.

Well, it all happens during setup, and these functions aren't called that
much, so maybe don't worry about it for now.

A related thing is having false dependencies. For example, Core module takes
M@ and Monad@<M@>. It exports Core@, which doesn't depend on Monad@<M@>.
That's a false dependency introduced. If the user only uses Core@, it
shouldn't need to provide Monad@<M@>.

We could address this by splitting up Core into the type and the
implementation. Either as separate modules, or within the same module as, e.g.

@(Core@, (Monad@<M@> m) { ... @(InlineMarkup, BlockMarkup); } Impl);

Again, let's not worry about it for the time being.

Next issue: it's slightly annoying to pass around everything as inline or
block. Can we unify somehow? Ideas:

Don't distinguish between inline and block markup. Use a single markup for
everything. This means you can't have a tag interpreted differently for inline
versus block markup. The only place we do this right now is the default inline
and block tags, both called "". But we can give those separate names if we
want, like "_inline@" and "_block@".

That way you could use any markup in either context. Umm... that's a little
concerning. What does it mean to use section@ in an inline context? And @l in
a block context? For it to make sense, we would have to do different
processing for tags in each. No, I prefer to type a tag based on inline or
block context.

The other idea is define a type Markups@, or some such, that has two fields,
inline, block. Then we can more easily name, pass around, and combine things.
We could do the same for Invoke too perhaps. invoke.inline and invoke.block.

---

Say we want to pass around a single invoke function instead of two. How would
we represent that?

@ Context@ = +(Unit@ inline, Unit@ block);
@ I@ = (I@, Context@, Command@) { M@<Result@<Unit@>>; }

Invoke.Inline becomes: invoke(i, Inline, cmd);
Invoke.Block becomes: invoke(i, Block, cmd);

Now markup can become an abstract type where you can insert entries as Inline
or Block.

The reason this is better than what we have today is because we can pass
around a single Markup@ object that stores both inline and block tags. I think
it's worth trying.

Does it make sense to do other cleanup while I'm at it?
* Separate different types out of /Fbld/Types%?
* Make a better monad transformer for M@<Result@<T@>>?
* Get rid of R@ helper type.
* Use a name other than String@ for Fbld String@, so we can using String@ for
  /Core/String%?
  Like, StringL@. That's not bad. Let's do that.

---

I'm thinking we want two different types. I'm not sure what to call them:
1. A function that takes global context and a command and executes the
command.
2. A global context, which is a pair of invocation functions, one for inline,
one for block.

Brainstorm of names:
* Invoke@, Context@.

Anything better than Context@ for (2)?
* Env@ is better.

So, what do define where?
* Command@
* Invoke@, Env@
* Invoke.Inline, Invoke.Block - that parse and execute structured text.
* Is Markup@ the right term to use? Or would that more often refer to the text
  itself rather than the tag definitions?

My vote:
* Command@ should be separate from Invoke@, because Parse doesn't need
  Invoke@.
* Invoke@ and Env@ must be defined together, because they depend on each
  other. I think Invoke% is fine for this.
* Maybe Interpret.Inline, Interpret.Block? Exec? Eval? Impl? Run?
  I like Exec or Run. Let's say Run, because it is a complete word.
* "markup" means the marked up text, not the tags. What other name could we
  use? Markup Language? Language?
  - This brings an interesting idea: should StringL@ be renamed to Markup@?
    No. I don't think so.
  How about Schema@? Tags@? Honestly, I like Markup@... Maybe think of it as
  the definition of what markup elements can be used in the doc. Yeah. Let's
  go with that.

We have our answers. Get to work.

---

The markdown backend makes things difficult:
* You can only define labels on section headers?
* It just feels like a ton of work to do properly.

Is it worth trying to do properly for real? In case it reveals issues with the
general structure of how fbld is implemented? Like, I fear I'll need to track
some other internal state for text wrapping and indentation and nested lists.

Anyway, the generated README.md looks fine to me except for @FbleVersion and
@BuildStamp not being implemented yet. Maybe let's focus on those first. If I
can generate README.md, then set up the template to have it checked in and
tested against the generated version, that will be great.

Actually, I should remove @BuildStamp, because we don't want it changing every
time. I don't think @BuildStamp is so important for that. That means we just
need to figure out @FbleVersion.

---

@FbleVersion is taken care of now. Let's revisit @BuildStamp.

@BuildStamp is intended to capture the version of the documentation. If we
left it in, we want it to execute buildstamp at the time the document is
produced, not at the time we build fbld-html-doc or whatever.

There are two ways to do that:
1. Pass it as a command line argument when we run.
2. Have fbld-html-doc be able to execute buildstamp at runtime.

For README.md, I'm thinking of checking it into source code. It's pretty
annoying if we keep modifying it for every buildstamp.

The fact is, we don't expect README.md to change for every git sha.

Could we update buildstamp and only check it in when README.md changes
otherwise? That way the buildstamp would be accurate, we would have a build
stamp.

On the other hand, buildstamp of index.html kind of represents the buildstamp
of the entire set of documentation, which certainly could have changed. And I
like having the build stamp in the website documentation. It's really nice
that it has the date along with the documentation.

What if, instead of saying README.md is a source file and we check it against
a generated file, instead we generate README.md from ninja directly to source?

But that means the build process dirties the source, which could mess up
buildstamp for other docs.

I could be really hacky and not implement buildstamp especially for markdown
backend. Because README.md is only expected to be read from github when you
can easily check what the git sha is.

I'm going to want to implement @BuildStamp eventually. How about this:
* Pass @BuildStamp as an argument to the main function. We can easily call it
  as part of the build command. For README.md we can pass "" as the build
  stamp, or HEAD, or something like that.

Sounds good.

