State Monad Performance
=======================

Here's the do function for state monad:

  R@<A@> ra = ma(s);
  f(ra.x, ra.s);

ra is a struct. If ma is a recursive call, we allocate the struct in ma,
GcRealloc it on return, then access its fields and throw it away. The
GcRealloc is costing us too much. It's no good to do an allocation every
iteration of a tightly nested loop that we are just going to throw away right
away.

Now, if we had code like:
  
  M@<String@> GetLine = {
     Maybe@<Char@> mc <- m.do(I.GetChar(in));
     mc.?(nothing: m.return(Str|'');
     String@ tail <- m.do(GetLine);
     m.return(Cons(mc.just, tail));
  };

We run into this, because GetLine is in the 'ma' args slot to do in the
recursive call. If we were okay getting the reverse list, we could instead
write this as:
     
  (String@) { M@<String@>; } GetLine = (String@ read) {
     Maybe@<Char@> mc <- m.do(I.GetChar(in));
     mc.?(nothing: m.return(read);
     GetLine(Cons(mc.just, read));
  };

In this case, the only call to do has GetChar in the ma slot, and I assume we
merge stacks on that because it's not a recursive call, so we don't pay
any GC cost for the intermediate result value.

Is it faster to write the code like this, and insert a Reverse call in
m.return? Probably. I should try it. I wouldn't like it to be though.

Can we come up with a better solution that doesn't require rewriting code?

What we need is for the intermediate struct value to be allocated on the
callers stack. Options:
* merge stacks so that callee stack is shared with caller.
  Can't do this forever, blows up memory use. But maybe we only need it one
  layer at a time or some such?
* ???

---

Options:
A. Copy the allocated struct from the callee stack to the caller stack.
B. Allocate the struct into the caller stack directly.
C. Allocate the struct at the start of the callee stack, and bump the caller
stack past that to include it on pop frame.

(C) sounds pretty reasonable to me conceptually. A function hopefully knows
what it is allocating to be returned to the caller versus what is just
temporary. Hopefully it can reorder things or reserve space or something to
put the object where it needs to be right away. Then, in FblePopFrame, we have
the ability to copy back any size object on the stack to the caller.

Currently we have a fairly elaborate frame structure that makes this
challenging, because it gets in the way. You could imagine keeping the frame
structure on a separate stack so that isn't an issue.

I want to step through the code with a debugger to get a better sense of what
it looks like. Just in case there's something going on I'm not aware of.

Observations from gdb:
* The stack is absurdly deep. What's with that? #2138 frames deep.
* The PartialApplyImpl is happening to /Core/Monad/State%.Monad!
  Specifically the do function. This must be us supplying the final state
  argument.
* The 'ma' argument is the PartialApplyImpl for Monad itself.
* The 'f' argument is /Pprof/Perf%.Parse!.GetLocs!
  Which is the otherwise anonymous function from Maybe@<Char@> to
  M@<List@<String@>> in GetLocs.

Note that we don't do any allocations in GetLocs directly. It's all via helper
functions like return, Cons, Str, List. That's means for an approach where we
allocate to the front of the frame to work, it has to be able to go through
multiple layers of functions.

Should I experiment again with FastCat to see if we see similar performance
issues there? Or just to have something much similar to better understand
what's happening?

Well, first I need to fix fastcat, because it crashes. I should add a test for
it too.

---

/usr/bin/time -v cat < scratch/pprof.input.txt > /dev/null
  Elapsed (wall clock) time (h:mm:ss or m:ss): 0:04.36
  Maximum resident set size (kbytes): 1428

Looks like there's a memory leak or bug in the --monadic option to fast-cat. I
should fix that. Also, let's truncate the input file to just the relevant
lines.

/usr/bin/time -v cat < scratch/pprof.input.txt > /dev/null
  Elapsed (wall clock) time (h:mm:ss or m:ss): 0:00.05
  Maximum resident set size (kbytes): 1348

/usr/bin/time -v ./out/pkgs/core/fble-fast-cat < scratch/pprof.input.txt > /dev/null
  Elapsed (wall clock) time (h:mm:ss or m:ss): 4:04.76
  Maximum resident set size (kbytes): 1760

What's the memory leak in the --monadic case? How do I track that down?

Let's do some profiling, shall we? Maybe that will tell us.

Why are my stacks so deep? I don't expect that, right? Or maybe I do?

(World@) { R@<Bool@>; } MCat = m.do(Stdin, (Maybe@<Int@> byte) {
  byte.?(nothing: m.return(True));
  Char@ char = /Core/Char/Ascii%.Chr(byte.just);
  Unit@ _ <- m.do(stdout_(/Core/Char/Ascii%.Ord(char)));
  MCat
};

MCat is a partial application of do, because we don't have state at this
point. The state comes from the stdio runner. We were over-applied on the
state though, so once we return the partial apply from the monadic.? case
statement, we should then apply the state. What happens?

We call do body:
  r = Stdin(w)
  tail call into (Maybe@<Int@> byte) { ...}

The byte is not nothing.
  Char@ char = /Core/Char/Ascii%.Chr(byte.just);
  m.do(stdout_(char), MCat);

But we should have over applied. And m.do should be a tail call. The stack
shouldn't be going so deep here. What's going on? Let's step through the code
and see?
  
What I see is that PartialApplyImpl isn't doing a tail call, so we end up
smashing the stack and not cleaning other stuff up while we are at it.

This is clearly a bug. I should be able to capture it in a memory test. The
case is doing a recursion where the tail call is applied to a partially
applied function.

---

Okay, that bug is tested and fixed. Unfortunately it doesn't solve the
problem. I'm still leaking memory in fble-fast-cast --monadic.

For the fun of it, let's see if that impacted the performance of pprof at all.

  /usr/bin/time -v ./out/pkgs/pprof/fble-pprof-report < scratch/pprof.input.txt

  Elapsed (wall clock) time (h:mm:ss or m:ss): 9:23.42 ==> 9:04.10
  Maximum resident set size (kbytes): 254964 ==> 253564
 
Anyway, we're still smashing the stack in fble-fast-cat. Here's the sequence:

We're doing a TailCall. The result of the tail call is a function. But we have
an unused argument.

Can I figure out what the result of that tail call is? That's what I really
want to know.

It's PartialApplyImpl, /Core/Monad/State%.Monad!. I bet it's our MCat function
being returned?

How do I make a test case for this? The case is:
* We are doing a tail call with over-applied args.
* The result of that tail called function.

What should happen is we continue in the TailCall loop, if we have enough
args?

Anyway, first step is to add a regression test. How do I make this? Can I
understand where it's coming from in the first place?

MCat returns a function. The state argument is presumably what's overapplied.
Any reason the test I just wrote for partial tail call memory doesn't hit this
case?

Overapply means a function that returns a function, without being defined as a
function itself.

I need a tail call that returns a function. For it to be a call means it takes
at least one argument. For it to return a function means it takes at least two
arguments. The recursion has to be controlled by Nat@ to know when to end, so
that has to be the first argument. The second argument can be Unit.

So, our function takes a Nat@, and returns a function from Unit@ to Unit@.
That's easy enough.

The real question is, can I convince myself this should be doable in constant
memory? Let's see.

f(5), tail calls f(4). That's constant.
f(4) tail calls f(3). That's constant.
...
f(1) returns Id function.
Then we call the Id function.

Yes. This should be constant? So long as we GC, right? We have to GC each
partial application of f? No. There are no partial applications of f. It has a
single argument. You can't partially apply that.

Yeah, this should be clearly constant memory use.

And... it is. We didn't catch the case I was hoping to apparently. Maybe
because we aren't over-applying every step of the way? That makes sense. How
can I overapply every step of the way?

Okay, I maybe got it. Let's double check.
  
(Nat@, Unit@) { Unit@; } f = (Nat@ n) {
  S@ s = S(n);
  s.?(Z: (Unit@ u) { u; });
  (Unit@ u) { f(s.S, u); };
};

f(4) returns a function that references f and s. We tail call that function.
f(3, u) is our recursive overapply. It returns a new function.

We are certainly allocating new functions at every iteration. But GC should
take care of us, right?

Let me get into the stack if this specifically and see what happens. Yes, the
stack looks like the fble-fast-cat case.

Now, how do I solve this one?

We have a function. We have only unused arguments. Where do those unused
arguments come from? What do we know about the function?

The real fear is that the function itself or some of the unused argument
values live in the current frame. I need to copy them out. Have we already
copied them out? We already take care of that I think. Let me see.

Looks like it's working. Awesome. Let's see if that was the last of the
fble-fast-cat memory leak. Yup! We got it. Cool.

/usr/bin/time -v ./out/pkgs/core/fble-fast-cat --monadic < scratch/pprof.input.txt > /dev/null
  Elapsed (wall clock) time (h:mm:ss or m:ss): 5:07.26
  Maximum resident set size (kbytes): 1716

The non-monadic took 4 minutes, so I expect at least that much time spent
here.

And for the fun of it:

  /usr/bin/time -v ./out/pkgs/pprof/fble-pprof-report < scratch/pprof.input.txt

  Elapsed (wall clock) time (h:mm:ss or m:ss): 9:23.42 ==> 9:04.10 ==> 9:19.40
  Maximum resident set size (kbytes): 254964 ==> 253564 ==> 253444

Oh well. You win some you lose some.

---

25% overhead for monadic version of fast cat actually isn't too bad. I think
it's worth look at fast cat in more detail performance wise to start. See
if/how we can optimize it.

First, the non-monadic version.

Flat Profile by Self Time
-------------------------
    %     self  block
19.49    14298  FbleCall[0006X]
11.36     8336  FbleNewUnionValue[000bX]
 7.83     5747  FbleFuncValueFunction[000fX]
 7.56     5548  FbleStructValueField[0010X]
 6.61     4853  FbleUnionValueTag[0012X]
 6.42     4710  _2f_Core_2f_Int_2f_IntP_2f_Map_25__2e_Lookup_21_.0021[000cX]

Breaking down into higher level chunks:
 47% Ascii.Chr
 15% IStreamImpl
 13% OStreamImpl

Okay, let's compare now to the --monadic version. If we are interested in
optimizing the monad performance, it's the difference between these that we
care about.

Monadic is 15% slower. Not bad actually.

* We are adding another FbleCall into the stack, so we get additional overhead
  from that.
* More calls to FbleFuncValueFunction.
* PartialApplyImpl is showing up. That's adding 4% of the 15% it looks like.
* Calls to memcpy have increased noticeably, due to increase in FbleCall and
  FbleTailCall, and the addition of PartialApplyImpl.
* More calls to FbleTailCall, from the monad and from PartialApplyImpl.
* Calls to FbleNewFuncValue that we don't have before. That must be from the
  nested do.

Interestingly, a lot of the data accesses seem to be faster in the monadic
version. Maybe that's just a trick of how sampling works?

Anyway, it seems not so unreasonable. If we can make things a little bit
faster, it will help everything.

Any way we can avoid the extra FbleNewFuncValue calls?

I'm not seeing the big GC cost I get in pprof, but that's because we do the
recursive call through the 'f' argument to do, never the 'ma' argument. That's
probably the issue I really want to address here.

Let's see if we can't do some small optimizations here and there. Starting
with memcpy.

Uses of memcpy:
* PartialApplyImpl
  Copies function statics to nargs
  Copies args to nargs
* PartialApply
  Copies args into statics
* TailCall
  Copies gTailCallData args in to 'args'.
  Copies unused args into gTailCallData args, 2 branches.
* FbleCall
  Copies unused args into gTailCallData
* FbleTailCall
  Copies args into gTailCallData.
* FbleNewFuncValue
  Copies executable into function value.

In the non-monadic version, all samples are from FbleCall, then FbleTailCall.
The monadic version also has PartialApplyImpl.

The FbleTailCall case is a little sad, because the callers start by collecting
all the args into an array. Then we copy those straight to another array. It
would be really nice if we could have the callers copy to the right array from
the start.

But that means breaking of abstractions. Is it worth it? You know I'm going to
want to break abstractions for performance eventually, right?

Yeah, FbleTailCall is really silly. Much better if we could get callers to do
the right thing in the first place. We could maybe even remove any calls into
fble? If we're willing to share the internal implementation of tail call with
everyone...

FbleTailCall is just under 4% of the pprof profile. We could get 4% savings if
we optimized things. That's a decent amount.

Can you remind me why we group func_and_args together in gTailCallData instead
of having func as a separate field?
* It's because of CompactFrame, so we can pass everything more easily. Fair
  enough.

Here's what callers would have to know about tail calls:
* There is a dedicated buffer you need to use to convey function and args.
* You have to check if the buffer is big enough and resize as needed.
  It should almost always be big enough. But still you have to check.
* Set the size, first arg is the func, then rest of the args.
* Then return this magic value to indicate to the caller you are doing a tail
  call.

I should be able to get the compiler to tell me the max size of the buffer, so
we don't have to worry about checking and resizing it. Do it based on the
function type with most arguments seen during compilation. We could never
apply more args than that. No need for capacity or resizing that way, which
will be nice.

FbleTailCallData can have the structure.
FbleTailCallSentinel can be the magic value. Or FBLE_TAIL_CALL_SENTINEL?

It's not that bad. Except, if we don't have an intermediate function, we break
anyone anytime we need to change how tail calls are done.

Maybe we could compromise with an FbleTailCall you call after filling in the
FbleTailCallData elsewhere? Or at this point, it doesn't seem worth having an
overhead. Just take the cost of everyone knowing about a tail call.

It's not that bad, right?
* C backend
* aarch64 backend
* interpreter
* value itself

Yeah, that seems not so bad. And it's heading more in the direction I want to
go of inlining stuff for real performance. What do you think? Shall we try it?
Shall we document it very clearly?

The hardest part is probably computing the max size needed for the buffer. I
can start with that separately.

Conceptually it seems reasonable. We need to return the arguments to the
caller, potentially multiple callers up the stack. We can't do that on the
stack itself. So return the function and arguments in a global, short lived
side channel.

Technically we use the result in the following places:
* TailCall, FbleCall

So we could allocate the buffer there and pass it in. But why bother? No need
to pass a buffer we could hard code everywhere. At least until we go to make
a multi-threaded implementation... In which case we can turn it into a thread
local buffer?

---

The compiler could store the max func type either with a function when you
allocate the function, or with a module. We can do the capacity check when
allocating the function or when allocating the module.

The compiler can check for max func type by looking at the type of the
function any time we do a function call. Hmm... But what about an abstract
function call? For example, (Int@) { T@; }, where we don't know T@? Can we
rely on the caller to know in case of overapplied args?

Conceptually we could keep the tail call buffer as part of the value heap.
Practically that's a bit tedious, because it means an extra layer of
indirection and another violation of abstraction required. We could allocate a
sentinel value as part of the heap too, instead of having to hard code a magic
number for it. Maybe keep part of FbleValueHeap* public?

Review of max size needed for tail call buffer:
* Tail call instruction knows how many args are needed.
* PartialApplyImpl does statics + args. Hmm... It's hard to know there, isn't
  it? This comes from PartialApply, and would be limited by the function type.

In other words, a function type should be sufficient, right? Or, when we
allocate a function, it's type? Or...? I'm not sure.

If we just look at calls, we'll miss the partial apply case. For example:

  F@ f = foo(a, b, c);    # three args.
  f(d, e, f);             # three args.

But foo takes 6 args.

Can we get into this case without knowing the type of foo? Or maybe we can
say, allocate double the max number of args applied at any given time, because
you are always applying to the value, and that value can worst case be a
partially applied thing, and ...

Could we create a function with an unbounded number of args?

(Int@, Int@, A@) { A@; } f = (Int@ x, Int@ y, A@ a) {
   a;
};

g = f(1, 2, f(3, 4, f(5, 6, f(7, 8, Unit))));

What happens here?

If we start with f(1, 2), we create a partial apply. Then ...

I'm not sure. It's hard to tell what could happen at runtime.

g = f(1, 2);      # PartialApply with 2 args.
h = g(f, 3, 4);   # Apply f, over apply with 2. Total of 5 needed.

Okay, so I'm thinking 2x might be good enough? Or not.

(Int@, ... Int@) {...} f = ...

g = f(1, 2)
h = g(3, 4)
i = h(5, 6)
...

We have to take the function type into account. Maybe: take function type into
account, then double that? The double is needed to get around the poly thing.

Or, we just need double the number of args expected by a function? Because
worse case, N args can lead to a PolyApply with N-1 stored up?

No, because I could still do:
f = (Int@ x) { ... (Int@ y ... }

f(1, 2, 3);

Ah. Okay. So really what I want is the sum of:
  A. Max num args expected by a function.
  B. Max num args applied to a function.

(A) represents the most we can store up in a PolyApply. (B) represents the
most we can extend to that. No need to worry about polies or deepest size
type. This is a straight forward calculation.

Cool. I'm happy with that. Take (A) + (B). You can add an extra 1 if you want
for the function, but really it should be (A)-1 + (B) + 1 for the function, so
(A) + (B) should suffice.

Cool. So really the questions are:
* Where to store (A) and (B)?
* Where to store the tail call buffer, the value heap or a global variable?
* Whose job to expand tail call buffer based on (A) and (B)?
  Depends where we store it. If we store with a function, then check when we
  allocate the function. If we store with a module, check when we allocate the
  module.

Here's what I suggest:
* Add (B) to FbleExecutable.
  Too bad we need to make that slightly bigger, but oh well.
* Move tail call buffer to FbleValueHeap.
* Add fields for (A) and (B) to fble value heap too.
* Check size of tail call buffer on allocation of new function.
* When we are ready, expose the buffer and sentinel fields from FbleValueHeap
  to allow direct access by backends.

Ready to give it a try?

On second thought, I don't need special handling for PartialApplyImpl. I know
exactly how many args we are going to pass for that. I'm more worried about
the unused args case. Double check that.

Cases to worry about:
* TailCall does a tail call when we have some unused arguments to the original
  call. We know max number of args coming in and max number of args to add. So
  no big deal, right? Just do double max_tail_call_args.

  Also, That's internal for now. I can keep it internal? No special handling
  needed on the first pass?
* Tail call returns a function with unused args. We know unused args is
  bounded by max_tail_call_args.
* FbleCall does a tail call with unused.
  This is max_tail_call_args + max_call_args, right?

The real trick is coming up with upper bounds for num_unused. What say you?

num_unused is argc - exe->num_args. Cases:
* argc is from a tail call. So max_tail_call_args gives us an upper bound.
* argc is from FbleCall.

Okay, so worst case is we have an FbleCall with a whole bunch of overapplied
args, and that returns a tail call which has its own args.

For example:
   f(1, 2, 3, 4, 5, 6, 7, 8, 9, 10);

Where f takes a single argument and returns a function. The function is a
result of doing a tail call...

Basically I need to record max call size, not max tail call size. Then we want
to ensure the buffer is double the max call size. No need to worry about num
args anywhere. That is apparently not relevant, because PartialApply knows how
to properly set max_tail_call_args based on that.

Careful:
* Special handling needed for FbleApply? Yes. Add another check there.

So our math is: 2x max_call_args needed, because we know num_unused is bounded
by (max_call_args - 1) and args is bounded by max_call_args.

---

The tail call change is made. Backends are all using the tail call buffer
directly now. Let's see what performance looks like.

My estimates base on profiling:
* 5% improvement on fastcat non-monadic
* 6% improvements on fastcat monadic
* 3.7% improvements on pprof.

/usr/bin/time -v ./out/pkgs/core/fble-fast-cat < scratch/pprof.input.txt > /dev/null
  Elapsed (wall clock) time (h:mm:ss or m:ss): 4:04.76 ==> 4:04.69
  Maximum resident set size (kbytes): 1760 ==> 1896

/usr/bin/time -v ./out/pkgs/core/fble-fast-cat --monadic < scratch/pprof.input.txt > /dev/null
  Elapsed (wall clock) time (h:mm:ss or m:ss): 5:07.26 ==> 4:37.17
  Maximum resident set size (kbytes): 1716 ==> 1900

/usr/bin/time -v ./out/pkgs/pprof/fble-pprof-report < scratch/pprof.input.txt
  Elapsed (wall clock) time (h:mm:ss or m:ss): 9:19.40 ==> 8:36.76
  Maximum resident set size (kbytes): 253444 ==> 253592

Nice benefit from monadic fble-fast-cat. I wonder why non-monadic
fble-fast-cat didn't benefit from this. It definitely should have. Maybe my
baseline is wrong?

Anyway, I think this is a good change.

