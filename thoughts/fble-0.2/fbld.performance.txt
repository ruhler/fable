Fbld Performance
================

Now that we've completely redesigned and implemented fbld, let's see if we
can't make it run a little faster.

Specifically, there are a lot of library man pages to generate. Each one takes
a couple seconds. That adds up to a long wait time. I would love to cut that
time in half if possible.

$ time ./pkgs/fbld/bin/fbld ../fbld/nobuildstamp.fbld ./fbld/config.fbld \
./fbld/version.fbld ../fbld/man.fbld ../fbld/dc.man.fbld \
./include/fble/FbleEval.3.fbld
real    0m1.750s

Fble based profiling says:
 44% in /Fbld/Parse%.Parse
 36% in /Fbld/Eval%.Eval
 15% in /Core/Stream/IStream%.GetChar

perf based profiling says:
 72% in /Fbld/Parse%.Parse

It's hard to get more clarity than that from the perf profile. I kind of wish
everything didn't go through FbleThreadCall. That really muddies the picture.

Let's focus on the parser. It's tough to tell from the profile, because
everything goes through Do. Once again, it would be nice if there was some way
to eliminate that to avoid muddying the picture.

Ideas from reading the code:
* Do we need a State monad? Can we use just a Reader monad?
  - It's not like we are writing output.
  - I don't think we can use a Reader monad. We need to track unconsumed
    output.
* Compute GetL_ up front as a list of CharL@?
  - To avoid having to redo GetL_ over and over every time we Try_ or Test_
    and fail?

Remember that perf profiling shows most of the time due to allocations. Can we
see who is doing those allocations? Should we increase the cost of
instructions that allocate for prof purposes?

According to perf, there are 909 allocations. They are:

         63       70           FbleNewStructValue_.constprop.7[0025]
         94      122           FbleNewLiteralValue[0005]
        150      159           FbleNewUnionValue[0010]
        266      292           FbleNewFuncValue[001e]
        328      349           FbleNewStructValue[0027]

This is odd. Let's focus on FbleNewFuncValue, which normally I don't expect to
see much of.


         17       17           _2f_Fbld_2f_Result_25__2e_Do_21_.000d[0057]
         23       24           _2f_Fbld_2f_Parse_2f_M_25__2e_GetL_21_.0058[003f]
         25       31           _2f_Core_2f_List_2f_Ord_25__2e_Ord_21_.0009[001d]
         32       33           _2f_Fbld_2f_Parse_2f_M_25__2e_Do_21_.002b[0047]
         43       46           _2f_Fbld_2f_Parse_2f_M_25__2e_Return_21_.0023[002
         54       57           _2f_Fbld_2f_Parse_2f_M_25__2e_Do_21__21_.002d[003
**      293      319       26  FbleNewFuncValue[001e] **

Do and Return are kind of expected, because they are structured as functions
that return functions to work with bind syntax. What about List Ord?

List Ord takes the ordering function separately. We should be able to factor
that out. That's the recursive call to Ord itself.

---

It's like the whole monadic construct involves allocations everywhere.
Particularly the parser one. We are allocating every time we 'try' and fail.
For example, allocating an error message that we just ignore in the end.

Is there any way to structure the parser monad so that it doesn't allocate all
over like this?

The reason results are turning into object allocations instead of being small
enough to be packed is because of the error message that we often throw away.
In theory we could use different variants on the function if we know we are
going to throw away the error message.

In the case of success, we need to allocate a heap object because we have to
have space to store the 'tail' pointer with the rest of the text to parse.

Could I change the parser monad to be a parser generator monad? Have it
somehow work out all the smarts to generate an efficient function that doesn't
do unnecessary allocation, while preserving the same kind of description?

I think it might be possible. We'll presumably want some restriction that
decisions made during parsing don't depend on the parsed result. They only
depend on whether parsing succeeded or not.

---

Let's start simpler. Say we have two kinds of parser types:
 * M@ is as today - parse and returns a value or error.
 * Parses@ - parse, but only indicates pass/fail, does not return a value or
   an error message.

Assuming Parses@ is much faster implementation wise, we do as much as we can
in Parses@. How much can we do there in practice?

* Try: wants to ignore error message, but not value.
* Test: Can ignore error message, but not value.
* Or: Could probably change to take M@<Unit@> as argument, then ignore both?
* Try_: Can ignore error message and value.
* Test_: Can ignore error message and value.
* EndOfInput - Can probably ignore error message and value.
* String - Can probably ignore error message and value.

I think I can do this incrementally. Slowly move things over to a Parses@ type
and see how far it gets me.

---

I don't know. It doesn't feel like this is going to be significant. It feels
like micro-optimizing. Maybe better to start by inlining common operations?

Let's focus on Or to start, which is only used with String matches right now.

And Do(Test_(...))?

It's like I want a minilanguage:

String :: String@ -> P@
Or :: P@ -> P@ -> P@
DoTest_ :: P@ -> (Bool@ -> M@<A@>) -> M@<A@>

How much time do we spend in Or? In Test_?

From perf profile, best I can tell is it's the regular use of Do that is
causing allocations which is hurting performance. Can we isolate how much of
those calls to Do could be a simplified Do_ that doesn't return value/error
message?

---

Okay, here's what I'm thinking. We want a variant of M@, call it M_@, that
ignores the error message but keeps the return value. For M_@<Unit@>, it
should be able to pack without having to allocate an object.

Let me work with this and see how far I get.

---

What we get to is:
* Return, Do, etc. glue functions want variants for M@ and M_@.
* Things that cannot return an error may as well use M_@. We can wrap in
  M(...) if we ever need to convert.
* Some functions an return errors, but in some cases we may want to ignore
  those error messages. In those cases, provide both M@ and M_@ variants.

Performance numbers: This is about 30% improvement. The number of object
allocations is cut in half.

Hmm... This feels sad. Do I want to take the change?

One thing we could do is generalize Result@ to include a second kind of error:
an unexplained error. That way we don't need two different types. That makes
it simpler in some cases, but we get less help from the compiler in other
cases.

Could we make it part of the reader? Like, have an extra option which says if
we want to return an error message or not. The functions Try_, Test_, etc.
will all say: run without recording the error message. Do this in combination
with expanding Result@ type.

That way, no need to duplicate any logic. No need to deal with messy types.
Everything can work in both contexts efficiently.

I like that idea. Let me save and back out my current changes and try that
alternative approach.
