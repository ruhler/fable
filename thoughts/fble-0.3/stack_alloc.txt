Stack Allocate
==============
Exploring whether we can do stack allocations to improve performance of fble.

The idea stems from the problem of function allocation.

The following allocates an intermediate function object:

  foo(a)(b)

The following does not:

  foo(a, b)

One way to think about the difference is in the second case we effectively
allocate an intermediate function object, but we do so on the stack as a pair
(foo, a). Thus we never need to allocate a heap object, so we don't incur the
costs of malloc or GC.

Can we somehow enable stack allocations for foo(a)(b) so we don't have to pay
the extra cost there too? And in particular in more complicated cases such as
monadic bind where the application of argument a is separate from the
application of argument b in the code.

Review of memory management. There are a few different categories of kinds of
objects:
* Packed values.
 No need to manage, we copy everywhere.
* Explicitly owned reference
 There is one clear owner of an object. The memory for the object can be
 reclaimed when the owner is done with it.
* Reference counting
 There is no single owner of an object. The memory for the object can be
 reclaimed when all the owners are done with it.
* Cycles
 There are reference cycles in the object without a clear owner. Typically we
 need more advanced GC to handle this case.

Currently in fble we treat everything as either packed values or potentially
having reference cycles. We don't take advantage of explicit ownership or
reference counting opportunities.

Memory management is made hard by references. Without references, everything
would be passed by value, you make copies.

References work as follows:
* A packed value 'ref' copied around everywhere.
* An allocated object 'obj' that stays put.
* The lifetime of 'obj' must be at least as long as the lifetime of 'ref'.
* The lifetime of 'obj' should not be significantly longer than all of the
  references to it.

The reference requirements are ensured by the current gc algorithm. If you
take a new reference to an object, that causes the obj to stay alive at least
as long as the reference. Once all the references to an object are gone, the
object will (eventually) be freed.

Consider a function. It has:
* Input arguments, guaranteed to stay alive longer than the function.
* Output, required to stay alive longer than the function.
* Local variables
 - If not captured by the output, don't need to stay alive longer than the
   function.

A key question about an object is: is it (potentially) captured by the output.
If the answer is no, I claim it could be stack allocated and automatically
freed when the function exits.

Let's pretend we have some memory heap associated with every function call,
and we can dynamically allocate as much memory to that heap as we want. We can
label these heaps based on position in the stack. Say the label is the number
of stack frames below this stack frame, so that inner calls have a higher
number id than outer calls.

If you have two heaps with ids x and y, if x > y, then the lifetime of all
objects in y is greater than the lifetime of all objects in x.

An object in heap x can freely refer to an object in frame y without
additional tracking. An object in heap x can refer to an object in frame x,
assuming we free everything in frame x all at once. An object in frame y
cannot safely refer to an object in frame x, because the reference in y would
outlive the object in x.

Let's say, when a function is called, it is provided the heap where the result
of the function should be allocated. Maybe it also needs to know the heap
where the arguments are allocated.

If there aren't reference cycles, and some object a references some other
object b, we can say the heap id of a >= the heap id of b.

In a function, when an object is allocated, we ask if there is a possibility
of the object being captured by the output. If yes, allocate it to the heap of
the output object. If no, allocate it to the current function's heap.

When calling a function, if the result of the callee is possibly captured by
the output of the caller, then pass the caller output heap as the callee
output heap. Otherwise pass the caller heap as the callee output heap.

We have also the case where the output of a function captures the inputs to
the function. If we already knew this, then the inputs to the function would
be allocated in heap that lives as long as the output to the function already.

Now the question is: is this enough to avoid memory leaks? In particular, I
worry about the 'possibility of capture' case. What if there is a small
possibility of capture, so we end up allocating a lot of garbage to an upper
frame?

Or, could we do accurate dynamic tracking?

For example, have a notion of virtual heap, still associated with a stack
frame. Virtual to make it so we can easy move an object from one heap to
another.

An object is allocated in the current heap. If there is a reference taken from
an object in y to an object in x, and x >= y, then the object in x is moved to
y, along with any other x references that are in heaps >= y. When we return
from a function, we move the return value to the caller's heap.

I claim this will be too expensive. Think about the case when allocating a
long linked list. Every time we return, we have to iterate over the entire
list to move all the objects. We need it to be constant time to return a value
to the caller.

That suggests we need to live with "possibility of capture" to allocate
objects to a safe heap to start with.

We haven't talked about tail recursion yet.

Say we are in heap 5. The result will go to heap 4. We have some local
variables in heap 5 that are being passed to the tail call. In theory, we need
to keep the local variables captured by the tail call and drop all the other
variables. Otherwise we'll have a memory leak. Perhaps functions that do tail
calls should have two heaps: the heap of objects potentially captured by the
tail call, and the heap of objects not captured by the tail call.

Can I come up with an example where potentially captured leads to a memory
leak? Almost surely. For example:

(Int@) { Int@; } F = (Int@ x) {
  Int@ y = decr(x);
  IsZero(y).?(true: x);
  F(y);
};

Contrived, yes. The variable x should only be captured at the end, but it has
the possibility of being captured every time. We end up allocating every value
on the outer caller's heap, thus using O(N) memory instead of O(1).

Can we flip the condition around and at least get some benefit? For example,
if I'm certain that an object isn't captured by the output, then we can
allocate it on the function heap. If that means we reduce the number of
objects participating in gc heap, that's great, right?

So, say for each object we can say: I guarantee this object will not live
longer than 'x'. If an object x references an object y, where x >= y, then we
don't need to track the reference?

Or maybe we keep track of a range of lifetimes. The lifetime for an object is
somewhere in the range [a, b]. It will not live longer than a. It will live
for at least as long as b.

Say an object [a, b] takes a reference to an object [m, n]. What happens? The
lifetime of the object [a, b] does not change (assuming no cycles for the
moment). How does the object [m, n] change?

If a >= n, no change. This means the [m, n] object will always live long
enough.

I guess it would be: [min(a, m), max(b, n)], right? It will not live longer
than both the objects. It may live as long as either of the objects. But,
again, if you change the value on the object [m, n], you have to change the
value of every other object it references recursively, which is too costly.

If an object has a single owner, we could say the lifetime of the object is
the lifetime of its owner. An object can only get a second owner through its
original owner.

If an object has multiple owners, and one owner is guaranteed to live longer
than all the other owners, then the object essentially has a single owner
still: the owner to live the longest.

Perhaps owners of an object could coordinate. Say I have object A with owner
X. Then, via X, we take a second reference to A from object Y. If X knows
about Y, and Y knows about X, then they could coordinate. Whoever is first to
be freed tells the other they have been freed and they are transferring
ownership. That's basically reference counting...

Makes you wonder if it's worth trying to go back to a reference counting based
GC. The language is simpler now. No links anymore. The only cycles will be
through RefValues.

---

Let me assume the high cost of memory management today is because objects are
allocated using malloc and an associated call into the gc. That suggests
switching to a reference count based approach will not help: we would still be
using malloc for objects.

Idea for allocating things on the stack:

Assume we reorganize values so that if you know the type of a value, you know
its shallow size. And assume we worry about polymorphic functions later or
have a way to know concrete types when they are invoked.

Have a function return its value as a copy. So the caller allocates space for
the return value on the stack, the callee fills in that space. That space
could contain references to other objects. Those other objects could be
allocated on the heap by the callee, allocated on the stack by the caller, or
allocated elsewhere with a lifetime that will outlast this function call.

Assume callee allocated objects transfer a reference to the caller as part of
this.

For local variables that would have been released when the function exits, the
function should go through and release any callee allocated parts of it. No
need to do anything else. Then we have successfully managed to allocate the
value on the stack and avoid malloc/free/gc for it.

Otherwise the object is returned to the caller of the function. For each local
and child allocated object referenced, heap allocate those as new objects and
copy that all over to the caller. We've successfully managed to allocate the
value on the stack and avoid malloc/free/gc for it, but we may have had to do
heap allocation for some things it referenced.

I claim this is good enough to allow stack allocation of the function value in
the monadic example stdout(byte).

To make this work, we need an easy way for the function to tell if an object
is:
a. heap allocated by a child.
b. locally allocated.
c. owned by the caller (either via the stack or heap).

How can we take a reference to an object owned by the caller from a child heap
allocated object if the object owned by the caller was stack allocated?

---

Important observation: Some things need to be allocated on the heap, even if
their lifetime is tied to the stack. For example, say we allocate a long list.
Because it's a long list, we can't allocate it on the stack. Then we use that
list as a local variable from some function f. The lifetime of the list is
clearly bounded by the call to f.

This means there are cases where heap allocated objects can safely refer to
stack allocated objects.

I think it's pretty clear conceptually how things should work. It's just
figuring out the details. Local variables should be allocated on the stack if
they aren't captured.

The details in question are:
* Can we allocate returned variables on the stack?
* Do we detect what's captured statically? Dynamically?
* Do we have a way to heap allocate objects that aren't gc'd?
* Will some combination of the above solve the fble-cat allocation case?

Next step, I think, should be to walk through the code for the simplified
fble-cat example. Understand what allocations we could stack allocate with
what knowledge and whether all the functions could be stack allocated.

---

Deep dive into monadic fble-cat code.

Function allocations are:

11. l1 = s2(l3);     stdout_(char)
13. l3 = l0(l1);     Do(stdout_)
15. l0 = func;       (Unit@ _) -> MCat
17. return l3(l0)

Let's start with the first one.

   0.  l0 = func /Core/Stdio/FastCat%.Main!.stdout_!![0017] [s0, a0];
   1.  return l0;

This is an anonymous function. We capture l3 as a static variable. So,
conceptually this is the pair (stdout, char). This is definitely captured by
the result of stdout_(char). To allocate this on the stack, we want to support
allocation of return results on the stack. If we did that, we end up with
(stdout, char) on the stack. No need for a heap allocation.

Note: we'll need to figure out how to allocate space for a function on the
stack when it could require an arbitrary number of static variables.

Next for do. Again, we allocate space for the result on the stack. The do
function at this point literally just captures the argument and returns a
function. So, in this case, we return (do!, (stdout, char)). No reason that
couldn't be allocated on the caller stack directly.

Except: are these functions potentially captured by the return result? I know
nothing about l3 statically without type information or some kind of inlining.
f(l0) could potentially capture l0 for arbitrary f.

Let's try working backwards. What is l3?

It's the result of calling do. A function that captures stdout(out). The
result of that will be another function that captures l0. So l3(l0) captures
l0 for sure. It captures stdout(out) too. So here is a case where the function
we want to return references other local variables. We would need to allocate
all of these local variables on the callers stack. Or copy them over to the
callers stack.

The resulting function is then passed to m.do(stdin).

---

Lots of thoughts on this. No major breakthroughs yet. Some highlights:
* We could allocate everything on the stack maybe, if we are willing to deep
  copy the result from the callee to the caller.
* Current GC is almost like copying the entire heap every time we finish a
  round of GC.
* How will we manage the API for external references to FbleValue* if we
  allocate everything on the stack?

It seems like the incremental improvement approach would be to try to
conservatively allocate values on the stack. But that won't eliminate the
function allocations in the cat example.

The aggressive improvement approach would be to try to do away with GC almost
entirely. Allocate everything on the stack. I don't have a good answer for the
pathological case of constructing a list though.


---

Did another round of thought on GC in performance.txt. It suggests stack based
allocation is worth trying, if only to get the following:
* Avoid having short lived objects put pressure on the stack after they are
  done being used.
* Avoid smashing the cache to free short lived objects.
* Avoid repeatedly smashing the cache when traversing long lived objects.

There are many different ways I could go about this. I fear getting bogged
down in details. How about we start like this:

* What is the easiest way we could adjust the heap allocator to have the
  properties above? Implement that and see what impact it has on performance.

Easiest way to start would be if we could restrict all the changes to heap.c.
Keep the same API for allocating objects and interacting with the heap. How
would that look?

Say we keep allocated objects in a linked list, maintaining the order they are
allocated in. To allocate a new object, you put it at the end of the list.

Say we magically make it so that new objects can refer to old objects, but old
objects can't refer to new objects.

When we release a heap object, if it's the last object in the list, we can
free it.

Could we traverse the heap from the back always?

---

Let's try generational gc. See gen_gc.txt for discussion.

In theory we now have all the following:
* Avoid having short lived objects put pressure on the stack after they are
  done being used.
* Avoid smashing the cache to free short lived objects.
* Avoid repeatedly smashing the cache when traversing long lived objects.

I'm not sure how to verify. It only helped performance a tiny bit though.
Like, 3% performance improvement.

Actually, turns out it was a bug in generational GC. With the fix, we now see
18% improvement and better memory behavior. I think we have achieved the goals
above.

Let's give memory management a break for a little while since the switch to
generational GC. Focus on partial application or other approaches to avoid or
reduce the cost of function allocations rather than a rework of overall memory
allocation for now.

---

We are again back to the high cost of allocations. Specifically a struct,
union, and function allocation required as part of the Result@ monad. Every
statement of Result@ monad requires an allocation.

I really wish we could allocate these directly on the stack. I think that
would make it much cheaper.

<@ A@>(Result@<A@>)<@ B@>((A@) { Result@<B@>; }) { Result@<B@>; }
Do = <@ A@>(Result@<A@> ra)<@ B@>((A@) { Result@<B@>; } f) {
  ra.value.?(nothing: Raise<B@>(ra));

  Result@<B@> rb = f(ra.value.just);
  Result@(Append(ra.errors, rb.errors), Or(ra.failed, rb.failed), rb.value);
};

Look at rb here. We know rb is a struct. We know that we only access the
individual fields of rb, after that we are done. From the Do function's point
of view, rb is short lived. Though we don't know if anyone else is using it
for other reasons.

In practice, that function f is likely to be Do itself, allocating a brand new
result.

Let's say we could return values in three different ways:
1. packed.
2. stack allocated.
3. heap allocated.

We always prefer packed over stack over heap.

To stack allocate, we are specifically talking about results of functions. The
caller should allocate space on the stack for the presumably shallow
allocation of the object. The callee knows about that and fills it in on the
stack if possible.

We just need to work out when to do which kind of allocation and how to manage
references.

---

Three approaches for returning objects on the stack:
1. Return the entire object on the stack.
2. Return the shallow object on the stack, anything else it references on the
heap.
3. Return up to a fixed amount of memory for the object on the stack, anything
else on the heap.

I want to try (1) to start, because it's so far in a different direction. With
(1), everything is allocated on the stack. There is no heap.

The big concern with (1) is the pathological case of building a large object,
like a linked list. Because we copy back every value return, and we are
copying N values back O(N) times, that's O(N^2) runtime to allocate an O(N)
list.

Heap allocations are expensive to allocate and cheap to move around. Stack
allocations are hopefully cheap to allocate but expensive to move around.

For (1), we need a managed stack, because standard calling conventions have no
way for a callee to return an unbounded amount of data on the stack to the
caller.

One idea that may make it easier is to have two stacks that we alternate
between for every call. If A calls B calls C calls D calls E calls F:

First stack: A C E
Second stack: B D F

This way, for example, when F is returning, it can return directly to the end
of E's stack frame without worrying about clobbering things. Otherwise it may
have to worry about clobbering itself. That is, compacting is easier if you
are compacting to a different memory region.

The API for the new proposed value heap:

FbleNewValueHeap, FbleFreeValueHeap
  As before, except Free cleans up any remaining objects.
FbleNewStructValue, FbleNewFuncValue, FbleNewUnionValue - as before.

void FbleValueHeapCall();
  Sets up a new stack frame on the heap, recording the current position.

FbleValue* FbleValueHeapReturn(FbleValue* return);
  Returns to the previous stack frame on the heap. Frees every object
  allocated on the current stack frame that is not reachable from the return
  value. Moves everything reachable from the return value allocated on the
  current stack frame back to the previous stack frame. Returns the new
  address to use for the returned value.

To manage objects in the C API, it will have to manage the stack as if it was
a bunch of stack frames. The easiest would be have everything it uses in the
first stack frame, which stays alive until FbleFreeValueHeap is called.
FbleEval can allocate a new stack frame to start so its only returning what it
uses.

We can still have packed values if we want. RefValues are not allowed to span
across stack frames, but that should come naturally. No need for
retain/free/addref.

Open question: how to properly free function values? Any way we can avoid the
need to free function values? Seems like that would make things easier in
general. Perhaps during compacting we iterate through all the allocated
objects (they should be next to each other on the heap) and free the ones not
moved. We could keep functions separately so its easier to iterate through
just those.

This approach sounds doable to me. I'm not convinced it's viable though,
because of these two things:
1. The pathological O(N^2) runtime to construct a N element list.
2. The need to iterate through all functions to clean up their executables.

Is it worth trying? Or should we find a solution to (1) and (2) first?

To address (1), we would want to limit to a constant amount of data returned
to the caller. Put the rest on the heap. If we do that, then we are basically
going to original approach (3). No need for a managed stack anymore. We
allocate a fixed amount of space for the callee to return values to. Anything
that doesn't fit in that fixed space we allocate on the heap.

The hope is this efficiently handles the case of small, short lived
allocations that are slowing us down with monadic code today. I fear it makes
inefficient use of stack space. All that potential space that won't be reused.

Honestly, I think we should try (1). Give it a chance to see its full
potential before worrying about how to address the bad cases. See how close it
gets to the current approach and if it solves any problems we are having
currently.

---

Here's an idea for how to avoid iterating through all the objects to clean
them up. Change FuncValue to directly store num_args, num_statics,
tail_call_buffer_size, profile_block_id, and run functions. Then we no longer
need to do anything on free of functions.

To support destructors, define a new internal value type NativeValue which is
a wrapper around a native object. NativeValue participates in GC, it's
basically raw data and an on_free function. Allocate things like file
descriptors and FbleExecutable (for interpreter) in NativeValue objects that
belong to statics of a function value. The run function can assume those
objects exist and have the desired native type.

The hope is that in normal execution, we very rarely have to deal with
NativeValue objects. Add some extra data structure for NativeValue objects,
such as an embedded doubly linked list, that makes it easy to traverse just
the native objects for on free.

I'm feeling good about this approach. We could implement it with the current
heap garbage collector if we wanted to. I'm not sure it gets us much. I
suppose the main downside is we can't share num args, num statics, tail call
buffer size, profile block id and run functions. So, if lots of functions are
instantiated with the same parameters, we end up with duplicate data. Perhaps
memory for that is expensive. On the other hand, when do you expect a bunch of
different functions to have the same executable? It would be functions
allocated by other functions. Maybe it's not that common.

---

First question: how to implement the stack data structure?

A. Use the existing native stack.

I'm not sure this is legit, but, for example, maybe we use alloca to allocate
on the callee stack. Then return the resulting pointer to the caller. The
caller used alloca to keep track of its local allocations. To access the
returned data from the callee, call alloca with the needed size to get access
to whatever was on the callee stack when it returned.

Downsides:
* It's pretty hacky. Probably not portable.

Assuming the hacks work, we could compact the stack as follows:
* The callee returns the value from its stack without any compaction.
* Immediately on return, the caller uses alloca to capture the callee's stack.
* We call a Compact function giving it a pointer to the original caller stack
  and the new caller stack. It can copy over everything.
* Somehow we need a way to realloc to free up the unused space from the
  callee. Hmm.. Sounds tricky.

B. Implement a single continuous address space.

This sounds nice, because:
* it's cheap to allocate and free: increment and decrement a pointer. 
* We can easily check if a pointer is in the compacting region of the stack or
  not, so traversal is easy. Just do pointer comparison.

How can we get a single continuous address space?
* Pass a fixed size heap when we create FbleValueHeap. 
  Sounds reasonable in theory. We could pick a default large heap.
* Use something like MAP_GROWSDOWN?
  Is that portable? How are you supposed to use that?
* mmap on demand and hope you can get continuous regions?

Some experiments to try:
1. What does the virtual address space look like for a mostly empty c program?
2. What does the virtual address space look like for, say, fbld while it's running?
3. What's the largest single region I can successfully mmap in one attempt?

(1):

55800b0000-55800c2000 r-xp  /home/richard/scratch/stack/main
55bab88000-55baba9000 rw-p  [heap]
7fa96b1000-7faa0b1000 rw-p  My 10MB mmap.
7faa0b1000-7faa21e000 ***p  /usr/lib/aarch64-linux-gnu/libc-2.28.so
7fde589000-7fde5aa000 rw-p  [stack]

(2):
  0bb34000-  10e9b000 rw-p  [heap]
7fd93ca000-7fda670000 rw-p  [stack]

(3):

Somewhere between 512MB and 1GB. I wonder if it's trying to reserve the space.

Let's try with MAP_NORESERVE now.

That gives us somewhere between 256GB and 512GB.

Cool. So with MAP_NORESERVE, we can get plenty of virtual address space for
the stack. Looks like in my case it allocates memory at the end of the
available region.

Any way to pick a decent default value for the heap size? I guess I could do
what I'm doing now: keeping trying 2x until we fail to allocate that much
virtual memory.

I suppose a more portable way to do this would be to malloc 2x until we fail,
use the last successful size as the stack.

Using malloc, the biggest allocation I get is 512MB.

If I search more precisely, the biggest allocation I get is around 1009MB.

I don't see any need to use mmap myself. Malloc a big region sounds fine to
me. We can search for what's available. Or take a fixed size.

---

Random different idea: what if we implement a copying collector instead of
mark sweep?

The stack allocation approach has already abandoned the idea of incremental
garbage collection. We know we care about maximum memory. So how about
something simple like this:

Start with some reasonable smallish heap size. Say 1MB. When we fill up that
1MB, then we do a big copy traversal of the entire heap.

A couple problems with this:
* We need to update all external references to use the new pointers. We can't
  do that as easily when there are external references beyond the one we are
  returning.
* How/when do we grow the heap? It's only after we copy that we know how much
  space we need for it.

Maybe we say at 1MB, copy over. If the result is less than 512KB, fine. If the
result is more than 512KB, then the next time we allocate a new region,
allocate it as a 2MB region?

In other words, we have heap size (after compaction), heap max (allocated
space). We set the next heap max based on heap size after compaction.

The nice thing about this approach is:
* It should be really fast when we aren't compacting.
* It's based specifically around the idea of minimizing the max memory usage.

Downsides:
* It doesn't work well with caching. Short lived objects will go out of cache.
* Big stop the world GC events.

---

Anyway, back to previously proposed stack allocation approach. We can use
malloc to allocate a single large enough region of memory up front. Allocation
is bumping a pointer. On 'enter', save the current stack pointer so we can
jump back to it. On traverse, we can use the pointer values to check what is
included in the traversal and what is down the stack.

---

Time to try implementing my stack allocation approach for real. The hope is we
remove all the time for IncrGc, malloc, free, ReleaseValue, and AddRef. We
replace it with time to traverse objects when returning. There's no doubt the
traversal will be expensive. But how will it compare to what we save? That's
what we want to find out.

Use md5sum as a best case example. I don't expect any large objects returned
there.

Where to start? Implement the heap API. Which will be:

FbleNewValueHeap, FbleFreeValueHeap,
FbleValueHeapCall, FbleValueHeapReturn
FbleNewStructValue, etc.

No need for FbleRetain/FbleRelease. No need for FbleValueAddRef. Start by
assuming we can make one big allocation for the heap space, if that's easier.
No obligation.

There are three major parts to this:
1. Implementing the new heap API
2. Switching to the new heap API
3. Cleaning up now unnecessary retain/release.

(3) we can do last. Just implement them as no-ops to start. That will be fun
cleanup/performance optimization.

High level sketch of implementation:
* Value is vtag + data
  - struct value: vtag + fieldc + fields
  - union value: vtag + tag + arg
  - func value is vtag + function + statics
  - ref value is vtag + value
  - native value is vtag + data + on_free
* Two stack regions, alternating back and forth for frames
* Each region has:
  - Pointer to the top, for new allocations.
  - Pointer to the base -> which should form a linked list of stack frames.
* We keep track of the current 'to' and 'from' regions for allocation.
* New heap: allocates and initializes the regions.
* Free heap: frees the regions.
* New value: increments the top of the current region and returns the previous
  top. All values are now properly aligned, so no worry about alignment here.
* Call: swap to/from regions, push a new frame onto the new to region.
* Return: Traverse/Copy everything on the top frame of the from region to the
  too region. Pop the top frame. Call native destructors on everything in the
  top frame being popped.

Let's say the 'base' of a stack frame points to a single pointer which is the
base of the previous frame on that stack. That's how we store the linked list
of frames.

That leaves two tricky parts:
* Keeping track of native values whose destructors need to be called.
  Ideally make this really fast assuming no native values, and reasonably fast
  assuming some native values.
* Implementing the traverse/copy logic.

For the traversal, implement a recursive function that, given a value, copies
it over to the new space and returns the new pointer. Case:
* The value is in an old space. Return it.
* The value hasn't been seen yet.
  Allocate space for it on the new stack. Set its type on the 'from' space to
  COPIED or some such and store a pointer to where it was copied to.
  Recursively copy over all the fields.
* The value has been seen. It's marked COPIED. Return the saved pointer for
  that value.

Easy.

For native values, keep them in a singly linked list. Use a field of the
native which isn't one that will be overwritten by the 'COPIED' value. After
the traversal, walk through the linked list. Skip over any values marked
'COPIED'. Call on_free on the rest.

That's it. Easy.

---

I drafted the code for implementing the new value heap. It's all very straight
forward and nice. Should be low overhead, if only it weren't for the bad
complexity of traversing the entire result every time we return from a call.

---

What to call my Call/Return, Push/Pop functions? Let's brainstorm.

FbleValueHeapCall, FbleValueHeapReturn
FblePushValueFrame, FblePopValueFrame
FblePushFrame, FblePopFrame
FbleValueHeapPush, FbleValueHeapPop
FbleNewFrame, FbleFreeFrame
FbleFramePush, FbleFrameReturn
FblePushValueFrame, FbleReturnValueFrame

I like Push/Pop. I like Frame. How to link that to the heap and values?

FblePushHeapFrame, FblePopHeapFrame.
FblePushStackFrame, FblePopStackFrame.
FbleNewFrame, FbleReleaseFrame

FbleNewStackFrame
FbleNewDataStackFrame

I like New too. Maybe better than 'Push'.

FbleNewHeapFrame, FbleReleaseHeapFrame
FbleNewValueFrame, FblePopValueFrame
FblePushValueFrame, FblePopValueFrame

FbleCallFrame, FbleReturnFromFrame

I like Return.

FbleNewHeapFrame, FbleExitHeapFrame
FbleNewHeapFrame, FbleReleaseHeapFrame

FbleReturnValue - This is good.

FblePushFrame, FbleReturnValue

Let's go with: FblePushFrame, FblePopFrame.

---

How to implement tail call?

I can bundle up the function and arguments into a struct value so it gets
copied back to the caller frame appropriately. But then I'll want to add more
args to the back of it.

Cases when we add num_unused to the back:
* If it's a tail call. Always that case.

How about we make num_unused and unused available for FbleTailCall, it can
bundle in those automatically? I kind of like that idea.

I think it's worth defining a special internal ThunkValue for this, so it's
easier to access the fields. We don't have to worry about packing. We can have
separate accessors for the function and args.

---

Trouble with tail call. We can't return the func and args to the caller frame,
because that memory will not end up getting reclaimed if we are in a loop.
Every subsequent tail call we do will add more and more to the caller frame
leaking memory.

We need the func and args for the tail call to end up on the callee's frame.
How do we manage that?

The other thing to figure out: what convention should I use for who calls
FbleFramePush/FbleFramePop when, particularly when dealing with native
functions? I think if I call some function FbleFoo(...) that returns an
FbleValue*, it should be the job of FbleFoo to do FbleFramePush and
FbleFramePop internally. Yeah. That's consistent and reasonable.

How to handle tail call then?

======= caller
======= callee

Seems like we want a way to traverse/compact in place. If executable->run
returns tail call, it returns the function and args to tail call still on the
callee frame (we could pass them via gTailCallData still if we want to).

What I want, then, is a function like:

void FbleCompactFrame(FbleValueHeap* heap, size_t count, FbleValue** save);

It frees everything in the frame except things reachable from those values
listed in save. It updates the pointers listed in save. If we had this, then
the implementation is straight forward I think. Do just like we have now,
except run FbleCompactFrame just before doing the tail call.

How could I implement this? We can't assume the frame is going to be small.
Some of the args could have been allocated on the frame and be really big.

Brute force way would be to double compact. Compact from A to B. Compact back
from B to A. That's two traversals instead of one. It's probably doable to
start, but not much fun.

For example, push a new frame, 'return' from the caller frame to the new
frame, then push a new caller frame, return from the previous new frame to the
new new frame. We don't have to write any new code for this, aside from the
wrapper to update save values.

Could we instead flip the polarity of the two stacks?

Say our stacks are A and B.

Say X calls Y and Y tail calls Z.

A: X
B: Y

When Y tail calls into Z, we 'pop' from B to a new frame in A.

A: X, Z
B: 

Now two things can happen.
1. We do another tail call. Z to W say.

A: X,
B: W

We end up exactly where we want to be.

2. We do a return from Z. Now we are in trouble again, because we can't return
in place.

What if we had 3 stacks, A, B, C?

X calls Y

A: X
B: Y
C:

Y tail calls Z

A: X
B: 
C: Z

Z tail calls W

A: X
B: W
C: 

Z returns to X

A: X
B:
C:

I think that works. We just need to keep track of which secondary stack is
active. Tail call swaps the active secondary stack.

We'll need to record where to return to. I'm sure it's doable. Just need to
work out the details.

Okay, easy.

Heap is a Frame* current.

Frame stores a Frame* caller and a Frame* alternative.

PushFrame:
  Pick either current->caller or current->alternative for the new current.
  The old current becomes caller, the unchosen becomes alternate.
  (In the future we could maybe pick based on free space for better memory use?)

PopFrame:
  current becomes current->caller

CompactFrame:
  current becomes current->alternate. It's caller is old current->caller and
  alternate is old current.
  
Sounds like a plan. How will we make use of this for tail calls now?

FbleTailCall does exactly what it does today. Copy func and args to
gTailCallData and return TailCallSentinel.

When we see TailCallSentinel, we add unused to gTailCallData like today. Then
we call CompactHeap, passing a pointer to gTailCallData.

The only thing is, I think we should store func and args next to each other on
gTailCallData and avoid storing the FbleFunction* pointer so that we can call
CompactFrame and have it work.

Okay? Let's try it.

---

More guidance on when to use FbleFramePush: Any native function that allocates
new FbleValues that are not returned directly to the caller should probably
call FbleFramePush/FbleFramePop to avoid leaking those allocations.

---

Code is drafted. Let's see if it's in a working state.

Some bugs:
* fble-mem-tests are hitting an assertion in FbleNativeValueData.
* StackSmash is clobbering a func value.

Yeah, so seems like we are clobbering memory somewhere. Let's see. Start with
the first failure.

---

Progress. We can run fble-md5 now. There are still bugs. fbld-md5 is clearly
leaking memory. That said, we have some numbers:

User time (seconds): 47.01
Maximum resident set size (kbytes): 30500

yes | head -n 60000 | /usr/bin/time -v ./pkgs/md5/fble-md5
  User time (seconds): 49.82 ==> 47.01
  Maximum resident set size (kbytes): 2516 => 30500

This is hopefully just the starting point to improve performance, because we
haven't optimized out calls to Retain/Release yet and we still have the memory
leak. So, decent start?

We need to track down the memory leak for sure.

Let's see if I can reproduce the memory leak in a simpler test case.

Yes. This leaks a lot:

  @ Unit@ = *();
  Unit@ Unit = Unit@();

  @ Bool@ = +(Unit@ true, Unit@ false);
  Bool@ True = Bool@(true: Unit);
  Bool@ False = Bool@(true: Unit);

  (Bool@) { Unit@; } Toggle = (Bool@ x) {
    Bool@ y = x.?(true: False, false: True);
    Toggle(y);
  };

  Toggle(True);

I've messed up management of the three stacks. In FbleCompactFrame, we somehow
need to reset the popped frame.

---

Problem fixed now.

yes | head -n 60000 | /usr/bin/time -v ./pkgs/md5/fble-md5
  User time (seconds): 49.82 ==> 47.01 ==> 47.22
  Maximum resident set size (kbytes): 2516 => 30500 ==> 2176

Let's see where else we are at.

---

* fbld is really slow. That's not surprising.
* memory growth tests fail. That's not surprising.
* fbld-tests gets an assert failure. That's surprising. Any other assert
  failures?

All the other spec tests seem to pass. Hmm... It's probably worth checking.

Next steps:
* Try to clean up / disable known failing tests so its easier to see if we
  break something.
* Try cleaning up Release values calls, see what kind of performance boost we
  get in md5.

---

Initial linux perf review of md5.

Before:
 4.19     7001  FbleReleaseValues[0015X]
 2.43     4057  _int_free[001fX]
 2.31     3857  IncrGc[001eX]
 2.21     3694  FbleReleaseHeapObject[0016X]
 1.71     2855  malloc[0029X]
 1.28     2138  FbleRetainValue[001cX]
 1.12     1864  FbleHeapObjectAddRef[0031X]
 1.01     1683  cfree@GLIBC_2.17[002fX]
 0.98     1641  Refs[002eX]
 0.93     1550  FbleRetainHeapObject[0018X]
 0.90     1504  FbleNewHeapObject[001dX]
 0.69     1155  FbleAllocRaw[0028X]

After:
 4.72     9262  Traverse.part.0[0026X]
 4.58     8988  FblePopFrame[0014X]
 3.54     6950  FblePushFrame[0017X]
 2.38     4668  FbleCompactFrame[0013X]
 1.41     2774  __memcpy_generic[001bX]
 0.31      601  FbleRetainValue[0034X]

Oh well. What did you expect?

---

Currently failing tests:
* ./pkgs/fbld/fbld-tests
* SpecTests/Test/MemoryGrowth.fble
* pkgs/sat/tests, compiled & interpreted in Sat.Dimacs test.
* fbld generated values.

My guess is just the two issues right now: the known issue with memory growth
test, and some issue causing problems for fbld-tests and sat tests.

Let's start with memory tests. Even before the stack allocation change
tracking number of FbleAllocs wasn't enough to catch leaks due to stack
growth. I want to try max RSS instead. It may be flaky, depending on how much
memory pressure the system is under. But assuming not too much memory
pressure, maybe it's good enough?

The first test is to see if memory-growth test works. Another good test would
be to see if the memory leak in the stack I fixed before gets detected.

The concern is whether we can observe the memory growth in the noise of
everything else involved during the memory test. Namely:

1. Compilation, initial evaluation of the function.
2. Allocation of the large value n.
3. Running the small test.
4. Running the large test.

Let's see some numbers for how it goes today. How do we get RSS/Max RSS for a
process?

getrusage has ru_maxrss and a few other memory related ones. Let's see what
those look like. Looks like just ru_maxrss actually.

MemoryGrowth sees 1704 RSS from start to finish. Do we need bigger n?

---

Through the power of git rebase, we now have ru_maxrss based memory tests.
Let's see if it's working now.

Yes, works now. It's just really slow because, well, O(n^2) traversal behavior
when allocating larger data structures.

---

Let's see what we can do about the sat test failure. I rather work with the
interpreter on this one I think.

I minimized the test a little. We are doing Reverse, ForEach in ParseLines. We
have a List@ whose 'cons' is showing up as a UnionValue instead of a
StructValue.

I should be able to step through the ForEach code to see how that list value
is constructed and trace when it gets corrupted.

First question:
* Is the list corrupted at the start of the call to Reverse?
Yes. It's already corrupted by then. That's going to make it harder to track
down what's wrong.

Maybe I can step through construction of the list and see where it goes bad.

---

Some logging shows an issue here:

pop
u 0x7fc7e4b348 -> 0x7fd7e47f20
s 2 0x7fc7e4b328 -> 0x7fd7e47f38
s 2 0x7fc7e4b308 -> 0x7fd7e47f58
n 0x7
n 0x7fd7e47f78
u 0x7fc7e4b2f0 -> 0x7fd7e47f78
n 0x7fd7e47e60

Look at 0x7fd7e47f78. The 'n' means we don't touch it because it's out of
range. But then right away we allocate it as a new value. That almost
certainly clobbers the original value, right? It shouldn't be possible to see
an address and have it be in the new allocation. The new allocation region has
to be empty.

Yeah. That explains the abort I'm getting. 0x7fd7e47f78 was the original list
pointer, but we over-allocated it as a new union value.

Next step is to figure out how we could ever see something in a region that is
supposedly all free. Add some more debug logs to print the frame regions when
we push/pop/compact. That should help to see what's going on. In particular,
when we reallocated this region that was apparently in use.

After modifying the algorithm slightly, now we have:

pop
u 0x7fc7e4b320 -> 0x7fd7e47ef8
s 2 0x7fc7e4b300 -> 0x7fd7e47f10
s 2 0x7fc7e4b2e0 -> 0x7fd7e47f30
n 0x7
n 0x7fd7e47f50
u 0x7fc7e4b2c8 -> 0x7fd7e47f50
n 0x7fd7e47e48

So question is, going into this pop, how could 0x7fd7e47f50 be both allocated
and free? Which one is correct?

Just before, we did:
pop 0x7fd7e47ef8 - 0x7fd7e47f88

That should have removed all references to 0x7fd7e47f50. How could we still
have a reference to it?

We compacted to 0x7fd7e47ef8 - 0x7fd7e47f88, then popped that range. The
popped value is 0x7fc7e4b178.

Hmm... I need to track allocations I think.

Here's a more complete sequence.

push 0x7fc7e4b2a8
push 0x7fd7e47ef8
push 0x7fe7e480d8
push 0x7fc7e4b2c8
pop 0x7fc7e4b2c8 - 0x7fc7e4b2e0
u 0x7fc7e4b2c8 -> 0x7fe7e480f8
n 0x7fd7e47e48
compact 0x7fe7e480d8 - 0x7fe7e48110
n 0x7fc7e4a360
u 0x7fe7e480f8 -> 0x7fc7e4b2c8
n 0x7fd7e47e48
s 2 0x7fe7e480d8 -> 0x7fc7e4b2e0
n 0x7
n 0x7fd7e47f50
 ==> 0x7fc7e4b2c8 - 0x7fc7e4b300
pop 0x7fc7e4b2c8 - 0x7fc7e4b338
u 0x7fc7e4b320 -> 0x7fd7e47ef8
s 2 0x7fc7e4b300 -> 0x7fd7e47f10
s 2 0x7fc7e4b2e0 -> 0x7fd7e47f30
n 0x7
n 0x7fd7e47f50
u 0x7fc7e4b2c8 -> 0x7fd7e47f50
n 0x7fd7e47e48

It looks to me like an issue here:

alloc 0x7fd7e47f50
u 0x7fc7e4b398 -> 0x7fd7e47f50
alloc 0x7fd7e47f68
s 2 0x7fc7e4b3b0 -> 0x7fd7e47f68
n 0x6316eecc88bb33
n 0x7
 ==> 0x7fd7e47ef8 - 0x7fd7e47f88
pop 0x7fd7e47ef8 - 0x7fd7e47f88
n 0x7fc7e4b178

I'm pretty sure we should be returning 0x7fd7e47f50 as part of this pop, but
we don't see it in the traversal. Later on we get a pointer to it somehow, but
because it was popped, we allocate on top of it.

Oh, look at that. 0x7fc7e4b178 is a ref value. Yeah. That's a problem. We
traverse the ref value, but fail to see through it to the value allocated on
the stack.

alloc 0x7fc7e4b178
r 0x7fd7e4da88 -> 0x7fc7e4b178

I was kind of assuming we would assign ref values in the same stack frame as
the value we assign to. That way we would traverse into their value? I'm not
sure. Think about it some more.

---

Question: How could a ref value in 0x7fc7e4b... be assigned a value allocated
higher up on the stack?

Okay, I'm close to decoding this.

Do tail calls 
  f(r.parsed.result)(r.parsed.state);

f is  /Sat/Dimacs%.ParseClauses!.:!!, with static ParseClauses
result is Unit.
state is our state with formula as a list of clauses.

We call the ParseClauses!.:!! function, which returns ParseClauses. We have
not yet applied the state argument, but we pop the frame anyway. When popping
the frame, we destroy the state, but it's saved as an unused argument. We
later go to apply the unused argument, but it's garbage. I think that's the
problem.

Here it is:

    } else if (num_unused > 0) {
      FbleValue* new_func = FblePopFrame(heap, result);
      return FbleCall(heap, profile, new_func, num_unused, unused);

Note the call to FblePopFrame too soon.

---

I tried writing a regression test for this, but I can't figure out how to
reproduce it in a small test.

---

With the fix, all fble tests pass now. It takes 4 hours to build everything,
but it all passes.

Next phase:
* Clean up retain/release calls, which are no longer needed.

After removing calls to FbleRetain/FbleRelease:

yes | head -n 60000 | /usr/bin/time -v ./pkgs/md5/fble-md5
  User time (seconds): 49.82 ==> 47.22 ==> 45.03
  Maximum resident set size (kbytes): 2516 => 2176 ==> 2108

Cool. There's still more cleanup to do. Then it's time to work on this
pathological case. I have ideas.

---

All the cleanup is done now.

yes | head -n 60000 | /usr/bin/time -v ./pkgs/md5/fble-md5
  User time (seconds): 49.82 ==> 47.22 ==> 45.03 ==> 44.81
  Maximum resident set size (kbytes): 2516 => 2176 ==> 2108 ==> 2116

Now on to performance.

There are a couple high level ideas to improve performance. I'm sure it's
dominated by Traverse. We should be able to verify very quickly running fbld
with linux perf.

Yeah:

Flat Profile by Self Time
-------------------------
    %     self  block
99.97    17963  Traverse.part.0[0001X]
 0.03        5  0xffffffd436e103cc[000aX]
 
How can we avoid so much traversal?

1. Merge stack frames.
For example, if we call a => b => c => d, instead of traversing when we go d
to c, c to b, and b to a, merge the stack frames for a,b and c,d. Traverse
only when we go c to b.

Variations: Merge frames until a certain number of allocations have been done.
We could limit overhead of potential garbage this way.

2. Make use of GC for some objects.
The extreme case is implementing the current API with every object GC
allocated. I feel like we should be able to get performance equivalent to
before stack alloc, but with all the nice cleanup of the new API.

The less extreme case is somehow identifying objects appropriate to allocate
on the heap and track them separately.

3. Allocate directly to caller.
Is there some way we could know where returned values should be allocated to
start? For example, in a function, I know if I'm allocating something I'm
going to return. Have the caller pass the frame where I should allocate to
directly.

4. ???

---

There are too many different ideas to try out. Let's pick one and run with it.
Specifically, let's go back to a GC based approach with the new API. I'm
hopeful that will be fast enough to let us merge the recent changes with the
main line and continue iterating from there.

How does a GC based approach work?

At a high level:
* Objects are 'owned' by their stack frame.
* When you return from a frame, you transfer ownership of returned objects to
  the new frame.

For performance to work out, we need to avoid doing allocation for new frames.
Ideally dropping a frame is constant time, regardless of how many objects were
allocated on it (not including time in incremental GC).

This means:
* We don't have to explicitly release each object on a frame when dropping the
  frame.
* We have immediate access to the next frame when dropping a frame.

We will need to drop references to objects at some point. Better to do it
sooner because it's more likely to be in the cache sooner than later.

Straw 1:
* Objects form a linked list. Each new object on a frame keeps the next one on
  the frame alive and so on.
* The 'top' object on a frame also points to the next frame.

This adds 16 bytes overhead to objects, in addition to the GC overhead.

Straw 2:
* For each frame we track two representative objects.
  1. An object whose 'next' is the next frame, forming a linked list of
     frames.
  2. An object whose 'next' is the next object in the frame, forming a linked
     list of objects in the frame.

Object (1) does not participate in the linked list of object (2).

Now we only need 8 bytes overhead per object, which sounds reasonable to me.

But where do we keep track of these two objects? That's the trouble. We don't
have a place for that.

Another challenge with this approach is I'm not sure if it's safe to remove a
reference from an object the way the current GC is implemented. That may not
trigger a collection event.

We could store the frame data structure separately, outside of the heap. Maybe
batch things together, so we allocate once every 1000 frames or so. Or have a
vector of objects. That sounds reasonable to start anyway.

Let's start simple. Each object has two extra fields: next in frame, and next
frame. FbleValueHeap keeps track of the top frame, and maybe an integer saying
how many frames down on the stack that is.

To allocate an object:
* next points to top frame,
* tail points to top frame's tail.
* drop reference to previous top frame.
* set new top frame

To allocate a new frame:
* increment count on FbleValueHeap.

To pop a frame:
* release the top frame, decrement the pop count? No, that doesn't quite work.

How can we have frames with no allocations? Where to keep info about that?

Again, start simple. Each object has one extra field: next in frame. We have a
vector of Frame entries that we update for each frame we enter (regardless of
whether we allocate there or not). The frame stores the top object on the
frame which we have retained. It could be NULL.

To push: update top object on frame.
To pop: release top object on frame, pop frame.

Yeah. That's it. Good and simple.

Trouble: I need a way to know if the value being returned was allocated on the
frame being popped or not.

The cases are:
A. value being popped was allocated down on the stack. No need to
   Retain/Release.
B. value being popped was allocated on this frame.
   Don't release. Push onto child frame.
C. value being popped is referenced from a value allocated on this frame.
   Retain and push onto the child frame.

How do I distinguish between these three cases?

We need to allow the same value to show up on multiple frames.

That solves it. So in the end we basically move our stack from managed by the
compiler to managed by the heap.

Performance:

yes | head -n 60000 | /usr/bin/time -v ./pkgs/md5/fble-md5
  User time (seconds): 49.82 ==> 44.81 ==> 56.61
  Maximum resident set size (kbytes): 2516 ==> 2116 ==> 2364

/usr/bin/time -v ./pkgs/fbld/bin/fbld ../fbld/nobuildstamp.fbld ./fbld/version.fbld ../fbld/html.fbld ../spec/fble.lib.fbld ../spec/fble.fbld > /dev/null
  User time (seconds): 98.44 ==> 120.47
  Maximum resident set size (kbytes): 99592 ==> 101404

We'll need to improve performance before we can take it. But at least fbld is
in the right ball part now.

---

Avoiding vector shrink resize for the stack:

/usr/bin/time -v ./pkgs/fbld/bin/fbld ../fbld/nobuildstamp.fbld ./fbld/version.fbld ../fbld/html.fbld ../spec/fble.lib.fbld ../spec/fble.fbld > /dev/null
  User time (seconds): 98.44 ==> 120.47 ==> 109.03
  Maximum resident set size (kbytes): 99592 ==> 101404 ==> 100472

---

Idea for tracking these cases:
A. value being popped was allocated down on the stack. No need to
   Retain/Release.
B. value being popped was allocated on this frame.
   Don't release. Push onto child frame.
C. value being popped is referenced from a value allocated on this frame.
   Retain and push onto the child frame.

Have a frame counter. Every time we push a new frame, increment the counter by
1. When we allocate a new object, store the current frame counter with the
object.

Now, when we return an object, there are three cases:
1. The object's allocation frame is less than the frame being popped. No need
to retain/release.
2. The object's allocation frame is the frame being popped. Don't release, move
to child frame. Update the allocation frame value to the child frame.
3. The object's allocation frame is the greater than the frame being popped.
The value being popped is referenced from a value allocated on this frame.
Retain and move onto the child frame, updating its allocation frame.

It's exactly the info we wanted. The benefit of this is we don't have to walk
through all the objects on a frame when we pop or compact. We can let GC
traversal take care of that. We just need to retain one object per frame which
can reach all the other objects on the frame.

Actually, in this case, no need to distinguish between (2) and (3)? The main
thing being that we aren't allowed to disrupt the reference chain down the
stack. But we can mess it up for any other objects?

Straw:
* For each frame we retain a single object which can reach any other object on
  the frame.
* Each object says which frame push it was allocated on.
* When you pop a frame,
  - if the returned object was allocated downstack, we know it's retained
    downframe, so just return it.
  - if the returned object was allocated since, make it the new retaining
    object for down stack (i.e. retain it) and return it.

Easy, no? Compact works similarly, except we add saved values to a new
frame instead of going downstack.

Each value has:
* 'next' field in singly linked list.
* 'generation' field for frame it was allocated at.

And we have a growing vector of values which are the retainers for each frame
on the stack.

The heap knows its current generation count.

Let's try it.

Do we have to increment generation count for compact frame? No, because
'downstack' hasn't changed?

It's leaking memory. I fear the current GC assumes we never change pointer
values of an object except to go from NULL to non-NULL.

Can I make a custom GC for this? It feels like we should be able to do better
that way.

---

Proposal for a custom GC:

Objects can be part of a doubly linked list of objects.

Each frame stores three lists of objects:
1. Potentially garbage objects allocated on callee frames.
2. Non-garbage objects returned from callee frames.
3. Objects allocated on this frame.

New objects go to the list of objects allocated on the latest frame. When we
pop from a frame, we add all objects allocated there to (1) of the caller,
then move the returned objects to (2) of the caller.

To perform GC: find the oldest frame with garbage (we can track this
incrementally so it's constant time to find), traverse objects on (2) as
roots, any objects in (1) not traversed after GC are freed.

During the traversal, we only traverse objects in (1) and (2). Any other
objects we don't have to worry about.

Keep track of the frame/generation an object belongs to so it's easy to tell
if we need to traverse an object or not. When traversing, update the traversed
objects generation to the current frame.

The reason to GC the oldest frame with garbage is because newer frames will be
popped first, and if we pop a newer frame before we GC that frame, we can
avoid traversing some objects entirely.

---

A couple thoughts:
* If we pop a frame while doing GC on it, we could lose track of where some
  objects belong. Best to not allow popping a frame while doing GC on it.
  Instead, when popping the frame, abandon the GC in progress entirely and
  return the garbage to the caller like we normally would when popping a frame.

  In practice, implement this by doing GC directly the data structure for the
  frame rather than moving potential garbage to a central area.

* If we are storing pointers to lists on frames, we have to be careful about
  reallocating and moving frames. To be on the safe side, use a data structure
  that doesn't move frames around in memory.

* How do we prevent GC from falling behind when GCing a frame that we keep
  compacting? If GC can't finish by the next time around and we keep adding
  more values to GC, we'll never finish, right?

  So, we should store current GC objects separately from the frame. We just
  need to make sure we pull them back into the frame if we pop the frame
  before GC finishes.

---

Draft is done. Things to debug:

SpecTests:
* StackSmash: fble-test.cov: ../lib/value.c|855| FbleFuncValueFunction:
  Assertion `func->_base.tag == FUNC_VALUE' failed.
* MemoryGrowth test: memory constant: M(10000) = 0, M(20000) = 0

Let's debug StackSmash first.

We allocate a ref value. Then a function value. We assign the function to the
ref. We free the ref value. We allocate a union value over the same space,
then try to access the ref value as a function.

Question is: how did we have a reference to the ref value but somehow managed
to GC the ref value? Guess I'll have to debug more.

We compact the heap, saving the function that the ref value points to. We
don't see that function holding on to anything, so we free the ref value.

Ah. I think I see. We are compacting the heap. We need to track generations
properly in this case to know what we should or should not traverse. Right now
we are saying don't traverse from func back to ref because ref has the
generation of the gc frame. That's the logic I had in mind, but it's wrong
because we want to traverse ref in this case because of compacting the heap.

---

If we didn't have compact frame:

Objects popped and saved to a frame with gen x:
* All have gen greater than x.
* None reference any object with gen greater than x outside of the set
  popped+saved.

That way we can safely traverse, following all objects with gen greater than
x. We'll cover all objects in the set and never go outside. As we go, we set
objects to gen x to remove them from the set of things to traverse.

That works great.

If we only had compact frame:

Objects popped and saved to a frame with gen x:
* All have gen greater than or equal to x.
* None reference any object with gen greater than or equal to x outside of the
  set popped+saved.

We could traverse by following all objects with gen greater than or equal to
x. We'll cover all objects in the set and never go outside. But we have no
obvious gen to set the new objects to remove them from the set of things to
traverse.

In general we have a mix of the two cases. Say we compact a frame, then push,
then pop back to it, all while GC is working elsewhere.

In the case of normal popping, we only traverse an object once, to move it to
the caller frame. For compacting, we could repeatedly traverse it on the same
frame as we repeatedly compact that frame.

In terms of generations when compacting, how about:
* Original generation of the frame is X.
* On compact, saved+popped is generation [X,Y].
* On compact, set new generation for frame to Z.

Now when we gc, we say traverse anything in range [X,Y], move to Z. Can we
make this work for both pop and compact cases?

Say we stored the range explicitly for saved+popped. If we had that, it's easy
to traverse it. And say we promise the generation for the target frame is not
in that range. Then it's easy to traverse. Can we maintain that?

At any time we might pop the frame before finishing GC. We would know the
range of all objects: range of saved+popped plus frame->gen plus anything
between here and current heap->gen.

Three operations to handle: Push, Pop, Compact.
* Push: Increment heap->gen, range starts empty (?).
* Pop: Add to range [callee->gen, heap->gen]. Note: caller->gen < callee->gen.
  Let's say callee->gen is the lowest gen object allocated on the frame always.
* Compact: Add to range [caller->gen, heap->gen].

New objects can always be allocated to a frame using heap->gen. They aren't
allocated using frame->gen. Is it safe to use heap->gen as the destination for
traversed objects?

I don't think so. Say we have callees allocating objects. Some will be gen
less than heap->gen, some will be gen greater than heap->gen, some will refer
to these objects we are saving in the caller. When the callee pops, we won't
be able to isolate the objects to traverse to saved+popped.

Compact is a special case. When we compact, we can allocate a new target id. A
new current generation for that frame.

What if we can process frame->gen is outside of saved+popped? GC needs to know
the lower and upper bound for traversal still.

Can we use (frame-1)->gen as a lower bound? Not if frame->gen is the lower
bound.

How about we record if we have compacted or not? compacted means the range of
saved+popped is ((frame-1)->gen, frame->gen), otherwise saved+popped is
(frame->gen, heap->gen]. Excepted we can't use (frame-1)->gen, because it's
lower than the actual lower bound.

Say we have two generations per frame: min, gen. They start the same. When we
compact, min stays the same, we bump gen. You can always use gen as the
destination for gc. Record if you've compacted or not.

If you've compacted, range is [min, gen). Otherwise range is (min, heap->gen).

Except, the problem is if you both compacted and popped. We can no longer use
frame->gen as an upper bound.

Needs more thought.

---

compact + compact => compact
popped + popped => popped
popped + compact => compact

The problem is: compact + popped. We want to compact forward to the
post-compact generation and pop back to the post-compact generation. That
means the objects span before and after.

A solution is to keep them separate. Each frame can have compacted objects and
separately popped objects.

Conceptually the solution is easy. A clean implementation is harder to come
by. Now each frame can have two parts of GC.

---

Bugs to work out. All the spec tests are passing, but as we know, that doesn't
mean much when working on GC these days.

Core test fails. Need to minimize.

It looks like we were compacting a frame while gcing the frame, which caused
us to somehow try to free a non-value alloced list node. The workaround was to
abandon gc in this case.

But now I'm afraid we could fall behind and never finish GC in a tight tail
recursive loop. In theory we should be able to keep subsequent compactions
separate from the current gc. The challenge is making sure we move marked
objects to compacted_saved instead of alloced after that. That means knowing a
bit more about what we are currently running GC on.

I should maybe write a test case for this? The idea would be: allocate a bunch
on the frame. Then compact and go into a tight tail recursive loop that
doesn't allocate much each iteration. The claim is we leak memory when we
shouldn't be leaking memory. We would get memory growth instead of memory
constant.

Initial performance numbers:

yes | head -n 60000 | /usr/bin/time -v ./pkgs/md5/fble-md5
  User time (seconds): 49.82 ==> 52.21
  Maximum resident set size (kbytes): 2516 ==> 2260

/usr/bin/time -v ./pkgs/fbld/bin/fbld ../fbld/nobuildstamp.fbld ./fbld/version.fbld ../fbld/html.fbld ../spec/fble.lib.fbld ../spec/fble.fbld > /dev/null
  User time (seconds): 98.44 ==> 86.73
  Maximum resident set size (kbytes): 99592 ==> 83044

Oh hey, that's actually pretty good for fbld. Maybe good enough to
mainline?

Before we mainline, I want to figure out a way to avoid hard coding a limit on
number of stack frames and preallocating stack frames.

Maybe allocate new frames on demand, put them in a linked list, but save them
for reuse? The important point is that we don't try to move them via realloc,
otherwise the pointers to lists get messed up.

Operations on frames:
* quickly compare stack depth of two frames.
* quickly access frame + 1 for next_gc.
* iterate over all frames for final cleanup.
* Add frame to the back.
* Pop frame from the back.

Seems like a linear doubly linked list of frames where we append to the end of
the list as needed and keep a pointer into the top of the list could work
well?

yes | head -n 60000 | /usr/bin/time -v ./pkgs/md5/fble-md5
  User time (seconds): 49.82 ==> 52.21 ==> 51.05
  Maximum resident set size (kbytes): 2516 ==> 2260 ==> 2344

/usr/bin/time -v ./pkgs/fbld/bin/fbld ../fbld/nobuildstamp.fbld ./fbld/version.fbld ../fbld/html.fbld ../spec/fble.lib.fbld ../spec/fble.fbld > /dev/null
  User time (seconds): 98.44 ==> 86.73 ==> 86.85
  Maximum resident set size (kbytes): 99592 ==> 83044 ==> 86060

Cool. I think we're ready to mainline this now. I don't mind a 1 second
regression in md5 given the 11 second improvement in fbld.

---

What are the next steps here?

Do another round of performance analysis. Maybe there are some improvements we
can make to the current GC approach based on that. After that, consider again
if we can avoid allocating on the heap in some case.

md5:

 7.69    33193  FblePopFrame[0012X]
 3.67    15822  FblePushFrame[0016X]
 2.16     9304  FbleCompactFrame[0014X]

**      950    38890    14550  NewValueRaw[0019X] **
        362    10369           FbleAllocRaw[0028X]   
        124     9023           _int_free[001eX]   
        107     3674           cfree@GLIBC_2.17[002cX]   
         85      828           FbleFree[0041X]   
         70      355           free@plt[004aX]   
         39       90           malloc[0029X]   

We could maybe improve PopFrame and CompactFrame if we had fewer object lists
to manage on each frame. Perhaps most of the time these lists are empty. Maybe
we could use a separate data structure to store GC possibilities separate from
the main stack? That way we don't need to deal with any lists if they are
otherwise empty.

PushFrame appears to mostly be overheads of the function call. I wonder if we
could inline it, since it is mostly called in one place, and if that wouldn't
improve performance notably.

Today we don't move any objects. We could simplify the code slightly under
that assumption. Not sure if I want to make that assumption yet though.

If we can do anything to improve GC, I think it would be to keep potential
garbage on a separate stack. Push/Pop frame should be faster, especially for
frames that don't do any allocation.

Otherwise, for md5, can we come up with some way to avoid IncrGc and malloc
for the short lived struct object allocations in Addx and Shlx?

fbld:
 8.94     2375  FbleCompactFrame[0007X]
 6.87     1826  NewValueRaw[000aX]
 6.54     1738  FblePopFrame[000eX]
 2.18      579  FblePushFrame[0050X]

**     3398     5337     1826  NewValueRaw[000aX] **
        951     1812           FbleAllocRaw[000bX]   
        754     1065           _int_free[0044X]   
        406      503           cfree@GLIBC_2.17[0059X]   
         84       90           FbleFree[0085X]   

fbld looks similar to md5.

Note that Push/Pop/Compact are orthogonal from NewValueRaw. NewValueRaw only
happens with allocations. Push/Pop/Compact happens all the time.

That means there are two things to work on next:
1. Optimize Push/Pop/Compact. By coming up with better data structures.
2. Optimize NewValueRaw. By figuring out how to avoid calling it for short
lived objects.

---

For (1), I think we can group compacted and popped together. The key is that
we don't traverse if the object has the same gen as the gc frame's gen. That
covers both cases of compacted and popped.

That should be a good start to performance improvement. There may be room for
more after that.

I haven't thought of anything for (2) worth trying yet.

yes | head -n 60000 | /usr/bin/time -v ./pkgs/md5/fble-md5
  User time (seconds): 51.05 ==> 50.59
  Maximum resident set size (kbytes): 2344 ==> 2268

/usr/bin/time -v ./pkgs/fbld/bin/fbld ../fbld/nobuildstamp.fbld ./fbld/version.fbld ../fbld/html.fbld ../spec/fble.lib.fbld ../spec/fble.fbld > /dev/null
  User time (seconds): 86.85 ==> 84.46
  Maximum resident set size (kbytes): 86060 ==> 83784

---

Idea: We don't have to call FblePushFrame/FblePopFrame at every function call.
We only need to call it enough to avoid excessive garbage. In particular:
* Only call FblePushFrame/FblePopFrame for recursive functions (when it's a
  RefValue?). Anything else will do constant allocation, which we assume is
  small enough we don't need to worry about.
* Only call FblePushFrame/FblePopFrame for one out of every X function calls.
  Again, each individual call is a constant amount of allocation. We can take
  a constant overhead of garbage easily enough.
* To skip FbleCompactFrame, just don't compact the frame. If we skipped the
  push for the caller and then find ourselves in a tight FbleCompactFrame
  loop, we can push a new frame instead of compacting and then compact in
  place the next time around on that frame.

This could get us up to 10-15% improvement based on the profiles for md5 and
fbld.

To start, I think we should move the code from function.c into value.c. It was
never clear which code should go where. That will let the compiler do inlining
in performance sensitive code and let us play around with things like only
calling PushFrame/PopFrame at recursive function boundaries without having to
deal with crossing a level of abstraction.

Moving the function.c code into value.c:

yes | head -n 60000 | /usr/bin/time -v ./pkgs/md5/fble-md5
  User time (seconds): 50.59 ==> 49.05
  Maximum resident set size (kbytes): 2268 ==> 2340

/usr/bin/time -v ./pkgs/fbld/bin/fbld ../fbld/nobuildstamp.fbld ./fbld/version.fbld ../fbld/html.fbld ../spec/fble.lib.fbld ../spec/fble.fbld > /dev/null
  User time (seconds): 84.46 ==> 80.68
  Maximum resident set size (kbytes): 83784 ==> 84732

---

To give a sense, here's a sample of function calls from md5 based on whether
they are normal, recursive, tail normal, or tail recursive. Note that
relatively few calls are recursive. So there's a potential to save a lot
here by skipping Push/Pop/Compact frame in that case.

1144988 n
  12907 r
 192804 tn
   7205 tr

How about this: add an option 'recursive' to push/pop/compact. Add to each
frame a count of non-recursive pushes and pops.

Push:
 * If recursive, push a new frame.
 * If not recursive, increment the non-recursive push count.

Pop:
 * Decrement the push count. If it's zero, pop the frame.

Compact:
 * If not recursive, do nothing.
 * If recursive and push count is 0, do like we do today.
 * If recursive and push count is greater than 0,
   Decrement the push count on the frame and push a new frame with push count
   0.

Easy? Worth a try?

Double check this is okay to do though. For example, any frame could end up
pointing to a really big object. With this approach, we end up essentially
holding on to some frames longer than they would otherwise. Are there bad
cases where that could impact memory complexity?

It's always a constant factor, right? 

Say we merge 5 frames, and each frame holds on to a big list. We end up with 5
big lists. That's not breaking anything. It's as if we had a single big list
which took 5x more memory to store. Constant factor should be fine.

But is it merging 5 frames, or is it potentially merging more? It's really
merging a tree of frames, right? If we assume at most K calls per frame,
that's potentially K^5 frames worth of memory all being merged into one. Still
constant, but a bit larger of a constant.

I still think we are okay. Shall we try it?

/usr/bin/time -v ./pkgs/fbld/bin/fbld ../fbld/nobuildstamp.fbld ./fbld/version.fbld ../fbld/html.fbld ../spec/fble.lib.fbld ../spec/fble.fbld > /dev/null
  User time (seconds): 80.68 ==> 77.85

So, a little bit of improvement.

Official numbers:

yes | head -n 60000 | /usr/bin/time -v ./pkgs/md5/fble-md5
  User time (seconds): 49.05 ==> 48.07
  Maximum resident set size (kbytes): 2340 ==> 3668

/usr/bin/time -v ./pkgs/fbld/bin/fbld ../fbld/nobuildstamp.fbld ./fbld/version.fbld ../fbld/html.fbld ../spec/fble.lib.fbld ../spec/fble.fbld > /dev/null
  User time (seconds): 80.68 ==> 78.77
  Maximum resident set size (kbytes): 84732 ==> 103956

Memory usage is definitely up. Is that expected and okay? Or are we
essentially making things go fast by leaking a bit of memory?

Anyway, I have an idea for how to pull everything together based on this.
Allocate all new values on the stack frame. When we PopFrame or CompactFrame,
traverse the stack frame values converting to GC allocated values there.

My claim is this approach is simple, fast, lets us allocate most short lived
objects directly on the stack without malloc/free, but also avoid overheads of
traversal. The best of all worlds hopefully. If we find short lived objects do
end up allocating on the heap, we can consider merge more of the recursive
calls, say 4 of every 5. We end up with a decent sized pool of stack allocated
objects that avoid the need for malloc/free.

---

It's fine for stack allocations to refer to GC allocations. When we pop the
frame we'll traverse the stack allocations to see which GC allocations are
referenced.

It's not okay for GC allocations to refer to stack allocations, because we
don't want to have to traverse a long chain of GC objects every time we pop.
Proposed solution: turn all stack allocations into GC allocations as part of
traversing the popped frame. This includes stack allocations farther down the
stack.

To avoid creating duplicate GC allocations for the same stack allocation,
create a GcValue kind on the stack to replace the original stack allocation.
That GcValue acts like a RefValue and points to the Gc version of the
allocation.

For stack allocations, we want a stack data structure. Maybe start with like
what I did before: malloc a big array at the start for all the stack
allocations and hope it's big enough. Once we prove out the approach, we can
think of better ways to (dynamically) size the stack. We can use that stack
space for storing frames as well. Only the GC allocated objects need to be
allocated via malloc.

Pieces to pull together:
* Use malloc allocated stack space for frames.
* Implement a GcAlloc function that converts a stack allocated value to a gc
  allocated value.

To start, we can allocate values on the stack with space for list and gen
fields. It's a little wasteful, but will simplify the programming. We could
reuse a list field to track gc allocated counterparts to the value, for
example. We could optimize space usage later if desired.

High level approach is easy then:
* Initially allocate by bumping the stack pointer.
* Pop and Compact call GcAlloc to convert to a GC object when
  popping/compacting.

Cool. Let's give it a try.

---

* Let's allocate all native values on the heap instead of the stack, to
  simplify tracking of the destructors.

---

Okay, draft is done. Looks like we have a memory leak somewhere. How to track
it down? Found it.

Some early results:

yes | head -n 60000 | /usr/bin/time -v ./pkgs/md5/fble-md5
  User time (seconds): 48.07 ==> 43.30
  Maximum resident set size (kbytes): 3668 ==> 3180

That's pretty nice.

Looks like we have some bug with ref values though, because fbld fails.

Let me allocate ref values on gc all the time. Yeah, that seems to fix it. I'm
not sure exactly why it's problematic, but it wouldn't surprise me if it is.
It shouldn't be bad to always Gc alloc.

The performance numbers look good:

yes | head -n 60000 | /usr/bin/time -v ./pkgs/md5/fble-md5
  User time (seconds): 48.07 ==> 43.72
  Maximum resident set size (kbytes): 3668 ==> 3168

/usr/bin/time -v ./pkgs/fbld/bin/fbld ../fbld/nobuildstamp.fbld ./fbld/version.fbld ../fbld/html.fbld ../spec/fble.lib.fbld ../spec/fble.fbld > /dev/null
  User time (seconds): 78.77 ==> 64.85
  Maximum resident set size (kbytes): 103956 ==> 107168

Can we mainline this?

Steps to do first:
* Make sure all the tests pass.
* Review linux perf results. See if anything interesting shows up.
* Figure out how to properly pick the stack size. Can we dynamically allocate
  as needed?

The performance is good enough. Good enough to declare the performance goals
of release fble-0.3 met I would say.

Tests pass. Let's mainline this and worry about a better approach to picking
stack size next.

It's hard to see much from the md5 perf profile. Who knows how much is inlined
where. The time spent in NewGcValueRaw is 2.5%. It's looking pretty good.

Similar in fbld perf profile. Hard to see based on what's inlined where.

I'd say performance wise we've achieved our object with stack allocation.

Now, how do we pick a better size for the stack?

Options:
1. Pick a better absolute size to start with.
2. Dynamically allocate more as needed in big chunks.

I like (2) better practically because we don't have to worry about silently
overrunning buffers or trying to gauge how much memory the user has, or
worrying about overcommit policy. The downside of (2) is we don't have a
single continuous range.

Let's start with (2), see how we can handle it.

A few issues to handle:
* How to check order of frames. Right now we use min_gen. Let's continue to
  use that for the time being. Easy.
* How to test if an object is gc allocated or not?
  - Store something in the value itself next to tag. Easy to do. Too costly?
  - Store something in the pointer value itself. Trickier. Maybe okay?
* Tracking bounds for new allocation.
  - Add a check every time we allocate. Easy. Not sure how costly.

Sounds like (2) is entirely feasible. Not sure how big a cost it is, but
honestly probably not very costly in practice. The idea is to allocate the
stack dynamically in large chunks of say, 1MB each. When we run out of space,
allocate a new chunk. We can keep linked list of allocated chunks if needed.

Say a Frame* lives in it's caller's space. The frame itself can allocate extra
if it needs to for new values or the callee. When we pop a frame, we put aside
any extra allocations it made for later use. Shouldn't be too bad. It's nice
to align the cleanup with frame pop. I assume/hope that the majority of frames
don't have any extra space allocated, so it's pretty cheap to deal with.

Add two fields to frame:
* A singly linked linked list of extra allocations.
* An intptr_t which is the max of the allocations.

Add one field to heap:
* A singly linked list of extra allocations.

Add a helper function to StackAlloc a certain size. Use that for allocating
values and frames. It checks for sufficient space, advances top pointer. If
necessary it uses or allocates a new extra allocation. When we pop the frame,
move all the extra allocations to the heap - O(N) is fine here, because there
should be very few extra allocations. It's very unlikely that a heap needs
more than 1.

Sounds like a plan. Let's implement it.

---

Cost of using a field in the value to store gc versus stack alloc instead of
pointer comparison:

yes | head -n 60000 | /usr/bin/time -v ./pkgs/md5/fble-md5
  User time (seconds): 43.72 ==> 43.25
  Maximum resident set size (kbytes): 3168 ==> 3280

/usr/bin/time -v ./pkgs/fbld/bin/fbld ../fbld/nobuildstamp.fbld ./fbld/version.fbld ../fbld/html.fbld ../spec/fble.lib.fbld ../spec/fble.fbld > /dev/null
  User time (seconds): 64.85 ==> 64.59
  Maximum resident set size (kbytes): 107168 ==> 106024

Cool, it's a performance improvement.

---

Cost of allocating the stack in 1MB chunks instead of all up front:

yes | head -n 60000 | /usr/bin/time -v ./pkgs/md5/fble-md5
  User time (seconds): 43.25 ==> 44.19
  Maximum resident set size (kbytes): 3280 ==> 3276

/usr/bin/time -v ./pkgs/fbld/bin/fbld ../fbld/nobuildstamp.fbld ./fbld/version.fbld ../fbld/html.fbld ../spec/fble.lib.fbld ../spec/fble.fbld > /dev/null
  User time (seconds): 64.59 ==> 66.65
  Maximum resident set size (kbytes): 106024 ==> 108952

Oh well. There was bound to be some cost.

---

After some minor cleanups, the final numbers:

yes | head -n 60000 | /usr/bin/time -v ./pkgs/md5/fble-md5
  User time (seconds): 43.21
  Maximum resident set size (kbytes): 3408

/usr/bin/time -v ./pkgs/fbld/bin/fbld ../fbld/nobuildstamp.fbld ./fbld/version.fbld ../fbld/html.fbld ../spec/fble.lib.fbld ../spec/fble.fbld > /dev/null
  User time (seconds): 66.84
  Maximum resident set size (kbytes): 108708

---

One problem with this approach: It's really hard to write spec tests that
capture bugs in the implementation, because the paths to hit the bug depend so
much on details of the implementation.

---

Memory leak:

(Int@) { Unit@; } F = (Int@ i) {
  Int@ ni = Incr(Gt(i, Int|100000).?(true: Int|50000, false: i));
  F(ni);
};

Let's write up a test case to reproduce it, then figure out what's really
going on and fix it.

My suspicion (what originally led to this test case) is that we keep aborting
the top GC when we compact the frame. We should figure out a way to avoid
aborting GC in that case, or maybe push a frame occasionally to allow GC to
happen.

To minimize the use case: you have a function that allocates garbage in a
tight loop.

---

Memory test written to reproduce the issue. Next question is what's going on
and how to fix it.

Here is the cycle of GC.

 1 ABORT
 1 FINISH
27 MARK
 1 COMPACT
 3 MARK
 1 ABORT

---

The high level problem is clear: there is interference when popping or
compacting the frame we are currently running GC on, so today we abort the GC.
This makes it possible to get stuck in a loop aborting GC, which causes memory
leaks.

The issue happens both for popping frames and compacting. It's probably more
noticeable and significant when compacting, but easier to understand when
popping frames.

Conceptually I'd like the solution to be to finish out the current GC in this
case instead of abandoning it. We may end up doing some unnecessary traversal,
but it would ensure forward progress and in theory makes perfect sense.

If I remember correctly, the GC algorith works roughly as follows:

* We have a stack of frames.
* Each frame stores GC allocated objects in one of three sets: alloced,
  marked, and unmarked.
* Invariant: if an unmarked object on a frame is reachable, it is reachable
  from a marked object on that frame.
* Thus if the set of marked objects is empty on a frame, we know all unmarked
  objects on that frame are unreachable.

When you first GC alloc an object to a frame, it goes to 'alloced'. When you
return a result to a frame, the returned result goes to 'marked' and
everything else allocated on the returning frame goes to 'unmarked'. To GC a
frame, you traverse through 'marked' objects over anything in 'unmarked',
adding those to 'marked' and moving the marked object to 'alloced'. You are
done when there are no more 'marked' objects to traverse.

Now let's say you are doing GC on a frame and during that process you pop the
frame. We set aside the 'marked' and 'unmarked' objects of the frame that GC
is working on compared to any new ones. If GC continued to work on those set
aside objects, what does it do to a marked object after it's done visiting it?

Case: The marked object was the value returned when the frame returned.
  It should be moved to 'marked' in the parent frame. Or 'alloced' ???

Case: The marked object is reachable from the value returned when the frame
  returned.
  It should be moved to 'marked' in the parent frame. Or 'alloced' ???
  Or it could be moved to 'unmarked' if the returned value was moved to
  'marked'.

Case: The marked object is not reachable from the value returned when the
  frame returned.
  It should be moved to 'unmarked' in the parent frame.

Perhaps that's the key:
* After traversing a 'marked' object, move it to the 'unmarked' group of the
  parent frame, unless it was the object returned, in which case move it to
  the 'marked' group of the parent frame.

That makes sense, because it's consistent with what would have happened had GC
finished on the frame before it returned.

I guess there's another issue, which is the question of knowing what objects
to traverse from 'marked'. I seem to recall when we move an object from
'marked' to 'alloced', we update a generation id in the object to keep track
of that. That can continue to work, so long as we simulate what would have
happened had we finished GC before popping the frame.

Sounds like I have a plausible approach with the clear guideline: treat things
as if GC had finished before popping the frame. Let's review the source code
and see if I have any concerns.

No concerns. Only point worth noting perhaps is that we keep track of a
'min_gen' and 'gen' for a frame, and the way we know what to traverse is
anything that's >= min_gen but != gen. That is, objects allocated at or below
this frame, except for 'gen' which are things that have already been
traversed.

Next step is to work out the book keeping for GC on a frame that has been
popped.

We need:
* Original gen, min_gen of the frame gc is done on.
  Easy. Make a copy of them at start of GC.
* Target frame to move 'marked' objects to.
  And whether to move it to alloced (frame didn't pop)
  or to 'marked' (value was returned) or to 'unmarked' (frame did pop).

How do we deal with multiple pops during a GC? Then we have multiple values
being returned. We need to keep track of the most recent.

For CompactFrame, it's not just one value being returned, it's a list. How do
we keep track of the set and do fast lookup?

Could we make use of 'gen' of the marked object to manage things more easily?
For example, when we return (or save) an object, update it's gen right away.
After traversing it, cases are:
* gen matches target heap, move it to alloced (frame didn't pop)
* gen > target heap, move to unmarked (frame did pop)
* gen < target heap, move to marked (value was returned)

Sounds plausible. Tricky, but plausible.

---

We need to be careful whenever we move or change the generation of an object,
because that could break the current GC round.

For example, if we move an object to a parent frame, and that object happened
to be on the 'marked' list in gc, then we break GC. Anything that object
refers to that hasn't been marked yet could get prematurely collected.

If we change the generation of an object to a parent frame, and that object
happens to be on the 'unmarked' list in gc, potentially we could break GC
unless we explicitly move the object off the 'unmarked' list when we change
its generation.

Let's draft some details, not worrying about compact frame just yet.

Straw 1
=======
Same list structures that we have today:
* Frame: alloced, marked, unmarked
* GC: marked, unmarked

PopFrame, assuming GC may or may not be in progress on the frame we are
popping.
* alloced => parent.unmarked.
* marked => parent.unmarked.
* unmarked => parent.unmarked
* return value => parent.marked
* GC.marked => unchanged (we have to let GC finish)
* GC.unmarked => unchanged (we have to let GC finish)

But here is where much care is needed. The return value could be GC.marked or
GC.unmarked. If so, we can't move it. Unless we visit it first?

Let's say we GC visit the returned object. What would happen?

I need a way to refer to how things are related on the stack.

Say A calls B calls C. 'A' is an older generation frame. C is a younger
generation frame.

If the returned object is on a younger generation frame than current GC, we
should not visit it when returning, otherwise it would pollute the current GC.

If the returned object is being returned to the frame we are currently doing
GC on, again we should not interfere with current GC.

If the returned object is from the frame we are doing GC on, it could either
be in frame.alloced,marked,unmarked or GC.marked,unmarked.

If it's in frame.alloced,marked,or unmarked, we want to move it to the caller
frame.marked without effecting the current GC.

If it's in GC.marked,unmarked, we want to visit refs, then we can safely move
it to the caller frame.marked.

We ought to be able to determine where the object is from the gen, right?

gen can tell us:
* If gen < GC.min_gen, the object is from an older generation.
* If gen < GC.gen, the object is currently in GC.marked,unmarked
* Else if gen < FRAME.gen, the object is in FRAME.marked,unmarked
* else object is in a younger generation frame.

I claim, as long as we ensure gen for an object stays accurate, and we keep
track of generations in the current GC, that should be enough for us to figure
out where things are and where things ought to go when.

I think this simplifies how we handle GC, based on the idea that when we
PopFrame or Compact, we take care of the returned/saved value immediately,
traversing it if necessary to avoid breaking the current GC.

Except we still need some way to keep track of where to put a marked object
after we finish traversing it.

---

I want to be careful. Let's say we return from a 100 deep stack, with GC at
the top of the stack. It's important that this doesn't result in 100 GC
iterations with GC chasing down the stack. That would result in pathological
poor performance.

If it takes GC 50 stack frame pops worth of time, then once that first GC
finishes, it should jump right to the GC 50 down the line.

Let me pose the problem a slightly different way. Say GC becomes totally
independent of the frame it's working on. We have GC.alloced, GC.marked,
GC.unmarked, and all generation ids required for the GC. We can finish GC
entirely, always move everything to GC.alloced.

How could this fit with frame pops going on during GC?

A. If the GC frame wasn't touched or popped during GC, then move GC.alloced
back to the frame that GC was run on. This is what we do today.

B. If the GC frame was popped, we will have returned a single value when it
was popped. There are two cases:

1. The value returned was not in the set of objects being GC'd.
Move the returned value to parent frame's marked.

At the end of GC, move GC.alloced to the parent frame's unmarked.

2. The value returned is in the set of objects being GC'd. 
Traverse returned value right then. Move the returned value to parent frame's
marked.

At the end of GC, move GC.alloced to the parent frame's unmarked.

C. If multiple levels of the GC frame are popped.
Repeat the same logic. Pull out returned values as needed, Update the target
frame for GC.alloced when it is done.

We can do this as long as we can always easily tell, for a given object, if
it's in the current GC set or not. I think that should be doable based on
generations.

So, high level idea is this:
* GC keeps track of it's alloced and relevant generations.
* We keep enough info about GC to know if an object 'belongs' to GC or not.
* We keep track of where to store the GC.alloced result of GC
  Some frame.alloced, or some frame.unmarked.
* When we pop/save a value that belongs to the GC generation, we pull it out
  of the GC generation and update the GC target.

Easy, no?

The key challenge will be maintaining information to know what objects belong
to the GC generation. Let's see if we can work out the details.

We store with gc:
* min_gen - objects with gen less than min_gen are not in the current gc.
* ...

I need to remind myself how the MarkRef logic keeps track of what to traverse.

min_gen - objects with gen less than min_gen are owned by some parent frame.
  They should never be traversed by GC. They can never point to something with
  gen >= min_gen.

gen - Objects allocated before the most recent compaction on the frame have
  gen >= min_gen and less than gen.

When we call PopFrame, we move to marked/unmarked a bunch of objects whose gen
is greater than min_gen. In this case, frame.min_gen = frame.gen, so a bunch
of objects have gen greater than both frame.min_gen and frame.gen.

When we call CompactFrame, we move to marked/unmarked a bunch of objects with
gen is >= frame.min_gen, but < frame.gen. None of them are larger than
frame.gen.

MarkRef works correctly in both these cases:
  gen >= frame.min_gen && gen != frame.gen

For the PopFrame case, this is equivalent to gen > frame.min_gen, as desired.
For the CompactFrame case, this is equivalent to gen >= frame.min_gen && gen <
frame.gen.

Objects allocated after gc could have:
* gen >= GC.gen in the case of compaction.
* gen == GC.min_gen, or gen >= heap.gen in the case of pop frame.
  That is, more objects allocated on the current frame, or objects allocated
  on some new frame.

The challenge is, when we start GC, the frame could have a combination of
unmarked/marked coming from frame pops or frame compaction?

While I'm thinking about it, it bothers me that heap->gen continually
increases and is never reset to a smaller value. At some point, if it wraps
around, GC will fall apart.

Maybe we could redesign 'gen' to track precisely what it needs?

What gen needs is, when we start GC on a new frame, the unmarked/marked have
to know which references go to a parent frame. That suggests, at each frame,
at minimum we need at least one gen for each distinct frame of the stack.

We always GC from older frame to younger frame, right? Let's ignore
CompactFrame for now. Could we allocate gen for an object as the stack frame
depth?

Objects in the GC set cannot refer to objects up the stack. So I think that
can work. Anything in the GC set for frame X with gen Y > X can only be
reachable from an object allocated on frame X. So if we don't see it when
traversing objects from frame X, we know it's unreachable.

In that case (still no compaction), the GC set just needs to know the id of X
to know what objects it should traverse. When it's done, it updates ids of all
objects to X? Is that even needed? I think not. No need to update objects. If
it's in the alloced/marked/unmarked set for frame X, then it's not reachable
from anything outside of the alloced/marked/unmarked set for frame X, and it
has id >= X.

No. That's not right. Consider this case: we have a bunch of objects returned
to frame X in alloced/marked/unmarked, including one with id X+1. Then we push
a new frame with id X+1, and take a reference to an 'X' frame object with id
X+1. We don't know that we should not be traversing that referenced 'X' frame
object with id X+1. So yes, after GC, we need to update all objects to have id
'X'. The important point is we don't start a new GC until all object id's have
been updated to 'X'.

Next layer of complexity: CompactFrame.

On frame X, we have a bunch of objects with id >= X. alloced/marked/unmarked.
When we compact frame, we move all but saved objects to unmarked. What's the
problem? Why do we need any special behavior in this case?

I think it's this. When traversing marked/unmarked, we don't want to
re-traverse anything in alloced. For pop frame, everything in marked/unmarked
has id > X, and everything in alloced has id X. We can use that to keep track
of what's already been traversed.

In the case of CompactFrame, we have some objects with id X that we want to
traverse, so we need to pick a new, unique ID that no objects in
marked/unmarked have. That's the hard part. We can't pick X, anything less
than X, or anything greater than X that might exist. So we have to pick a
completely new ID that has never been picked before.

But we only need to pick that new ID once we start a round of GC. Could we get
away with two ID's for each frame? X and X+1? We keep track of which is
active. We promise that no objects on the frame have id 'X', or the other way
around, no objects on the frame have id 'X+1'. At the start of GC, we flip
between them, by the end of GC, the invariant holds true.

Now CompactFrame is nothing special. We have alloced/marked/unmarked. The key
is we know either 'X' or 'X+1' is unused, so we can move all objects traversed
there. Now generation ids are limited by stack depth, and I no longer have any
fear of running out (you'll run out of memory before you run out of ids).

Is it enough? I'm not sure. If everything is pop frame, we can keep X always.
If everything is CompactFrame, we can alternate. But what happens when we have
a mix? Should be okay? CompactFrame switches, PopFrame keeps. PopFrame
accumulates objects to the target Gen, compact frame whole sale ... I'm not
sure still.

PopFrame puts objects into marked/unmarked, promising all ids are greater than
X (and X+1). CompactFrame puts all objects into marked/unmarked, promising ...

So the invariant is:

alloced: all have id A
unmarked/marked: all have id != A

New alloces go to A.
PopFrame all in unmarked/marked have id > max(A,B).
CompactFrame: Move alloced to unmarked/marked. So it has id A, pick B now as
the new id. But we could ...

No, it's not enough. New allocs after compact must have a different ID than
compacted allocs in unmarked/marked. So some have X, some of X+1. If you
compact again, you need to move all those to unmarked/unmarked, thus having
used up your X and X+1 ids.

Needs more thought.

---

Okay, how's this for a solution.

1.
Each frame has X, X+1 for generation. Really this is a stack depth plus an
extra bit for GC phase. Each frame has GC phase P set to 0 or 1. You allocate
new objects to generation X+P.

At start of GC for a frame, you toggle the phase for the frame. An object of
the GC is considered done with GC after it's gen is set to the new X+P. We
are guaranteed there are no untraversed objects of generation X+P in the GC
set, because when the previous GC finished there were only objects allocated
of the other frame, just as when this GC finished there will only be objects
of X+P on the frame.

No need to have separate 'min_gen' and 'gen' for a frame. A single 'gen'
suffices. When you compact a frame, you simply move all alloc/marked/unmarked
to unmarked, and move save to marked.

GC should traverse any objects >= GC.gen that are not equal to X+P.

We can make that change. That will solve the concern about running out of gen
ids. Gen id is limited by stack depth. We'll run out of memory before we run
out of ids.

2.
When we pop or compact a frame that is currently undergoing GC, we record the
returned/saved value(s), but we do not move them yet. We wait until GC
finishes. We update the target of GC to the appropriate 'unmarked' list, we
keep the target gen as the original X+P that GC was going to do anyway.

When GC is finished, we take the recorded returned/saved value(s) and move
them to 'marked'.

We pop or compact a frame that has GC going that already has some of these
recorded value(s), simply discard the existing recorded values and save the
new ones.

The extra space needed to record these values is bounded by the largest number
of saved variables in a single compact, so it will be relatively small. We can
have a dynamically allocated array that we expand if/as needed.

And that's it. Simple as that, we make it so nothing interrupts the current
GC, but we're still able to batch together everything that happened down the
stack in the time it took the current GC to complete.

Net benefits of these changes:
* No more concern about running out of gen ids.
* No more memory leak due to interrupted popped or compacted frames.

There is some minor detail to work out in terms of how we keep track of the
target of a GC and whether the frame we are popping/compacting is the current
frame. Maybe easiest is to track a pointer to the frame we are running GC on.
We know to move objects to 'alloced' if target X+P matches the frame, we move
objects to 'unmarked' if target X+P is greater than the current frame.

So, for GC,we store: marked, unmarked, target X+P, pointer to current frame
being GC'd, and the frame to GC next.

---

I drafted up the code for part 1. The code's not bad. But we're getting seg
faults at runtime. Will need to debug.

Let's start with MemoryGrowth, which isn't showing any growth. That suggests
objects are being GC'd when they ought not to be.

---

Okay. Comparing traces of known good versus failing, I can see a case where we
are not marking an object we expect to. In memory growth, based on my tracing,
it's around line 5550 in the trace.

We are traversing an object that's moving from 480 to 496 in the original GC,
it sees a reference to another object with gen 480, which it follows.

In the new gc we are traversing an object that's moving from 2 to 3. It sees a
reference to another object with gen 3, which it does not follow.

Let's track this GC and understand how we could end up with an object there
which we had not visited but which had the target generation in place. Because
according to my theory, That shouldn't be possible.

We start from the previous gc, which moves the misgenned object 0x55b6048e70
to the gc target gen 3. Now 0x55b6048e70 is in 'alloced' with gen 3.

  gc [2 -> 3]
  traverse 0x55b6048e70[2 -> 3]

We traverse for a while, moving a bunch of objects to gen 3. Then we finish
that GC and move on to the next one

  ...
  traverse 0x55b6045fa0[20 -> 3]
  traverse 0x55b604aa20[20 -> 3]
  pop [6]
  gc [4 -> 5]
  gc [6 -> 7]
  pop [5]
  gc [5 -> 4]

  compact [3]
  gc [3 -> 2]

Now in theory we are starting the gc that ought to move the object in question
to generation 2. But we never see that object. We start a new GC, and then run
into trouble:

  gc [2 -> 3]
  traverse 0x55b6041380[2 -> 3]
  0x55b6041380 ==> 0x55b6048e70

Hypothesis:
* If we pop the frame GC is working on, we do the following:
1. Move top->alloced to top->unmarked. So top->unmarked contains target gen.
2. Move heap->marked/unmarked to top->unmarked. So top->unmarked contains
other phase.

Now we've mixed together objects with X+P and X+'P together, we are screwed.

What's interesting is that if we finish out GC every time, this wouldn't be a
problem. Like, maybe if I implement Part 2, I can get around this issue.

Perhaps as an intermediate stepping stone we can increment phase instead of
toggle it? No, it wouldn't fit in a single bit in gen if we did that.

Well hmm... Should we make the jump, go to the full solution and hope for the
best?

How about this: split depth and phase. Get GC working with that. Then do Part
2, get GC working with that. Then toggle instead of increment phase, get GC
working with that. Then merge depth and phase into gen, get GC working with
that.

---

I think we need a global gc phase, not per frame. Because we could pop a
frame, push a new one, then end up with a mix of objects at higher phases that
we don't expect.

This is tedious.

No, it doesn't work. We're ending up with double free. I'll need to understand
what's really going on here to address the problem properly.

---

Review of invariants.

1. An object in GC.unmarked is reachable iff it is reachable from an object
in GC.marked.

This is the key invariant to maintain. Since that holds, as soon as GC.marked
is empty, we can free everything in GC.unmarked.

2. An object in Frame[x].unmarked is reachable iff it is reachable from an
object in Frame[x].marked. Needed to preserve invariant (1) when starting GC.

A. Mark operation preserves invariant (1).
The object being marked cannot be in GC.unmarked, because it is in GC.marked.
To remove the object being marked, we must ensure that all objects in
GC.unmarked that are reachable from marked are subsequently reachable from
some other object in GC.marked.

Consider a reference from the object being marked to some other object X. Case
on X:

* X is the object itself. By some sort of induction, we can skip this case.
* X is in GC.marked. We can skip this case, because anything in GC.unreachable
  reachable via this reference is also reachable via X, which is in
  GC.unmarked.
* X is in GC.unreachable. We move X to GC.marked.
* X does not belong to the set GC.marked,GC.unmarked. We can skip this case,
  because any object reachable...

I want to strengthen invariant (1) to say an object in GC.unmarked is reachable
iff it is reachable via a path of objects starting from GC.marked and
continuing through objects from GC.marked,GC.unmarked.

That way we can easily ignore any references X going out of an object being
marked that don't belong to GC.marked,GC.unmarked.

Good. I think that's clear. We need to ensure we preserve this invariant going
into GC. We need ensure our logic for determining if X belongs to the set
GC.marked,GC.unmarked is correct.

3. No object in GC.unmarked has depth and phase equal to depth and phase of
GC.

4. If an object X in GC.marked,GC.unmarked has a reference to some other
object Y, and Y.depth > X.depth, then Y is in GC.marked,GC.unmarked.

5. If an object X in GC.marked,GC.unmarked has a reference to some other
object Y, and Y.depth = X.depth, and Y.phase != X.phase, then Y is in
GC.marked,GC.unmarked.

---

Okay, I think I got it.

When we do GC, we have some set of marked,unmarked. Let's call this the GC
set. What we need is some way to distinguish between objects in the GC set,
and objects reachable from the GC set but not in the GC set. We don't care
about objects not reachable from the GC set.

The original, working approach:

* PopFrame: objects in GC set have gen greater than frame gen, object's
  reachable from GC set not in the set have gen less than or equal to the
  frame gen.

* CompactFrame: objects in GC set have gen greater than frame min_gen but not
  equal to frame gen. Objects reachable from GC set not in set have some
  other gen.

My current, broken approach: We only need to find an example where we can't
distinguish objects properly.

X in frame 1.
Y in frame 2 references X.
Pop Y to frame 1, run GC.

Now we think X is in the GC set, because X frame 1 >= GC frame 1 and X phase 0
is less than GC phase 1. That's wrong.

Can we come up with a better approach? Better meaning, easier to reason about
and not leaking ids.

PopFrame is easy: we can use stack depth to easily distinguish between GC and
non-GC objects.

CompactFrame is the tricky one, so let's focus there.

Before any CompactFrame, objects in the GC set have depth greater than the
current frame.

After CompactFrame, some objects in the GC set have depth equal to the current
frame. Let's focus on those. How do we distinguish those from newly allocated
objects?

Claim: We don't care about truly newly allocated objects, because we can't
have any references to them from the GC set (double check the assign ref case
though).

That means we only need to care about objects we have traversed from the
current GC set. But I still think a single phase bit should be sufficient
for this. New objects get allocated with the target phase, we move objects to
the target phase. We only check target phase when the depth is equal.

What's broken in my current implementation is we mix up the PopFrame and
CompactFrame cases. In the PopFrame case, same depth objects are always
outside the set. In the CompactFrame case, same depth objects are outside the
set depending on phase.

Say new objects are allocated to phase 0. We aren't running GC on this frame
yet. We can call PopFrame all we want, no need to adjust target phase.

As soon as we call CompactFrame, we need GC to know that phase 0 objects
should be considered part of the GC set. We can continue to allocate new
objects to phase 0, because they aren't reachable from the GC set (double
check assign ref case).

Except, if we call PopFrame again, we might add objects into the GC set that
refer to phase 0 allocated objects. That's no good. So a single bit will not
be enough.

Whenever we call CompactFrame, increment the frame phase. Allocate new objects
to the new phase.

When it comes time to do GC, we traverse objects with depth greater than the
current depth, plus objects whose depth equals the current depth but phase is
less than the current phase.

I bet this works. I'm not sure if it's an improvement though. We make better
use of ids, but if a single frame compacts enough times, we still run out. And
the cost is an extra word in the GC header of an object to maintain.

Is there any time we could reset the phase for a frame?

Once GC has started on a frame, new objects could be allocated to phase 0. But
objects moved out of GC can't, because they may be reachable from within. We
could keep track of a start phase and an end phase though, which would allow
us to wrap around.

Is there anything better we can do?

Any time we call PopFrame, it might add a reference from GC set to newly
allocated objects. Any time we compact, we need a way to distinguish compacted
objects to newly allocated objects. Assuming we don't modify objects when we
do compact, we need a way to distinguish between N sets of objects, where N is
the number of times we compact the frame since the previous GC on that frame.

Random brainstorm time.

It would be nice if we could preserve that newly allocated objects have phase
0. What if phase itself had two parts: a count and a GC cycle A or B?

Once GC starts on a frame, flip the GC cycle for the frame and reset the phase
counter. For example, go from odd phases to even phases. I think that works.
We can still use phase to distinguish between N things, we just have a more
natural way of resetting it after each GC.

Another idea: Say we run GC on a frame. Now we promise not to run GC again on
that frame until PopFrame or CompactFrame has been called on that frame. Then
maybe we don't need to distinguish between different CompactFrame calls. We
have a single phase bit. New objects allocated during GC get the new value.
Not sure.

---

Summary of some thoughts.

The current approach relies on having an easy way to distinguish between
objects that have or have not already been traversed this GC round.

If it weren't for CompactFrame, this would be easy. Set an objects frame
number to the current frame to indicate it has already been traversed this
round.

That doesn't work with CompactFrame, because some of the untraversed objects
may have object frame number set to current frame to start.

There are a few different approaches to get around this:

1. Store stack depth and phase with an object. Each time we compact frame, we
increment phase. We can tell if an object is traversed or not by comparing
both depth and phase.

Downsides:
* Extra word of memory needed per object to track the phase.
* To avoid issues with overflows, we need an extra bit somewhere to let us
  reset the phase.

Sounds complicated and practically expensive. Conceptually the cleanest
approach.

2. Try to merge depth and phase into a single entity 'gen'.
This is the current working approach.

Downsides:
* No clear way to avoid issues with overflows.

Practically nice, conceptually and theoretically pending towards not viable.

3. Double traverse reachable objects.
We can have a sentinel id reserved for GC that we move objects to during GC.
Then we add an extra traversal at the end of GC to set depth back when GC is
done.

Downsides:
* 2x traversal of reachable objects presumably doubles the latency of GC.

Maybe okay?

4. Traverse alloced objects too.
If we know some unmarked/marked objects have depth equal to the current frame
to start, move all alloced objects to marked as well. Use a phase bit to track
the new ID to allocate to.

Downsides:
* Extra traversal of known allocated objects.

Better than (3) I think, because unmarked/marked objects grow in scale more
than direct alloced objects on a frame.

---

There are unknowns in terms of performance costs. Certainly I want to try (4).
Maybe the trick is to try (4) and compare it performance wise to our current
(2). That should give a sense of worst case performance overhead. If it's not
bad, go with (4).

Let's work out details for 4.

* Object stores stack depth + single bit phase.
* Alloc allocs to current stack depth and phase.
* PopFrame as is now.
* CompactFrame moves objects to marked/unmarked, does not touch phase. Set a
  flag on the frame to indicate some objects in marked/unmarked may have
  current alloc stack depth and phase.
* On GC start, if that flag is set, toggle phase on the frame, move all
  alloced to marked, and reset the flag.

I think it's that simple.

How do we want to store depth + phase? Probably like before:
gen = 2*depth + phase.

Let's draft it up, see how goes.

---

To start, same issue as before. As long as we can interrupt GC, a single bit
for phase isn't enough.

After changing phase to a counter, now I'm getting a memory leak somewhere,
and elsewhere corruption of some sort. So there must be some bug still.

Maybe I should start with the pure depth,phase approach, which is supposed to
be the simplest conceptually? Otherwise... take the time to debug so I learn
why it's not working.

---

Pure depth,phase approach seems to work better. Let's start there on our
exploration.

Do we have to worry about cycling over? No. As long as GC happens before 2^64
frame compactions, it should be fine. We only ever do equal or not equal
comparison for phase.

That fixes the concern about cycling over. At the cost of object overhead for
storing the phase in addition to the stack depth.

Actually, seems like it doesn't work. :(

Here's my plan: enable tracing again on the simplest test failure I can find.
I expect GC operations to happen identically in both cases. Find the
difference and we can track down where things went wrong.

Specially I want to keep track of the MarkRef decision sequence.

Maybe print: global count, decision, followed by gen/phase information.
Hopefully vim can deal with diff for that well enough.

Program to trace to start, because it seems to fail quickly.

./pkgs/fbld/bin/fbld ../fbld/nobuildstamp.fbld ./fbld/version.fbld
../fbld/html.fbld ../README.fbld > ./www/README.html
