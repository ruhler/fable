Fble Language Thoughts
----------------------
* Vague concern: will fble support static evaluation / compilation to
  hardware? Is it bad to support structs and links that can hold functions and
  processes?

  I envision static evaluation as follows: you evaluate a program to, say, a
  function. That's the static evaluation pass. The result will be based on the
  interpreter you are using. If you have a hardware interpreter, for example,
  the resulting function will be a description of a hardware circuit.

* Issues that came up when switching to the new unit test format
- Should we have some form of relative reference?
  It seems bad that every time you import a module, you have to duplicate a
  potentially long path from the root. Any change you make in module hierarchy
  would require rewriting all references into that module hierarchy. If we had
  some way to write a path relative to some other path, maybe that could be
  avoided.

- Static analysis to detect obvious invalid union accesses might be nice. I've
  already run into that kind of bug multiple times. Though to be honest,
  comprehensive test coverage makes it really easy to spot and fix these bugs.

  And there is now precedent for emitting warnings from the compiler.

- Fairness
  I think it would be cool if children were executed fairly. In particular,
  the amount of runtime a child gets is independent of how many children its
  siblings has.
  
* It would be awesome to have a well defined style guide for programming in
  fble. And maybe an automatic re-formatter.
 
  Goal would be a balance between not having too much or too little on a
  single line. Propose some width limit on line, such as 80 chars, but to
  avoid too little as things are squished to the right, make that 80 chars
  past the indent of the line.

  For each expression, figure out how to lay it out assuming all components
  are really big. Then implement some packing algorithm to move things to a
  single line if it fits.

  Working style guide proposed in fble.style.txt.

* There's no good support for abstract data types. You can't export a union or
  struct type abstractly without also exporting the fields and constructors
  and deconstructors. That seems bad, because it means you can't easily
  control the invariants with which your data type is constructed.

  From the point of view of the type system, it wouldn't be hard to turn a
  struct or union type into an abstract type. We just need some way to express
  that in the language?

  Proposal:
    @ Foo@ ?= *(...);
    ...

  Where the '?=' means Foo@ is abstract outside the body of the type let.
  Easy. Does it let you split things across submodules?

  See fble.adt.txt

* How can we make a fast implementation of the language?
  Like, really fast? This, to me, feels like the single most major fundamental
  problem with the language. Can we make it fast.

  Some particular disadvantages we face, compared to, say, c:
  - no primitive types or operations
  - automatic reference vs. value
  - immutable data types
  - automatic memory management
  - closures that capture variables from local scope
  - light weight multithreading

  See fble.performance.txt and friends.

* Should we support zero-argument functions now?
  They aren't necessary, because you could always do a single argument
  function that takes a unit. But it seems a little arbitrary to disallow them
  now?

* Should we have support for generics?
  See fble.generics.txt.

* Should we add support for unordered struct types?
  The concern is that someone writes down an explicit type for a module, then
  the module implementors reorder fields or add fields to that type, causing
  the user to break. Is this captured already in the discussions on API
  versioning that we have done before?

* A common question that comes up is whether to fuse two things in a single
  loop traversal or do them separately.

  For example: in the test runner, should we count the number of tests in the
  same loop we run them in, or should we call a separate list length function?

  For example: in the sat solver, should we track pure literals and units
  during substitution, or do those in separate passes?

  This seems like an important place where composition of functionality
  perhaps doesn't support good performance? Is there a language feature or
  approach to library design that maintains the flexibility we would like to
  have: we can specify iterations separately but somehow compose them together
  for performance reasons if desired?

* Sometimes it's pretty tedious writing code.
  For example, implementing Map.IsEmpty, you test a bunch of conditions, and
  want to break out as soon as you find any element in the map. In C++, I
  would write this as a sequence of checks:

  if (there is a value here) {
    return False;
  }
  if (there is a value to the left) {
    return False;
  }
  if (there is a value to the right) {
    return False;
  }
  ...

  But in fble that becomes nested:
  if (there is a value here) {
    return false;
  } else {
    if (there is a value to the left) {
      return false;
    } else {
      if (there is a value to the right) {
        return false;
      } else {
        ...
      }
    }
  }

  Which is rather a headache to have to read and write. Anything I can do to
  clean this up while preserving the efficiency of breaking out at first sight
  of a value?

  And it's annoying that it's so much harder to implement something like
  IsEmpty than it is to implement something like ForEach, if you want to break
  out of the computation early.

  Another good example is the Alien Tick function for the Invaders game, which
  describes a single step of a finite state machine. Each state updates a
  small number of fields, but we have to mention every field in every state
  update because we can't do updates in place.

  Another good example is a delete function for a binary tree based map,
  because there are something like 6 different cases nested at different
  levels. It would be so much nicer if we didn't have to nest. 

  Proposal: let's have a variation on case expression that works in statement
  mode. Syntax looks something like:

  expr '.?(' name ':' ... ')'; expr

  Which is equivalent to:
  expr '.?(' name ':' ... ':' expr')'

  Hmm... Doesn't look so clean in practice I fear.

  I think better is something like:
  stmt ::= expr '.?' name { stmt } stmt

  Which is equivalent to:
   expr '.?' (name: stmt, ':' stmt)

  Now you can say things like:
    x.? just { 
      Foo(x.just);
    };

    y.? just {
      Foo(y.just);
    };

    Foo(5);

  Maybe it's worth a try?

  But note, this is the same exact problem function bind syntax was introduced
  to solve. In theory we should already be able to do something like:

  Unit@ _ <- ifJust<Foo@>(x, {
    Foo(x.just);
  });
  Unit@ _ <- ifJust<Foo@>(y, {
    Foo(y.just);
  });
  Foo(5);

  Now, it's annoying to have to define IsJust for any tag we might want to use
  this with, and a little annoying to have to write Unit@ _ <- , and annoying
  to have to write the type that we are returning explicitly, and annoying
  that this probably has higher performance overhead. Could those issues be
  fixed more generally?

  No, it's not quite the same. Because the function bind evaluates its first
  argument strictly instead of lazily. We would need to have the first
  argument be a function. So:

  Unit@ _ <- ifJust<Foo@>(x, (Unit@ _) {
    Foo(x.just);
  });
  Unit@ _ <- ifJust<Foo@>(y, (Unit@ _) {
    Foo(y.just);
  });
  Foo(5);

  This could perhaps be simplified if we allowed zero argument functions:

  <- ifJust<X@, Foo@>(x, () {
    Foo(x.just);
  });

  <- ifJust<Y@, Foo@>(y, () {
    Foo(y.just);
  });

  Foo(5);

  I made a minor adjustment in syntax to have the syntax match normal case
  expressions. Otherwise, let's see if I make use of this as I program. I'm
  not fully convinced yet. The downside of this approach is it relies on
  default branches, which means the compiler can't check for you that you've
  covered all the cases.

  Note: In hindsight, I use this feature a lot. It makes a huge difference for
  code writability and readability.

* A funny thing about kind restrictions.
  Something of kind @ cannot be used in a polymorphic function where <@>@ is
  expected. That makes sense.

  As a consequence of the kind restrictions we put in place on polymorphic
  functions to prevent that, something of kind <@>@ cannot be used in a
  polymorphic function where @ is expected.
  
  This means, for example, that I can't work with lists of polymorphic values.
  Is this a bad thing? I'm not sure.

  What's funny is, we can define a struct type of kind @ that has a single
  field of kind <@>@, and then use that struct type where something of kind @
  is expected. Is this a bad thing? It seems weird. Is it?

  It is weird and unnecessary. We should allow something of kind <@>@ to be
  used where @ is expected, because you can do everything with a <@>@ that you
  can with an @. The same is not true the other way around, because you can't
  apply types to something of kind @ but you can of kind <@>@. Similarly, you
  can use something of kind <@,@>@ where something of kind <@>@ is expected. I
  should update the language spec and implementation to support this.

* Conditionally updating multiple variables.
  Is annoying. For example, I have variables x, y, z. If some condition holds,
  I want to update x and y, otherwise leave them as they are. How do you code
  this?

  % xyz = p.?(true: @(x: ..., y: ..., z), false: @(x, y, z));

  For now, where the variables already belong to a struct, I'm going:
  XYZ@ xyz_ = {
    p.?(false: xyz);
    @(x: ..., y: ..., z);
  }
  XYZ@ xyz = xyz_;

