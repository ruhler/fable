Fble Profiling
==============
Goal is to update fble runtime implementation of profiling to output in a form
suitable for consumption by pprof. See pprof.txt for context.

Actually, I think it's totally doable and simpler than what we have today.
Here's the proposal:

We keep to data structures:
1. The stack.
2. The profile.

The profile is a tree of nodes, where the path from the root to the node is a
compacted sample path. But we allow there to be back edges in case adding a
frame to a stack would cause us to compact and drop nodes. Each node keeps
track of time and entry counts.

The stack is a stack of pointers into the profile that tracks the current
position. When you enter a frame, you update the pointer in the profile based
on that frame and push it on the stack. When you tail call, you update the
pointer in the profile based on that frame and update the top of the stack.
When you exit a frame, you pop the stack and go back to whatever pointer into
the profile is left.

Really the only difficult operation is given a profile, a pointer into the
profile, and a new frame, traversing to the right next place into that profile
with compaction accounted for.

The general idea is:
* If the new frame is already a child node of this node, follow it and you're
  done. Easy. Fast. We can do binary search for child nodes. Most nodes will
  have only a few children, but some of the 'FbleCall' variety could have
  lots, so best to do binary search.
* Otherwise see if we can compact:
  If the current node matches. That's a 1 compaction.
  Else try a 2 compaction: 2 nodes up matches for two nodes.
  Else try a 3 compaction: ...
  Until we run out of possibilities.
  If you find a compaction, add a back edge to the start of that.
* If you can't compact, add a new node.

Our tree nodes will need a pointer to their parent to check for compaction. I
think we should also keep track of the depth of the tree node, so we can
quickly identify back edges so we traverse the tree.

It's going to be messy. Tests will need to be updated. But I think this will
be good. Let's give it a try and see how goes.

---

I'll need to change the FbleProfile data type. Can we make it not be public to
start? That seems like a decent first step?

It will mess up test cases, but I'll have to rewrite those anyway.

Can I use NULL instead of having an enabled flag? No. We want people to be
able to use the APIs not knowing if profiling is enabled or not. Best to make
that enabled flag internal and provide a function to manipulate it.

How will I update profiles-test.c? Should I add an API to be able to query the
profile? Anything more than just outputting a profiling report?

profiles-test.c at least would be useful to keep around.

---

I have two kinds of profile tests:
1. fble-profiles-test checks expected number of calls in /ProfilesTest%
2. fble-profile-test is unit test for the FbleProfile APIs.

Let's not worry about them for now. Revisit after I switch to the new API.

---

Sketching out the new implementation, the code looks pretty nice and easy so
far. I just need to do a few bits:
* EnterBlock is the fun one: binary search in the profile, if nothing found,
  search for compaction and insert a new node sorted.
* FreeNode should be straight forward.
* GenerateReport: Maybe just traverse the tree, and at each node, print the
  count (?), time, and then walk up the tree to figure out the sample path (in
  reverse order). Or pass the sample path prefix down as an arg.

---

Looks like the new implementation works now?

Let's compare performance and results before/after.

Here's the new implementation:

yes | head -n 200000 | /usr/bin/time -f "%E" ./out/pkgs/md5/fble-md5 --profile
md5.new.prof.txt --
c2938b130a1d2db9597a9c9a8ea2a5cf  -
2:37.36

Here's the old implementation:

yes | head -n 200000 | /usr/bin/time -f "%E" ./out/pkgs/md5/fble-md5 --profile
md5.old.prof.txt --
c2938b130a1d2db9597a9c9a8ea2a5cf  -
3:32.20

So definately performnace is improved. 2.5x overhead instead of 3.5x overhead.

Looking at the results themselves:
* Um, there are an absurd number of samples. Is canonicalization not working?

It's got the expected number of samples based on md5.old.prof.txt. But
pprof.py runs out of memory processing those all.

Let me see if I can hack up a script to canonicalize and see if we are
under-canonicalizing.

It doesn't look like we are missing any canonicalizations. I think md5 just
happens to have a large number of different paths with all the rounds and
stuff. Let me try a simpler program to compare results on.

Yeah, on core tests, the profiling info matches what we had before. Looks
good.

Awesome. I'm happy about this. Just a bunch of things to clean up now.

---

I need to get tests back in place. Which means I need a way to query the
profile.

For fble-profile-test, I want to be able to write what would be printed out
for the profile. But also I want to check counts as well as time?

The most general API would be something that can iterate over all the
sequences and get count and time for them. From that I could implement queries
for specific samples. Hmm... Yeah, maybe that's the way to go. It could be
slow to start, but I could implement queries like: count number of different
samples, assert count and time for a given sample. Etc. Worst case, I could
convert into some different structure that I can explicitly traverse.

How about:

FbleName FbleProfileBlockName(FbleProfile* profile, FbleBlockId block);
void (*FbleProfileQuery)(FbleProfile* profile, FbleBlockIdV sequence, uint64_t
count, uint64_t time, void* userdata);
void FbleQueryProfile(FbleProfile* profile, FbleProfileQuery query, void* userdata);

---

Trouble with fble-profiles-test:
* How to implement calls with this query interface?

If we have a -> b -> c, then a calls b 1 time, but the profile report is going
to look like:

1 a
1 a -> b
1 a -> b -> c

How can I tell the count for a -> b should be ignored for a -> b -> c? I guess
it's safe to look at sequences that end with a -> b?

Okay, it works out for calls, as long as I look at the end of the sequence,
under the assumption that if a -> b -> c, then there must be a count for 
the a -> b in a sequence ending with a->b.

---

How to update fble-perf-profile to take perf script input instead of perf
report? It should be easy, right?

How we do it in python:
* If line starts with tab:
  Whitespace split into [addr, name, so]
  Strip everything after + from name.
  Push that into sample stack.
* If line is empty:
  The sample stack has the stack in reverse order.

How we do it in fble:
* If line starts with newline, add the sample.
* If line starts with tab:
  Skip space, skip word, get to plus (needs to be or ' ')
* Else: skip to end of line.

What do I prefer? It would be nice not to need a GetLine function. Maybe let's
go more the fble approach, inlining as is convenient.

---

Looks like I have a bug in compaction somewhere. It's rare. Most things work
just fine. But in some cases, seems like I'm marking something as canonical
that I shouldn't be. Like an off-by-one in the sequence check or something.

I have 122 sample traces that perf-pprof.py says all canonicalize to the same
sequence, but fble-perf-profile says can be one of two different canonical
sequences. I should be able to write a unit test for this once I come up with
the example sequence that I'm incorrectly compacting. Hopefully it reproduces
in isolation and isn't a bug with insertion order or something messy like
that.

Okay, so really I have 27 sequences.

And here's the one that canonicalizes differently:

   A;B;C;A;D;C;E;C;E;C;E;C;E;C;E;C;E;C;E;C;A;B;C;A;D;C;E;C;E;C;E;C;E;C;E;C;E;C;E;C;A;B;C;A;D;C;E;C;E;C;E;C;E;C;E;C;E;C;E;C;A;B;C;A;D;C;E;C;E;C;E;C;E;C;E;C;E;C;E;C;A;B;C;A;D;C;E;C;E;C;E;C;E;C;E;C;E;C;E;C;A;B;C;A;D;C;E;C;E;C;E;C;E;C;E;C;E;C;A;B;C;A;D;C;E;C;C;E

I bet it's because in one case we canonicalize from the front, in the other we
canonicalize shortest first. Let me try both ways and see what I get.

First, from the front:

   A;B;C;A;D;C;E

I notice when doing that by hand that we have a lot of skips back: drop
something, and the result exposes something more to drop.

Second, from smaller up:

   A;B;C;A;D;C;E;C;A;B;C;A;D;C;E;

Yeah. So when doing smaller up, we drop things in a slightly different order.

Does it matter? I don't think either implementation has a bug.

Let's minimize the test case:

   A;B;C;A;D;C;E;C;A;B;C;A;D;C;E;C;C;E

Yeah. If you go from the back, shortest first, you drop the C at the end, so
you can't combine ABCADCEC at the front.

I think I prefer how fble-perf-profile does it. So stick with that. It's too
bad there isn't a canonical version. I should probably add a unit test for
this anyway.

Even shorter:

   A;C;E;C;A;C;E;C;C;E

---

PiDigits with --profile is blowing up memory use. Is this expected or a bug?
It's hard for me to believe it would be expected. Surely we have a small
number of repeated canonicalized traces, right?

Review of the code:
* It looks simple enough. Hard to believe anything crazy would be going on?

Let's isolate the issue to PiDigits. Yes, I can easily reproduce with just
PiDigits.

Next step? Trace the profiling logic maybe?

The stack depth is fine. On the order of 200 frames worst case.

So we must be inserting lots of nodes somewhere. Let me see if I can track
that down.

This must be a canonicalization failure. I bet if I look at the sequences,
we'll see clear failure of canonicalization.

Canonicalization looks okay to me. It must be overwriting or replacing
existing nodes? Binary search failure?

Except I've managed to get hundreds of thousands of uniq, and apparently
canonical sequences. Maybe this is a pathological case for profiling?

Let me shrink the size of the benchmark, see if I can get a profile out of it
and look at what I see.

You know what I wonder? In Div, we have different branches for 1, 2p0, 2p1.
That means there is a different path through Div for each different input
argument. And that can easily blow up.

I suspect things are working as intended, and we just have a blowup in number
of different sequences because we trace all paths through functions like Div
separately. For example, if we only had function level blocks instead of
condition level blocks, the profiles wouldn't blow up like this.

Or, put another way, increasing number of cases though which a recursive call
is done beyond 1 can lead to an exponential blowup in profiling sequences,
even with canonicalization.

---

You can't have all sequences of 2p0/2p1 in canonical form. We can only have:
  0, 1, 01, 10, 010, 101

That would give a 6x blowup in number of traces. You would have 6x traces with
some one of those strings as infix. There is exponential growth as the number
of options grows and if you nest calls with sequences.

I'd like to nail down what specific sequences we are seeing in the PiDigits
blowup. Proposal: For each new node added to the profile, dump its sequence in
order. Count occurrences of each frame. The top occurring frames, I think,
ought to be those involved in sequences. Is it Div calling into Sub? Something
else? How many choices.

That's the next step here.

---

Trying to use the new profiling approach for fble-pprof, it seems we are just
generating too large a profile. This is a different case from PiDigits. In
this case, the runtime memory for generating the profile is fine, it's just
too much information for fble-pprof to handle. Like, 60M .prof file, or 30M
.prof file is too big. A 3M prof file is about what fble-pprof can handle
today.

The hack I used to work around this was to randomly sample and only output
the sequences with (random) samples greater than 0. That way we can tune how
big the output is to some extent based on random sampling.

Should I formalize this? Maybe have a --profile-sample-rate XXX option you can
pass. When set, it automatically down samples? Or, --profile-sample-period N
to make it an integer, meaning sample every N bytes? Or, should it be randomly
sampled approximately every N bytes to avoid pathological cases?

I bet it isn't hard to implement. If it makes things actually useful in
practice, isn't that worth doing?

On the other hand, I could down-sample at time of profile generation. Surely
that's much more efficient. And then, perhaps, we could auto downsample until
the number of sequences drops below a certain count?

I think --profile-sample-period is a little better than auto downsampling,
because it lets us keep the same sampling frequency between two different runs
to compare for improvements.
 
Something we could do related to both PiDigits and generating too large a
profile would be only profile at function boundaries. Stop emitting internal
sub-blocks. Let me try that, just for the fun of it.

It seems to fix the PiDigits blowup. I think it helps focus in on the
functions we care about. I don't really need all the rest, unless I want
detailed info about code coverage. Which, so far, I haven't really wanted.

Honestly? I think I should do it. Who cares about code coverage for now?

But note: limiting to functions is not enough. I would still want the option
to downsample.

The trouble is, there seems to be some issue with fble-pprof crashing, so I
wonder if I'm doing something wrong.

The idea is: runtime is solely responsible for enter/replace/exit profiling
calls. Only have blocks per function. But we need to keep the block stack to
keep track of function names.

Yeah. I'll need to look more closely how to properly implement it. It's going
to need some rearrange of the code to track current location separately from
block ids.

---

The problem with fble-pprof was a bug from when I optimized it: ';' versus
','. Easily fixed.

I decided to remove case branches and execution nesting level from the block
names. In practice we could end up with multiple different blocks with the
same name. People can use location information to tell them apart.

We lose the ability to do code coverage, but I don't have any real tooling
support for that today anyway. If we decide to add it in the future, we can.
At that time, perhaps we decide to have --coverage as a runtime option to
enable profiling of all blocks. Or perhaps we do some other special thing
where we only keep track of whether a subblock was covered or not.

---

On profiling downsampling: in theory I should randomize it based on a binomial
distribution, which I could generate using a geometric distribution. But
that's O(np) where n is the number of samples and p is the sampling rate. That
feels expensive to me.

What if we start with an approximation. For a sequence with a large number of
samples n, np is a good approximation to how many we sample. For a sequence
with a small number of samples, who cares? Right? The goal is to shrink the
profiling by getting rid of the ones with a small number of samples.

Except for the pathological case where every sequence has a small number of
samples, in which case we could end up getting rid of all the samples. The key
is to make sure the total number of samples, N, turns into Np.

Proposed implementation: keep a running overflow counter as you dump profile
sequences. Call it 'overflow'.
 
For a sequence with n samples:

   Output n+overflow / period samples.
   Set overflow = n+overflow % period;

Easy, fast.

Because we traverse in depth first, overflow is likely to redistribute to a
similar sequence.

Another thought: we collect count information and output it to the generated
profile, but we don't yet make use of it for anything. Maybe I should remove
it from the output profile until we can do something useful with it? Because
count feels a bit meaningless for fble-perf-profile and downsampled profiles.
That also makes it easier to justify not outputting anything for sequences
with 0 samples (but non-zero counts).

---

* Remove counts from generated profile?

No, don't bother. I confirmed it doesn't save any space to remove the counts.
Lets hold off on making changes until after we have a way to view the counts.

---

How to update book/Profiler.fbld for the new strategy? I think I need to shift
the orientation. It shouldn't be a user guide. We already have the profiling
guide and man pages for that.

I think it should include:
* My personal opinion of a good profiling format (pprof).
* fble specific challenges related to producing profiles in that format
 - Giving names to functions, all of which are anonymous.
 - Dealing with tail recursion, deep recursion, potentially unbounded stack
   traces.
* My personal opinion of how best to view pprof files.
* Other topics to maybe include somewhere
 - The need for deeper context for the foo -> FbleCall -> bar case.
 - The need for not too much context, else things blow up? PiDigits case?
 - Code coverage versus profiling.

Do I want to deal with this now? It's a lot of work to write this stuff. On
the other hand, maybe future me will be happy I got started early.

Let's try. See how far I get before I give up. I can't make things worse than
they are now.

