Fble Compilation Challenge
--------------------------
Should we compile fble to machine code before evaluating it, or should we
continue to use an interpreter?

Advantage of compilation:
* Potential for substantial performance improvements.

Disadvantage of compilation:
* It's more tedious to run a program if you have to invoke a c compiler, for
  example.

What about AOT vs JIT vs ...?

That's more a question of what representation a program should be distributed
in. The tradeoff is: too high level a representation requires compilation /
interpretation to be done somewhere. too low level a representation takes up
more space and is limited in where it can be run.

I guess today the representation is .fble, which is relatively compact, but
takes some time to compile and is slow to interpret. If we compile, the
representation would be .o, which may or may not be as compact, but is much
faster to run.

Regardless, we need to go to well specified formats (.fble, .c, .o, etc.), and
in general it's good for the framework to support separate pre-processing
passes, so I think this is worth introducing.

This is an end user API change. Instead of loading a .fble program, you want
to load a .o file. Or maybe you want to link against a compiled .o program.

Proposal: given a .fble program, compile to an object file that exposes the
following API:

FbleValue* Eval(FbleValueHeap* heap);

And in general, once you have an FbleValue, you can run it efficiently with
the existing FbleApply and FbleExec APIs, it just that code will be
represented as pointers to machine code instead of pointers to instruction
blocks.

---------

It seems worth doing some more detailed research and up front design for this.
Consider the following options to start:
* Generate c code.
* Use llvm.
* Use c--.
* Generate a custom, compact, efficient bytecode.

C-- looks obsolete now, and I'm not inspired by Haskell's performance.

llvm looks like a very complex entity I'll have to learn a lot more about if I
want to use it.

C code will be pretty clunky.

My vote is to experiment with llvm to start, and maybe spend some time
thinking about a custom bytecode.

Things to figure out how to do in particular in llvm:
* call into an fble runtime library
* tail call behavior - calling into a function as if by goto instead of
  pushing something on the stack
* storing pointers to code

Perhaps a nice way to avoid a direct dependency on llvm would be to generate
llvm's text format assembly language. Not sure. We'll have to see.

---

It seems fine to use llvm as the bytecode instead of a custom bytecode. It's
presumably just as compressible as whatever I come up with, but has the
advantage that there is existing technology to convert it to machine code.

We still want to have control over threading, however. Which means llvm isn't
at the bottom of the execution stack, it's in the middle, between the thread
scheduler and the actual computation.

Let me start calling llvm native code. The value of using native code over an
interpreted bytecode is you get hardware support for incrementing the pc,
fetching the next instruction, predicting branches. That could easily give you
10x improvement over interpreting instructions.

The concern is that the thread scheduler, or interaction with it, may start to
dominate performance overhead. I expect the native code would be a function
you could call that would do some finite amount of work on a thread and then
return a continuation. This means we can't use the native stack, unless the OS
supports some form of voluntary context switching we could leverage. And it
means we'll end up with a scheduling loop on top things that doesn't take
advantage of hardware support for fast pc incrementing, etc. If the amount of
work that gets run on a thread is small, that would be bad. Which suggests we
want to inline as much as we can to get decent size chunks of uninterrupted
native code.

In summary, some things to think about:
* Inlining to get decent size chunks of interrupted thread execution.
* See if llvm has any support for cooperative multithreading, or manipulation
  of the thread.

---

In terms of a custom bytecode. If we wanted all instructions to have the same
size, we could do it with:

FbleInstrTag tag;
bool exit;
FbleLoc loc;
size_t tag; // or blockid, or pc.
FbleFrameIndexV args;
FbleLocalIndexV dests;
FbleInstrBlock* code;

Notes
* exit could be incorporated into tag
* args is a vector for struct and scope, otherwise it could be 2.
* dests is a vector for fork, otherwise it could be 1.
* code could be a pc in theory, if all the instructions were saved into one
  big array. Though I guess we would need some other way to initialize the
  locals memory.

---
It looks like llvm has a tailcc calling convention that can be used to support
tail calls. Good.

It doesn't look like llvm has any general support for multithreading.

