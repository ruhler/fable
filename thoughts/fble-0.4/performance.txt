Fble Performance
================

The next round.

Starting with fbld as the application, because I have a C implementation to
compare against now.



fble implementation:
* ./pkgs/fbld/bin/fbld ../fbld/nobuildstamp.fbld ./fbld/version.fbld ../fbld/html.fbld ../spec/fble.lib.fbld ../spec/fble.fbld > /dev/null
* Elapsed (wall clock) time (h:mm:ss or m:ss): 1:29.06
* Maximum resident set size (kbytes): 122500

c implementation:
* ./fbld/fbld ../fbld/nobuildstamp.fbld ./fbld/version.fbld ../fbld/html.fbld ../spec/fble.lib.fbld ../spec/fble.fbld 
* Elapsed (wall clock) time (h:mm:ss or m:ss): 0:02.82
* Maximum resident set size (kbytes): 10480

C implementation is 30x faster and uses 10x less memory. Wow.

Perf breakdown for C implementation:
* Not surprisingly, most of the time is in FbldEval, spread across strcmp,
  malloc, free, etc.
* The big thing that stands out in FbldEval itself is environment lookup. 

Perf breakdown for Fble implementation:
* Evaluating sequence shows up a fair amount? Like half the time? With all the
  function call overheads involved with that.

It's difficult to tell from my profile, because of the way we merge samples
together.

Looking at raw samples:
* List.Ord, Map lookup are prevalent in the most common samples.
* Next is the 'Tail' function. 
* Next is the 'Head' function.

But really, map lookup seems to dominate.

---

What next here? It would be nice if I had a simple test case that demonstrated
the performance issue, where we are using the same algorithm in C and in fble.
That way I can dive deep into what overheads we have in fble that we don't
have in C, and try to get rid of them.

To start, string comparison? Or maybe there are some silly benchmark game
benchmarks we can use for string comparison? No, doesn't look like it.

How about this for a silly program:
* Input is a list of words.
* Add each word to a list.
* Look up each suffix of each word to see if it's in the list?

Or, we could look at the List.Ord function to start, since we are spending a
lot of time there?

How about this, rewrite fble implementation to use a list for Env instead of a
map. That way calls to Ord should go away, almost entirely? Maybe it's an
improvement. Maybe it brings us closer to the C implementation, and we can
focus on the lookup cost from there.

---

Switch to linked list for fble implementation. It's much faster. Wow.

Elapsed (wall clock) time (h:mm:ss or m:ss): 1:29.06 ==> 0:43.50
Maximum resident set size (kbytes): 122500 ==> 118964

Who would have thought? Does that imply that my Map implementation just isn't
very good?

---

Trying to tease out where time is going from the profile report for fble
implementation now.

Why is there no Parse() entry in the profile? Because it's a tail call I
guess. This is where perf based sampling hurts us that profiling wouldn't.

Total time: 13234
Eval:        6549
Parse:       1132

Profiling says:

Total time: 593575 
Eval:       519169 
Parse:       50077 
Input:       20885
Output:       1868

A fair amount of time processing int literals actually. More time processing
int literals than parsing! Wow. Can we fix those?

Removing the biggest use of Int literals:

Elapsed (wall clock) time (h:mm:ss or m:ss): 0:43.50 ==> 0:38.92
Maximum resident set size (kbytes): 118964 ==> 113248

---

Total:    526362
Eval:     451992
 Lookup:  135473
Parse:     50039

Result%.Ok! alone: 35563

It's an allocation, and it has to be if the argument 'x' isn't packed. Except
most of the time it's AssertArgCount, which is passing Unit?
